---
title: "3"
output:
  html_document: 
    toc: true
---

<!--
# Random todos for Veronica

- consider log models for sbert things
- try non-parametric brm-monotonic Dirichlet / simplex models 
- try GAM (on ???)
- better params for tSNE ??
- image embedding multi-modal model thingys??



wth happened with game tGuW7nukBHY72yfXn in round 1? we don't have text from them then??

check that role is correctly recording (post transition)
check that when a player is exited they aren't still selecting 
(I think these are not actual issues, but things that seemed to happen when some players were being non-cooperative)
Might be an issue in a couple games - we are getting more correct answers that people still playing in a couple instances in a couple games! (a relatively rare issue, but look into anyway!)

Confirm all sbert analyses on filtered data!

# Much prep(rocessing)
-->
```{r set-up, include=F}
knitr::opts_chunk$set(echo = FALSE, warning=F, message=F)
knitr::opts_chunk$set(dev = "png", dev.args = list(type = "cairo-png"))
options(knitr.table.format = "html")
library(tidyverse)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstanarm)
library(rstan)
library(viridis)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())

ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  %>% 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study3"


date_start=lubridate::ymd('2022-10-04') #TODO change

image_location="write-ups/images"

model_location="code/models"


```

```{r, include=F, eval=F}
##This was for determining participant bonuses using the version of data with PID
d.treatments <- read_csv(here(data_location, 'treatments.csv')) %>% rename(treatmentId=`_id`)
# 
d.games <- read_csv(here(data_location, 'games.csv')) %>%
  select(gameId=`_id`, treatmentId, playerIds) %>%
  left_join(d.treatments) %>%
  mutate(playerIds=str_split(playerIds,",")) %>%
  unnest(playerIds) %>%
  select(playerId=playerIds, name)

# d.round_results.raw |> select(speaker, gameId, trialNum) |> unique() |> 
#   group_by(speaker,gameId) |> tally() |> filter(n>1) |> 
#   pull(speaker) -> speakers

d.players <- read_csv(here(data_location, 'players.csv')) %>%
  filter(createdAt>=date_start) %>% 
  rename(playerId=`_id`) %>%
  left_join(d.games) %>%
  select(data.bonus, playerId,id,data.bonus,name) %>%
    filter(!is.na(name)) %>%
  mutate(bonus=round(data.bonus,2),
         #bonus=ifelse(playerId %in% speakers, bonus+2, bonus),
         cost=round(bonus*4/3,2)) %>%
  filter(cost!=0) %>% write_csv(here(data_location, "player_payments.csv")) |> select(id,bonus) %>% write_csv(here(data_location,"for_prolific.csv"))


```



```{r, include=F, eval=F}

treatments <- read_csv(here(data_location,"treatments.csv"))
d.games <- read_csv(here(data_location, 'games.csv')) %>% 
  rename(gameId = `_id`) %>% 
    filter(createdAt >= date_start) |> 
  left_join(treatments |> select(treatmentId=`_id`,name))

ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  %>% 
    fromJSON(flatten = T)
}
d.chat.raw <- read_csv(here(data_location, 'rounds.csv'), guess_max=10000) %>%
  filter(createdAt >= date_start) %>%
  mutate(data.chat = ifelse(is.na(data.chat), '{}', data.chat)) %>%
  rename(row_id = `_id`) %>% 
  mutate(data.chat = map(data.chat, .f = ParseJSONColumn)) %>% 
  unnest(data.chat) %>% 
  select(-data.target, -ends_with('response'), -ends_with('_correct'), -ends_with('time')) %>% 
  rename_with(~ gsub("data.", "", .x, fixed = TRUE)) %>% 
  filter(type=="message") %>% 
  write_csv(here(data_location, 'raw_chat.csv'))

library(data.table)
d.round_results.raw <- read.csv(here(data_location,'rounds.csv')) |> 
  setDT() |> 
  filter(createdAt >= date_start) %>% 
  rename_with(~ gsub("data.", "", .x, fixed = TRUE)) %>% 
  rename_with ( ~ gsub("room", "player", .x, fixed=T)) %>% 
    rename_with ( ~ gsub("player", "player_", .x, fixed=T)) %>% 
    rename_with ( ~ gsub("correct", "_correct", .x, fixed=T)) %>% 
    rename_with ( ~ gsub("response", "_response", .x, fixed=T)) %>% 
  rename_with( ~ gsub("time", "_time", .x, fixed=T)) |> 
  select(-chat) |> 
  pivot_longer(cols=starts_with('player'), names_to=c("playerId", "info"), names_prefix="player__", names_sep="__",
               values_to="values", values_transform=as.character, values_drop_na=T) |> 
  filter(values!="") |> 
  filter(playerId!=speaker) %>% 
  pivot_wider(names_from=info, values_from=values) %>% 
  filter(!is.na(correct)) |> 
  mutate(tangram = gsub('/experiment/tangram_', '', target, fixed=TRUE),
         tangram = gsub('.png', '', tangram, fixed=TRUE),
         correct=as.logical(correct),
         time=as.numeric(time)/1000) |> 
  write_csv(here(data_location, 'raw_results.csv'))

d.exit.survey <- read_csv(here(data_location, 'player-inputs.csv')) %>%
  filter(createdAt >= date_start) %>%
  left_join(d.games, by = c('gameId')) %>%
    rename_with(~ gsub("data.", "", .x, fixed = TRUE)) %>% 
    write_csv(here(data_location,'exit.csv'))


```

```{r, include=F, eval=F}
#we exclude rounds where no one talked (this is our criteria for "they weren't playing anymore")
# this is better than if no one submitted b/c maybe people fail to click on some round?

rounds_include <- (read_csv(here(data_location,'raw_chat.csv'))) %>% 
  filter(role=="speaker") %>% 
  filter(!is.na(text)) %>%
  filter(gameId!="MhCsn5ZQTvFv49Bwy") |> # ***** just excluding this game by fiat -- the assigned speaker seemed to either really, really not be fluent or not understand the game. They do not provide descriptions and only barely answer when the listeners play 20 questions. ******
  select(gameId,numPlayers,repNum,targetNum) %>% unique() %>% 
  group_by(gameId,numPlayers,repNum) %>% tally() %>% 
  filter(n==12) %>% select(gameId,repNum) |> 
  left_join(d.games |> select(gameId,name)) |> 
  write_rds(here(data_location,"rounds_include.rds"))

d.round_results <-(read_csv(here(data_location,'raw_results.csv'))) %>% inner_join(rounds_include) %>% write_rds(here(data_location,'round_results.rds'))

d.correct <- d.round_results %>% 
  group_by(`X_id`,gameId,target,targetNum,repNum,trialNum,
           numPlayers,countCorrect,speaker,tangram) %>% 
  summarize(realCorrect=sum(ifelse(correct,1,0)))

d.round_results %>% left_join(d.correct) %>% 
  left_join(d.games |> select(gameId, name)) |> write_rds(here(data_location,"round_results.rds"))

d.exit_survey <- (read_csv(here(data_location,'exit.csv'))) %>% 
  inner_join(rounds_include |> select(gameId) |> unique()) |> 
  write_csv(here(data_location,"exit_survey.csv"))
  
```
# Descriptives

How many games:

Note -- one 6 p thick game excluded by fiat -- the assigned speaker seemed to either really, really not be fluent or not understand the game. They do not provide descriptions and only barely answer when the listeners play 20 questions.

Aimed for 40 each. 

Partial means it didn't go all the rounds, reduced means it has fewer people than it started out with. (Note we also started games even if they were incomplete, so there might be more classification adventures there. )

```{r}
d.round_results <- read_rds(here(data_location, "round_results.rds")) 

d.round_results%>% group_by(gameId,name, numPlayers) %>% 
  summarize(max_rep=max(repNum),
            min_active=min(activePlayerCount)) %>% 
  mutate(game_length=case_when(
    max_rep!=5 ~ "partial",
    min_active!=numPlayers ~ "reduced",
    T ~ "complete")) %>% 
  group_by(name, game_length) %>% 
  tally() %>% 
  pivot_wider(names_from="game_length",values_from="n")
```

Of rounds included

```{r}
treatments <- read_csv(here(data_location,"treatments.csv"))
d.games <- read_csv(here(data_location, 'games.csv')) %>% 
  rename(gameId = `_id`) %>% 
    filter(createdAt >= date_start) |> 
  left_join(treatments |> select(treatmentId=`_id`,name))

(read_csv(here(data_location,'raw_results.csv')))|>   left_join(d.games |> select(gameId,name)) |> 
select(gameId, name, numPlayers, trialNum, activePlayerCount) |> 
  unique() |> 
  ggplot(aes(x=trialNum, fill=as.factor(activePlayerCount)))+geom_bar()+facet_grid(.~name)+
  labs(title="Of all games even rounds excluded")

d.round_results |> select(gameId, name, numPlayers, trialNum, activePlayerCount) |> 
  filter(name %in% c("6_thick", "6_thin")) |> 
  unique() |> 
  ggplot(aes(x=trialNum, fill=as.factor(activePlayerCount)))+geom_bar()+facet_grid(.~name)+
  labs("Of complete rounds only")

# weird <- d.round_results |> select(gameId, name, numPlayers, repNum, trialNum, activePlayerCount) |> 
#   filter(name %in% c("6_thick", "6_thin")) |> 
#   unique() |> 
#   group_by(gameId) |> 
#   tally() |> 
#   filter(n!=72)
# 
# d.round_results |> select(gameId, name, numPlayers, repNum, trialNum, activePlayerCount) |> 
#   filter(name %in% c("6_thick", "6_thin")) |> 
#   unique() |> 
#   inner_join(weird) |> 
#   group_by(gameId) |> 
#   summarize(min=min(trialNum),
#             max=max(trialNum))


```

How long full games took

Note that this is inaccurate for games where some players kept the tab open but didn't respond (but we don't have an easy way to distinguish "exited" from "inactive, but tab open" in this record). 

```{r}
summary <- d.round_results %>% group_by(trialNum, repNum, gameId, name) %>% 
           mutate(time= time %|% 0) %>% # empties are either that they didn't answer or that they were already exited (should adjust recording for future!). This slighlty lowballs 
  summarize(max_time=max(time)) %>% 
  group_by(gameId, name) %>% 
  summarize(total_time=sum(max_time)/60,
            num_rounds=max(repNum)) %>% 
  arrange(name)

message("Full games")

summary %>% filter(num_rounds==5) %>% 
  group_by(name) %>% 
  summarize(games=n(),
            min_time=min(total_time) %>% round(),
            `25th_time`=quantile(total_time, .25)%>% round(),
            median_time=quantile(total_time, .5)%>% round(),
            `75th_time`=quantile(total_time, .75)%>% round(),
            max_time=max(total_time)%>% round()) 

```









# Exit survey

```{r}
exit <- read_csv(here(data_location,"exit_survey.csv")) |> 
  select(playerId,gameId,correctness, human, workedWell, time, fair, chatUseful,feedback.x, name)
```


Most people think they understood directions

```{r}
exit |> group_by(name,correctness) |> tally() # most people think they understood directions

```

Did you think you were playing with humans? Mostly yes.

```{r}
exit |> group_by(name,human) |> tally() |> pivot_wider(names_from=human, values_from=n) |> 
  mutate(sum=no+yes+`NA`,
         no=no/sum ,
         yes=yes/sum ,
         no_answer=`NA`/sum) |> select(-`NA`,-sum)

```

people mostly thought they worked well together

```{r}
exit |> group_by(name, workedWell) |> tally() |> pivot_wider(names_from=workedWell, values_from=n, values_fill=0) |> 
  mutate(sum=stronglyAgree+agree+neutral+disagree+stronglyDisagree+`NA`) |> 
  mutate(across(agree:`NA`, ~ .x/sum)) |> 
  select(name, stronglyAgree, agree, neutral, disagree, stronglyDisagree, `NA`)


```

we also have text answers about whether the chat was useful, time was sufficient, pay was fair, and general feedback which I guess I should read sometime. 

# Trial internal structure

```{r chat}

rounds_include <- read_rds(here(data_location,"rounds_include.rds"))
d.round_results <- read_rds(here(data_location,"round_results.rds"))

d.chat.filter <- read_csv(here(data_location, "filtered_chat.csv")) |> 
  filter(!is.chitchat) %>% 
  filter(!is.na(target)) |> 
  mutate(text = gsub("\\n", '', fixed = T, spellchecked), # note that this is using spellcorrected version!!!!
         text = gsub("[/?/.]", ' ', text),
         text = str_squish(text),
         tangram = gsub('/experiment/tangram_', '', target, fixed=TRUE),
         tangram = gsub('.png', '', tangram, fixed=TRUE),
         utt_length_chars = str_length(text), 
         utt_length_words = str_count(text, "\\W+") + 1) %>%
  group_by(gameId, trialNum, repNum, tangram) %>% 
  mutate(is.firstutter=ifelse(role!="speaker",F,NA)) %>% 
  fill(c("is.firstutter"), .direction="down") %>% 
  mutate(is.firstutter= is.firstutter %|% T) 

d.chat <- d.chat.filter %>% 
  group_by(gameId, trialNum, repNum, tangram, playerId, role, numPlayers) %>%
  summarize(text = paste0(text, collapse = ', '),
            total_num_words = sum(utt_length_words, na.rm=T) %>% as.numeric(),
            total_num_chars = sum(utt_length_chars, na.rm=T) %>% as.numeric()) %>%
  inner_join(rounds_include) %>% 
  full_join(d.round_results, c("gameId", "trialNum", "repNum", "playerId", "tangram", "numPlayers", "name")) %>% 
  mutate(text = text %|% "",
         total_num_words= total_num_words %|% 0,
         total_num_chars= total_num_chars %|% 0,
         role = role %|% "listener") |> 
  write_rds(here(data_location, "chat.csv"))

d.listener <- read_csv(here(data_location,"raw_chat.csv")) %>% filter(role=="listener") %>% inner_join(rounds_include)

d.chat.pre <- d.chat.filter %>% group_by(gameId, trialNum, repNum, tangram, playerId, is.firstutter,role, numPlayers) %>%
  summarize(text = paste0(text, collapse = ', '),
            total_num_words = sum(utt_length_words, na.rm=T) %>% as.numeric(),
            total_num_chars = sum(utt_length_chars, na.rm=T) %>% as.numeric()) %>%
  inner_join(rounds_include) %>% 
  ungroup() %>% 
  mutate(text = text %|% "",
         total_num_words= total_num_words %|% 0,
         total_num_chars= total_num_chars %|% 0,
         role = role %|% "listener") %>% 
  filter(is.firstutter)

```

```{r}
#To do deal with rounds include issues
rounds_include <- read_rds(here(data_location,"rounds_include.rds"))

#a <- read_csv(here(data_location, 'rounds.csv'), guess_max=10000)

ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  %>% 
    fromJSON(flatten = T)
}

# chat_labelled <- read_csv(here(data_location, 'rounds.csv'), guess_max=10000) |> 
#   filter(createdAt >= date_start) %>%
#   mutate(data.chat = ifelse(is.na(data.chat), '{}', data.chat)) %>%
#   rename(row_id = `_id`) %>% 
#   mutate(data.chat = map(data.chat, .f = ParseJSONColumn)) %>% 
#   unnest(data.chat) |> 
#   select(-data.target, -ends_with('response'), -ends_with('_correct'), -ends_with('time')) %>%
#   rename_with(~ gsub("data.", "", .x, fixed = TRUE)) |> 
#   group_by(gameId,repNum,trialNum) |> 
#   mutate(selector=ifelse(type=="selectionAlert", str_c(playerId,"_"), ""),
#          selected=accumulate(selector, paste),
#          num_selected=str_count(selected, "_"),
#          self_selected=str_detect(selected, playerId)) |> 
#   filter(type=="message")
# 
# chat_labelled |> select(-selector, -selected) |> write_csv(here(data_location,"time_course_round.csv"))

speaker_said_so_far <- read_csv(here(data_location, 'rounds.csv'), guess_max=10000) |> 
  filter(createdAt >= date_start) %>%
  mutate(data.chat = ifelse(is.na(data.chat), '{}', data.chat)) %>%
  rename(row_id = `_id`) %>% 
  mutate(data.chat = map(data.chat, .f = ParseJSONColumn)) %>% 
  unnest(data.chat) |> 
  select(-data.target, -ends_with('response'), -ends_with('_correct'), -ends_with('time')) %>% 
  rename_with(~ gsub("data.", "", .x, fixed = TRUE)) |> 
  group_by(gameId,repNum,trialNum) |> 
  mutate(speaker_said=ifelse(role=="speaker",str_c(text," "), ""),
         said_so_far=accumulate(speaker_said, paste)) |> 
  filter(type=="selectionAlert") |> 
  inner_join(rounds_include)


```


## speaker language

Amount of speaker language (total, not cleaned) before selection

you can kind of see the block structure where there's discontinuities at 12, etc. 

how much said before listener selected

```{r}
speaker_said_so_far |> mutate(num_words=str_squish(said_so_far) |> str_count("\\W+") + 1) |> 
  ggplot(aes(x=trialNum, y=num_words, color=name))+geom_point(alpha=.01)+ stat_summary(fun.data = "mean_cl_boot", size=.2)+facet_wrap(~name)+
  coord_cartesian(ylim=c(0,75))+
  scale_x_continuous(breaks=c(0,12,24,36,48,60,72))



```

How much did the speaker say before the first listener selected?

```{r}
list_order <- speaker_said_so_far |> mutate(num_words=str_squish(said_so_far) |> str_count("\\W+") + 1) |> 
  group_by(gameId,repNum, trialNum) |> 
  mutate(add_words = num_words-lag(num_words, default=0),
         select_num= row_number()) 

list_order |> 
  filter(select_num==1) |> 
  filter(add_words!=0) |> 
  ggplot(aes(x=trialNum, y=add_words, color=name))+facet_wrap(~select_num)+geom_point(alpha=.01)+stat_summary(fun.data = "mean_cl_boot", size=.2)+
  coord_cartesian(ylim=c(0,50))+  scale_x_continuous(breaks=c(0,12,24,36,48,60,72))

```

this is relatively similar across games/sizes, although there's some order statistics stuff going on. 

how much of the time did the speaker say more things between the n-1 and nth selection?

```{r}
list_order |> 
  filter(select_num!=1) |> 
  filter(select_num!=6) |> 
  mutate(said_more=ifelse(add_words==0,0,1)) |> 
  ggplot(aes(x=trialNum, y=said_more, color=name))+facet_wrap(~select_num)+geom_smooth()+
  scale_x_continuous(breaks=c(0,12,24,36,48,60,72))
```

```{r}
# list_order |> 
#   filter(select_num!=1) |> 
#   filter(add_words!=0) |> 
#   ggplot(aes(x=trialNum, y=add_words, color=name))+facet_wrap(~select_num)+geom_point(alpha=.01)+stat_summary(fun.data = "mean_cl_boot", size=.2)+
#   coord_cartesian(ylim=c(0,50))+scale_x_continuous(breaks=c(0,12,24,36,48,60,72))
```

## How much feedback do listeners give (per trial)?

Note, most listeners say nothing most of the time, but we're not showing all the zeros. 

```{r}
rounds_include <- read_rds(here(data_location,"rounds_include.rds"))
d.round_results <- read_rds(here(data_location,"round_results.rds"))
chat <- read_csv(here(data_location, "filtered_chat.csv"))
 time_course <- read_csv(here(data_location, "time_course_round.csv")) |> 
   filter(type=="message") |> 
   full_join(chat) |> 
   full_join(d.round_results) |> 
   inner_join(rounds_include) |> 
  mutate(text = text %|% "",
         role = role %|% "listener") |> 
  filter(role=="listener") |> 
  select(gameId, trialNum, text, playerId,name, self_selected, is.chitchat, num_selected) |> 
    mutate(text = gsub("[/?/.]", ' ', text),
         text = str_squish(text),
         utt_length_chars = str_length(text), 
         utt_length_words = str_count(text, "\\W+") + 1) %>%
    group_by(gameId, trialNum, playerId, name, self_selected, is.chitchat, num_selected) |> 
  summarize(text = paste0(text, collapse = ', '),
            total_num_words = sum(utt_length_words, na.rm=T) %>% as.numeric(),
            total_num_chars = sum(utt_length_chars, na.rm=T) %>% as.numeric())
```

Said before that listener selecting (no chit-chat)

These are faceted by game size and how many listeners had selected so far. 

note decline in dot density over trials. 

```{r}
time_course |> filter(name %in% c("6_thick", "2_thick")) |> 
  filter(!self_selected) |> 
  filter(!is.chitchat) |> 
  group_by(gameId, playerId,name, trialNum, num_selected) |> 
  summarize(words=sum(total_num_chars)) |> 
  ggplot(aes(x=trialNum, y=words, color=as.factor(num_selected)))+geom_point(alpha=.4)+facet_wrap(~str_c(num_selected," ",name))+
  geom_smooth()+
  theme(legend.position = "none")

```

Said after selecting (no chit-chat)

```{r}
time_course |> filter(name %in% c("6_thick", "2_thick")) |> 
  filter(self_selected) |> 
  filter(!is.chitchat) |> 
  group_by(gameId, playerId,name, trialNum, num_selected) |> 
  summarize(words=sum(total_num_chars)) |> 
  ggplot(aes(x=trialNum, y=words, color=as.factor(num_selected)))+geom_point(alpha=.4)+facet_wrap(~str_c(num_selected," ",name))+
  #geom_smooth()+
  theme(legend.position = "none")

```

Note that we expect more opportunity for pre-selection talk when there are fewer selections, and more post-selection when there are more selections (b/c of number of listeners eligible).

Amount of listener talking declines, mostly because things turn into more zeros. As expected, in 2p games, there's little talk post selection (because they've clicked it, so it should be ~impossible). In 6p games there is some. This is probably mostly listener-listener as some help explain to laggards. 

<!--# Many graphs 

 
Everything here has bootstrapped 95% CIs. 

Should find better curves to fit, but using quadratic to allow for some curvature.

```{r}
d.chat %>% filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram, name) %>% 
  summarize(words=sum(total_num_words)) |> 
ggplot(aes(x=repNum, y=words, color=name))+
  facet_wrap(.~name, nrow=1)+
  scale_color_brewer(palette="Dark2")+
    geom_line(aes(group=groupxtangram), alpha=.05,method=glm, se=F)+
  coord_cartesian(y=c(0,60))+
    #geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian(link = 'log')))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  labs(title="Words from speaker per tangram", y="Number of words", x="Round number", color="Player count")+
  theme(legend.position="null")

d.chat %>% filter(role=="speaker") %>% 
    #mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId, name) %>% 
  summarize(words=sum(total_num_words)) |> #View()
ggplot(aes(x=repNum, y=words, color=name))+
  facet_wrap(.~name, nrow=1)+
  scale_color_brewer(palette="Dark2")+
    geom_line(aes(group=gameId), alpha=.5,method=glm, se=F)+
  #coord_cartesian(y=c(0,60))+
    #geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian(link = 'log')))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  labs(title="Words from speaker per round", y="Number of words", x="Round number", color="Player count")+
  theme(legend.position="null")

```

```{r}
d.chat %>% filter(role=="speaker") %>% 
ggplot(aes(x=repNum, y=total_num_words, color=name))+
  facet_wrap(~tangram)+
  scale_color_brewer(palette="Dark2")+
    geom_smooth(method=glm, formula=y~poly(x,2), se=T, alpha=.1)+
    #  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian(link = 'log')))+
       stat_summary(fun.data = "mean_cl_boot", size=.2)+
  labs(title="Tangram variability", y="Number of words", x="Round number", color="Player count")+
  theme(legend.position="bottom")


```



```{r accuracy}
#Note: as a result of 5 high looking lower, we adjusted the inclusion criteria to exclude the game where people didn't select responses after the first round, but one listner kept sending "is anyone there?" type messages to the chat the *entire* game. (This is probably a minor software issue since maybe others had disconnected?)

d.round_results %>% group_by(playerId,repNum, gameId, name) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  ggplot(aes(x=repNum, y=correct.num, color=name))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  #geom_point()+
  scale_color_brewer(palette="Dark2")+
  #scale_y_continuous(limits = c(0,1))+
  labs(x="Round Number", y="Fraction correctly selected", title= "Overall accuracy increases over repetitions", color="Player count")+
    theme(legend.position="bottom")

  
```

Note that this accuracy is of players who clicked something!


```{r time}
d.round_results %>% group_by(playerId, repNum, gameId, name) %>% 
  filter(correct==T) %>% 
  #summarize(time=mean(time)) %>% 
  ggplot(aes(x=repNum, y=time, color=name))+
  geom_jitter(width=.4, height=0, alpha=.01)+
geom_smooth(method = "glm", formula = y~x,
                      method.args = list(family = gaussian(link = 'log')))+
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  scale_y_continuous(limits = c(0,180))+
    scale_color_brewer(palette="Dark2")+
  labs(x="Round Number", y="Time to selection in seconds",
       title="People choose faster in later rounds", color="Player count")+
  theme(legend.position = "bottom")


```
-->
<!--
# Prep Sbert
Should we do this on filtered (chit-chat free) and/or spell checked sample?
```{r, include=F, eval=F}
rounds_include <- read_rds(here(data_location,"rounds_include.rds"))
d.round_results <- read_rds(here(data_location,"round_results.rds"))

d.pre.sbert <- read_csv(here(data_location, "filtered_chat.csv")) |> 
  #filter(!is.chitchat) %>% 
  filter(!is.na(target)) |> 
    filter(!is.na(text)) %>% 
  mutate(tangram = gsub('/experiment/tangram_', '', target, fixed=TRUE),
         tangram = gsub('.png', '', tangram, fixed=TRUE)) %>%
  inner_join(rounds_include) |>
  separate(name, into=c("playerCond","channelCond")) |> 
  select(gameId, targetNum, repNum, trialNum, playerCond, channelCond, activePlayerCount,playerId, tangram, role, text) |>
  group_by(gameId, targetNum, repNum, trialNum, playerCond, channelCond, activePlayerCount,playerId, tangram, role) |>  summarize(sentence=str_c(text, collapse=" ")) |> 
  ungroup() |> 
  write_csv(here(data_location,"pre_sbert.csv"))
```


```{r, include=F, eval=F}
library(reticulate)
np <- import("numpy")
mat = np$load(here(data_location,'post_sbert.npy'))
saveRDS(mat,here(data_location,'post_sbert.RData'))

```

```{r}
sbert_concat <- read_csv(here(data_location,"pre_sbert.csv")) |>   bind_cols(readRDS(here(data_location,'post_sbert.RData'))  %>% as_tibble())

F_mat <- sbert_concat %>% select(starts_with("V")) %>% as.matrix() #Features
M_mat <- sbert_concat %>% select(-starts_with("V")) %>% mutate(feature_ind=row_number())
```

```{r helpers}
# note: cor expects features to be in columns so we transpose
get_sim_matrix = function(df, F_mat, method = 'cosine') {
  feats = F_mat[df$feature_ind,]
  if(method == 'cor') {
    return(cor(t(feats), method = 'pearson'))
  } else if (method == 'euclidean') {
    return(as.matrix(dist(feats, method = 'euclidean')))
  } else if (method == 'cosine') {
    return(as.matrix(lsa::cosine(t(feats))))
  } else {
    stop(paste0('unknown method', method))
  }
}

# note this does de-duplicated version
flatten_sim_matrix <- function(cormat, ids) {
  ut <- upper.tri(cormat)
  data.frame(
    dim1 = ids[row(cormat)[ut]],
    dim2 = ids[col(cormat)[ut]],
    sim  = as.numeric(cormat[ut])
  ) %>%
    mutate(dim1 = as.character(dim1),
           dim2 = as.character(dim2))
}

make_within_df <- function(M_mat, F_mat, method) {
  M_mat %>%
    do(flatten_sim_matrix(get_sim_matrix(., F_mat, method = method),
                          .$repNum)) %>%
    mutate(rep1 = as.numeric(dim1), 
           rep2 = as.numeric(dim2)) 
}

make_across_df <- function(M_mat, F_mat, method) {
  M_mat %>%
    do(flatten_sim_matrix(get_sim_matrix(., F_mat, method = method),
                          as.character(.$combinedId)))
}
```

-->
# Sbert results

## Across game divergence

```{r, cache=T}

game_divergence <- M_mat %>% 
  filter(role=="speaker") %>% 
  group_by(tangram,repNum, channelCond,playerCond) %>% 
  mutate(combinedId=str_c(gameId,repNum,sep="_")) %>% 
  make_across_df(F_mat, 'cosine') %>% 
  separate(dim1, into=c("gameId_1","repNum_1"), convert=T, sep="_") %>% 
  separate(dim2, into=c("gameId_2","repNum_2"), convert=T, sep="_") %>% 
  filter(gameId_1!=gameId_2) %>% 
  mutate(sim = ifelse(is.nan(sim), NA, sim)) %>%
  ungroup()

```

```{r}
ggplot(game_divergence, aes(x=repNum+1,y=sim,color=str_c(playerCond, channelCond)))+
      stat_summary(aes(group=str_c(playerCond, channelCond,tangram), color=str_c(playerCond, channelCond)),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+

  geom_smooth(formula=y~poly(x,2))+

  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="Cond")+
  theme(text=element_text(size=14), legend.position="bottom")+
    scale_color_viridis(discrete=T, direction=-1)
  #coord_cartesian(ylim=c(0.1,.6))

```

## Within game divergence

```{r, cache=T }

tangram_distinctive <- M_mat %>% 
    filter(role=="speaker") %>% 
  group_by(gameId,repNum, channelCond,playerCond) %>% 
  mutate(combinedId=tangram) %>% 
  make_across_df(F_mat, 'cosine') %>% 
  rename(tangram1=dim1,tangram2=dim2) %>% 
  mutate(sim = ifelse(is.nan(sim), NA, sim)) %>%
  filter(tangram1!=tangram2) %>% 
  ungroup()
```


```{r, }
ggplot(tangram_distinctive, aes(x=repNum+1,y=sim,color=str_c(playerCond, channelCond)))+
      stat_summary(aes(group=str_c(gameId), color=str_c(playerCond, channelCond)),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+

  geom_smooth(formula=y~poly(x,2))+

  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity of descriptions \n of different tangrams within a game", x="Block", color="Players")+
  theme(text=element_text(size=14))+
    scale_color_viridis(discrete=T, direction=-1)
  #coord_cartesian(ylim=c(0.1,.6))

```

## Within game similarity

```{r, cache=T}

tangram_change <- M_mat %>% 
    filter(role=="speaker") %>% 
  group_by(tangram, gameId, playerCond,channelCond) %>% 
  mutate(combinedId=str_c(repNum,playerId,sep="_")) %>% 
  make_across_df(F_mat, 'cosine') %>% 
  separate(dim1, into=c("repNum_1","p1"), convert=T, sep="_") %>% 
  separate(dim2, into=c("repNum_2","p2"), convert=T, sep="_") %>% 
  mutate(sim = ifelse(is.nan(sim), NA, sim)) %>%
  filter(!is.na(repNum_1)) %>% 
    mutate(later=ifelse(repNum_1>repNum_2,repNum_1, repNum_2),
         earlier=ifelse(repNum_1>repNum_2,repNum_2, repNum_1),
         samespeaker=ifelse(p1==p2,"same_speaker","diff_speaker")) 

adjacent <- tangram_change %>% 
  filter(earlier+1==later) %>% 
  ungroup()

to_first <- tangram_change |> filter(earlier==0) |> ungroup()

to_last <- tangram_change |> filter(later==5) |> ungroup()
```


```{r}

 ggplot(to_first, aes(x=later+1,y=sim,color=str_c(playerCond, channelCond)))+
      stat_summary(aes(group=str_c(gameId), color=str_c(playerCond, channelCond)),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity to ...", x="Block",title="first block")+
    scale_color_viridis(discrete=T, direction=-1)

 ggplot(adjacent, aes(x=earlier+1,y=sim,color=str_c(playerCond, channelCond)))+
      stat_summary(aes(group=str_c(gameId), color=str_c(playerCond, channelCond)),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="", x="Block")+
  ggtitle("next block")+
    scale_color_viridis(discrete=T, direction=-1)

 ggplot(to_last, aes(x=earlier+1,y=sim,color=str_c(playerCond, channelCond)))+
      stat_summary(aes(group=str_c(gameId), color=str_c(playerCond, channelCond)),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="Players", title="Similarity to description in final block")+
    scale_color_viridis(discrete=T, direction=-1)

```

# CAMP graphs

```{r}
#good
library(cowplot)
reduction <-  d.chat %>% filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram, name) %>% 
  summarize(words=sum(total_num_words)) |> 
  #group_by(repNum, name, gameId) |> 
  #summarize(words=sum(words)) |> 
ggplot(aes(x=repNum+1, y=words, color=name))+
   scale_color_brewer(palette="Paired", direction=-1)+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  annotate("text", x=6, y=60,label="Words from speaker per tangram", color="black", size=6, hjust=1)+
    annotate("text", x=6, y=50,label="Speakers said more in 6p games \n and less in later blocks", color="black", size=6, hjust=1)+
  theme(legend.position="none",
        text=element_text(size=16))

for_legend <-d.chat %>% filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram, name) %>% 
  summarize(words=sum(total_num_words)) |> 
ggplot(aes(x=repNum+1, y=words, color=name))+
   scale_color_brewer(palette="Paired", direction=-1)+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  labs(y="Number of words", x="Block", color="")+
  theme(legend.position="bottom", legend.text = element_text(size=18))+
  guides(color=guide_legend(override.aes=list(linetype=0, alpha=1, size=7)))

# good
 accuracy <- d.round_results %>% group_by(playerId,repNum, gameId, name) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  ggplot(aes(x=repNum+1, y=correct.num, color=name))+
     scale_x_continuous(breaks=seq(1,6))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
       annotate("text", x=2, y=.98,label="Listener Accuracy", color="black", size=6, hjust=0)+
    annotate("text", x=6, y=.75,label="Accuracy increased,\n condition differences remained", color="black", size=6, hjust=1)+
  theme(legend.position="none",
        text=element_text(size=16))+
        scale_color_brewer(palette="Paired", direction=-1)

 diverge <- ggplot(game_divergence, aes(x=repNum+1,y=sim,color=str_c(playerCond, channelCond)))+
      stat_summary(aes(group=str_c(playerCond, channelCond,tangram), color=str_c(playerCond, channelCond)),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="")+
 annotate("text", x=6, y=.58,label="Similarity of descriptions\n across games", color="black", size=6, hjust=1)+
    annotate("text", x=1, y=.23,label="6_thin developed\nless group-specific names", color="black", size=6, hjust=0)+
  theme(legend.position="none",
        text=element_text(size=16))+
   scale_color_brewer(palette="Paired", direction=-1)


 converge <- ggplot(to_last, aes(x=earlier+1,y=sim,color=str_c(playerCond, channelCond)))+
      stat_summary(aes(group=str_c(gameId), color=str_c(playerCond, channelCond)),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="")+
 annotate("text", x=5, y=.33,label="Similarity to description\n in final block", color="black", size=6, hjust=1)+
    annotate("text", x=5, y=.15,label="Thick games and 2p games\n converged faster", color="black", size=6, hjust=1)+
  theme(legend.position="none",
        text=element_text(size=16))+     scale_color_brewer(palette="Paired", direction=-1)

```

```{r, fig.width=10, fig.height=10}

row1 <- plot_grid(reduction,accuracy, labels=c("A","B"), label_size=18, label_x=.15, label_y=.95)
row2 <- plot_grid(get_legend(for_legend))
row3 <- plot_grid(diverge, converge, labels=c("C","D"), label_size=18, label_x=.15, label_y=.95)

p <- plot_grid(row1,row2,row3, nrow=3, rel_heights = c(1,.1,1))

save_plot(here(image_location,"CAMP1.pdf"),p, base_width=10, base_height=10)
#save_plot(here(image_location,"CAMP1.png"),p, base_width=10, base_height=10)

p

```



# Models
From pre-reg

We will do graphical visualizations for accuracy, time taken and utterance reduction. 
 
Our primary analysis will be a Bayesian mixed model for utterance reduction in the words written by the speaker on each trial: 
words ~ block*channel*group_size + (block*channel*group_size|tangram)+ (1|tangram*group)+(block|group)

We will also run a logistic Bayesian mixed model on listener accuracy:
listener_accurate ~ block*channel*group_size + (block*channel*group_size|tangram)+ (1|tangram*group)+(block|group)
Additionally, we will analyse the effect of the language. Using SBERT embeddings we will embed the concatenation of everything the speaker said in a trial. We will then take pairwise cosine distances of these to look at the following effects. :
(divergence across games) For the same condition & block & tangram, distance between utterances from different games. 
(divergence within games) For the same condition & block & game, distance between utterances for different tangrams.
 (convergence within games) For the same condition & game & tangram, distance between utterances from different blocks. We plan to look at the similarities for block 1 with all later blocks; block 6 with all earlier blocks; and block N with block N+1. 
(Note: these SBERT analyses were done as exploratory analyses on the earlier collected conditions.)
Additionally, exclusive to the thin channel parts of this condition, we will analyse the distribution of emoji’s produced as a function of block and its relation to accuracy and speaker utterance length. 

## Reduction of words

rerun for longer with fuller mixed effects

```{r, eval=F, include=F}
chat_mod <- d.chat |> filter(role=="speaker") |>
  group_by(gameId, repNum, tangram, playerId, name) |> 
  summarize(words=sum(total_num_words)) |> 
  separate(name, into= c("gameSize","channel"))

red_prior <- c(set_prior("normal(12,20)", class="Intercept"),
               set_prior("normal(0,10)", class="b"),
               set_prior("normal(0,5)", class="sd"),
              set_prior("lkj(1)", class="cor")
               )

red_model <- brm(words ~ repNum*channel*gameSize + 
                (repNum*channel*gameSize|tangram)+
                          (1|tangram:gameId)+
                          (repNum|gameId), 
                 data=chat_mod,
                 file=here(model_location,"red_model_study3_mix.rds"),
                 control=list(adapt_delta=.99),
                 prior=red_prior)


```

```{r} 
read_rds(here(model_location,"red_model_study3_mix.rds")) |> summary()

```

## Accuracy model

```{r, eval=F, include=F}
acc_data <- d.round_results %>% select(playerId,repNum, gameId, name, tangram, response, correct) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
    separate(name, into= c("gameSize","channel"))
  


acc_priors <- c(set_prior("normal(0,1.5)", class="Intercept"),
               set_prior("normal(0,.5)", class="b"),
               set_prior("normal(0,.1)", class="sd"),
               set_prior("lkj(1)", class="cor"))
               
acc_model <- brm(correct.num ~ repNum*channel*gameSize+
                          (repNum*channel*gameSize|tangram)+
                          (1|tangram:gameId)+
                          (repNum|gameId), 
                        family=bernoulli(link="logit"),
                        data=acc_data,
                        control=list(adapt_delta=.99),
                        file=here(model_location,"acc_model_study3_mix.rds"),
                        prior=acc_priors)

```

```{r} 
read_rds(here(model_location,"acc_model_study3_mix.rds")) |> summary()

```

## Sbert models

```{r, eval=F, include=F}
game_divergence <- M_mat %>% 
  filter(role=="speaker") %>% 
  group_by(tangram,repNum, channelCond,playerCond) %>% 
  mutate(combinedId=str_c(gameId)) %>% 
  make_across_df(F_mat, 'cosine') %>% 
  rename(gameId_1=dim1, gameId_2=dim2) |> 
  filter(gameId_1!=gameId_2) %>% 
  mutate(sim = ifelse(is.nan(sim), NA, sim)) %>%
  ungroup() |> 
  mutate(gameSize=as.factor(playerCond)) |> 
  rename(channel=channelCond)

sbert_priors <- c(set_prior("normal(.5, .2)", class="Intercept"),
               set_prior("normal(0,.1)", class="b"),
               set_prior("normal(0,.05)", class="sd"))#,
              # set_prior("lkj(1)", class="cor")
               
game_div_model <- brm(sim ~ repNum*channel*gameSize+
                          #(repNum*channel*gameSize|tangram)+
                         (1|tangram),
                         # (repNum|gameId), 
                        data=game_divergence,
                        control=list(adapt_delta=.95),
                        file=here(model_location,"div_model_study3_mix.rds"),
                        prior=sbert_priors)


tangram_distinctive <- M_mat %>% 
    filter(role=="speaker") %>% 
  group_by(gameId,repNum, channelCond,playerCond) %>% 
  mutate(combinedId=tangram) %>% 
  make_across_df(F_mat, 'cosine') %>% 
  rename(tangram1=dim1,tangram2=dim2) %>% 
  mutate(sim = ifelse(is.nan(sim), NA, sim)) %>%
  filter(tangram1!=tangram2) %>% 
  ungroup() |> 
  mutate(gameSize=as.factor(playerCond)) |> 
  rename(channel=channelCond)

tangram_div_model <- brm(sim ~ repNum*channel*gameSize+
                         (1|gameId),
                         # (repNum|gameId), 
                        data=tangram_distinctive,
                        control=list(adapt_delta=.95),
                        file=here(model_location,"tangram_model_study3_mix.rds"),
                        prior=sbert_priors)

tangram_change <- M_mat %>% 
    filter(role=="speaker") %>% 
  group_by(tangram, gameId, playerCond,channelCond) %>% 
  mutate(combinedId=str_c(repNum,playerId,sep="_")) %>% 
  make_across_df(F_mat, 'cosine') %>% 
  separate(dim1, into=c("repNum_1","p1"), convert=T, sep="_") %>% 
  separate(dim2, into=c("repNum_2","p2"), convert=T, sep="_") %>% 
  mutate(sim = ifelse(is.nan(sim), NA, sim)) %>%
  filter(!is.na(repNum_1)) %>% 
    mutate(later=ifelse(repNum_1>repNum_2,repNum_1, repNum_2),
         earlier=ifelse(repNum_1>repNum_2,repNum_2, repNum_1),
         samespeaker=ifelse(p1==p2,"same_speaker","diff_speaker")) 

adjacent <- tangram_change %>% 
  filter(earlier+1==later) %>% 
  ungroup()

to_first <- tangram_change |> filter(earlier==0) |> ungroup()

to_last <- tangram_change |> filter(later==5) |> ungroup() |> 
  mutate(gameSize=as.factor(playerCond)) |> 
  rename(channel=channelCond)

to_last_model <- brm(sim ~ earlier*channel*gameSize*samespeaker,
                          #(repNum*channel*gameSize|tangram)+
                         # (1|tangram:gameId)+
                         # (repNum|gameId), 
                        data=to_last,
                        control=list(adapt_delta=.95),
                        file=here(model_location,"to_last_model_study3.rds"),
                        prior=sbert_priors)
```

```{r} 
read_rds(here(model_location,"div_model_study3_mix.rds")) |> summary()

read_rds(here(model_location,"tangram_model_study3_mix.rds")) |> summary()

read_rds(here(model_location,"to_last_model_study3.rds")) |> summary()



```

# tSNE 

```{r}
library(Rtsne)

for_Rtsne <- read_csv(here(data_location,"pre_sbert.csv")) |>   bind_cols(readRDS(here(data_location,'post_sbert.RData'))  %>% as_tibble()) |> mutate(feature_ind=row_number()) |> 
  filter(role=="speaker") |> 
  select(starts_with("V"), gameId,tangram, channelCond, playerCond, repNum, feature_ind)
```

```{r test}
test <- for_Rtsne |> filter(tangram=="C") #|> 
  #filter(channelCond=="thick") |> 
  #filter(playerCond==2)
set.seed(42)

a <- test |> select(starts_with("V")) |> Rtsne(check_duplicates=F)

b <- test |> select(-starts_with("V")) |> bind_cols(a$Y |> as.tibble()) |> 
  rename(x=V1, y=V2)

```

```{r}
library(useful)

do_rtsne_thing <- function(letter){
  test <- for_Rtsne |> filter(tangram==letter) 
set.seed(42)
a <- test |> select(starts_with("V")) |> Rtsne(check_duplicates=F)
b <- test |> select(-starts_with("V")) |> bind_cols(a$Y |> as.tibble()) |> 
  rename(x=V1, y=V2)

tsne_for_plot <- b |> select(gameId, tangram, channelCond, playerCond,repNum, x, y) |> 
  mutate(theta = useful::cart2pol(x, y) |> pull(theta)) %>%
  group_by(gameId,tangram, channelCond, playerCond) |> 
  arrange(repNum) |> 
  filter(repNum %in% c(0,5)) |> 
  mutate(finalTheta=last(theta),
         last_x=last(x),
         last_y=last(y),
         first_x=first(x),
         first_y=first(y),
         next_x=lead(x),
         next_y=lead(y))

plotted <-  ggplot(tsne_for_plot, aes(x = x, y = y, color = finalTheta)) +
  facet_grid(playerCond~channelCond)+
    geom_point(data = tsne_for_plot |> filter(repNum==0),
               size = 1) +
  #geom_segment(aes(xend=next_x, yend=next_y))+
    geom_segment(aes(x=first_x, y=first_y,xend = next_x, yend = next_y),
                 #alpha=.5,
                 arrow.fill = NULL,
                 arrow = arrow(length = unit(0.20,"cm"),
                               angle = 15,
                               type = "closed")) +
   # theme_few(20) +
    scale_shape_manual(values = c(21)) +
    scale_alpha_continuous(range = c(0.5, 1))+
    scale_color_gradientn(colours = viridis(5))+
      theme(axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank()) +
    labs(x = "", y = "") +
    guides(color = F, shape = F, alpha = F) +
    theme(aspect.ratio = 1)

  return(plotted)
}
```

```{r}
letters=c("A","B","C","D","E","F","G","H","I","J","K","L")
collect_plots=list()
i=0
for (letter in letters){
  i = i + 1
  
 collect_plots[[i]]=do_rtsne_thing(letter)
}

```
```{r}

for (i in 1:12){
  print(collect_plots[[i]])
}
```

```{r chaos, fig.width=10}
test <- for_Rtsne 
  #filter(channelCond=="thick") |> 
  #filter(playerCond==2)
set.seed(42)

a <- test |> select(starts_with("V")) |> Rtsne(check_duplicates=F)

b <- test |> select(-starts_with("V")) |> bind_cols(a$Y |> as.tibble()) |> 
  rename(x=V1, y=V2)


ggplot(b |> filter(repNum==0), aes(x=x, y=y, color=tangram))+geom_point(alpha=.2)+facet_grid(playerCond~channelCond)
```

```{r fig.width=5, fig.height=10}
ggplot(b |> filter(repNum==5), aes(x=x, y=y, color=tangram))+geom_point(alpha=.2)+facet_grid(tangram~str_c(playerCond, channelCond))+theme(legend.position = "none")
```

# PoS

```{r}
rounds_include <- read_rds(here(data_location,"rounds_include.rds"))

pos_raw <- read_csv(here(data_location,"PoSTagged.csv")) |> inner_join(rounds_include)
```
Sloppy first attempt -- we group by trial & speaker, summarize & pct-ize


ToDo the naive word count and the PoS sum are not always equal (off in both direction sometimes) -- some punctuation normalization may help?


Following Robert's analysis. First graph is raw-averages, second is grand-average (first do pcts for each speaker-trial, then do grand avg)

Diff between them shows that where there is more reduction, there is more noun-yness. 


```{r}

pos_raw |> 
  mutate(numWords= str_count(text, "\\W+") + 1) |> 
  filter(role=="speaker") |> 
  filter(!is.chitchat) |> 
  group_by(repNum,name) %>%
  summarize(numWords = sum(numWords),
            nouns = sum(NOUNcount)/sum(numWords),
            verbs = sum(VERBcount)/sum(numWords),
            dets= sum(DETcount)/sum(numWords),
            preps = sum(ADPcount)/sum(numWords),
            conjunctions_pronouns = (sum(CCONJcount) + sum(SCONJcount) +
                                       sum(PRONcount))/sum(numWords),
            adjectives = sum(ADJcount)/sum(numWords)) %>%
  mutate(OTHER = (1 - nouns - verbs - dets -conjunctions_pronouns -
                      preps - adjectives)) %>%
  gather(POS, prop, nouns:OTHER) %>%
  mutate(POS = factor(POS, levels = c('nouns',  'verbs', 'preps', 'adjectives',
                               'conjunctions_pronouns', 'dets', 'OTHER'))) %>%
  select(repNum, POS, prop, name,) %>%
  ggplot(aes(x = repNum, y = prop, fill = POS)) +
  facet_wrap(~name)+
    geom_area(alpha=0.6 , size=1, colour="black") +
    scale_fill_brewer(palette = "Set1")
   


pos_raw |> 
  mutate(numWords= str_count(text, "\\W+") + 1) |> 
  filter(role=="speaker") |> 
  filter(!is.chitchat) |> 
  group_by(repNum,name, playerId, trialNum) %>%
  summarize(numWords = sum(numWords),
            nouns = sum(NOUNcount)/sum(numWords),
            verbs = sum(VERBcount)/sum(numWords),
            dets= sum(DETcount)/sum(numWords),
            preps = sum(ADPcount)/sum(numWords),
            conjunctions_pronouns = (sum(CCONJcount) + sum(SCONJcount) +
                                       sum(PRONcount))/sum(numWords),
            adjectives = sum(ADJcount)/sum(numWords)) %>%
  mutate(OTHER = (1 - nouns - verbs - dets -conjunctions_pronouns -
                      preps - adjectives)) %>%
  group_by(name, repNum) |> 
  summarize(across(nouns:OTHER, mean)) |> 
  gather(POS, prop, nouns:OTHER) %>%
  mutate(POS = factor(POS, levels = c('nouns',  'verbs', 'preps', 'adjectives',
                               'conjunctions_pronouns', 'dets', 'OTHER'))) %>%
  select(repNum, POS, prop, name) %>%
  ggplot(aes(x = repNum, y = prop, fill = POS)) +
  facet_wrap(~name)+
    geom_area(alpha=0.6 , size=1, colour="black") +
    scale_fill_brewer(palette = "Set1")
    

pos_raw |> 
  mutate(numWords= str_count(text, "\\W+") + 1) |> 
  filter(role=="speaker") |> 
  filter(!is.chitchat) |> 
  group_by(repNum,name, playerId, trialNum) %>%
  summarize(numWords = sum(numWords),
            nouns = sum(NOUNcount)/sum(numWords),
            verbs = sum(VERBcount)/sum(numWords),
            dets= sum(DETcount)/sum(numWords),
            preps = sum(ADPcount)/sum(numWords),
            conjunctions_pronouns = (sum(CCONJcount) + sum(SCONJcount) +
                                       sum(PRONcount))/sum(numWords),
            adjectives = sum(ADJcount)/sum(numWords)) %>%
  mutate(OTHER = (1 - nouns - verbs - dets -conjunctions_pronouns -
                      preps - adjectives)) |> 
  ggplot(aes(x=numWords, y=nouns))+geom_jitter(alpha=.05)+facet_wrap(~name)+coord_cartesian(xlim=c(0,30))
```

# Emoji analysis


```{r}
rounds_include <- read_rds(here(data_location,"rounds_include.rds"))
d.round_results <- read_rds(here(data_location,"round_results.rds"))

d.listener <- read_csv(here(data_location,"raw_chat.csv")) %>% filter(role=="listener") |> inner_join(rounds_include) |> 
  filter(name %in% c("6_thin","2_thin"))

listeners <- d.round_results %>% select(gameId, trialNum, repNum, target, playerId, name) |> 
  filter(name %in% c("6_thin","2_thin"))
emoji <- d.listener %>% 
  select(gameId,repNum, target, playerId, text, trialNum, name) %>%
  mutate(emoji=case_when(
    text=="✅"~  "check",
    text=="🤔" ~ "think",
    text=="❌" ~ "x",
    text=="😂" ~ "lol",
  )) |> 
  full_join(listeners) |> group_by(gameId, trialNum, repNum, target, playerId, name, emoji) %>% 
  count() %>% 
  group_by(gameId, repNum, trialNum, target, playerId, name) %>% 
  pivot_wider(names_from=emoji, values_from=n, values_fill = 0) |> 
  rename(none="NA")
```
What fraction of listener-trials produce any emoji? (Grouped by game, but measured per listener)

```{r}
# rate of any emoji

emoji %>% mutate(total=lol+check+x+think, any=ifelse(total>0,1,0)) %>% 
  group_by(gameId,repNum, name) %>% summarize(any=mean(any)) %>% 
  ggplot(aes(x=repNum, y=any))+geom_jitter(width=.1, alpha=.5)+geom_smooth()+facet_grid(.~name)
```
Of emoji that are used, what's the distribution?

```{r}
group_emoji <- emoji %>% group_by(gameId, repNum, name) %>% 
  select(-target, -playerId, -none) %>% summarize(across(everything(), sum)) |> 
  mutate(total=lol+think+check+x,
         lol=lol/total,
         think=think/total,
         check=check/total,
         x=x/total) %>% 
  pivot_longer(c("lol","think", "check", "x"), names_to="emoji", values_to="pct")

ggplot(group_emoji, aes(x=repNum, y=pct, color=emoji, group=emoji))+geom_jitter(width=.1)+geom_smooth()+facet_grid(.~name)
```


```{r}
count_emoji <- emoji %>% group_by(gameId, playerId, repNum, name) %>% 
  select(-target,) %>% summarize(across(everything(), sum)) |> 
  pivot_longer(c("lol","think", "check", "x", "none"), names_to="emoji", values_to="count")

ggplot(count_emoji, aes(x=repNum, y=count, color=emoji, group=emoji))+geom_line(aes(group=playerId))+facet_grid(name~emoji)
```



A few people sent many copies of the same emoji over the course of a single trial which could sway things (see above graph), so we check by binarizing by did that listener produce that emoji on that trial and then summarizing. 

```{r}
count_emoji <- emoji %>% group_by(gameId, playerId, repNum, trialNum, name) %>% 
  select(-target, none) %>% 
    mutate(across(everything(), ~ifelse(.x>1,1,.x))) %>% 
  group_by(gameId, playerId, repNum, name) |> 
  summarize(across(everything(), sum)) |> 
  pivot_longer(c("lol","think", "check", "x", "none"), names_to="emoji", values_to="count")

ggplot(count_emoji, aes(x=repNum, y=count, color=emoji, group=emoji))+geom_line(aes(group=playerId), alpha=.5)+stat_summary(fun=mean, color="black", size=.1)+facet_grid(name~emoji)+scale_y_continuous(breaks=c(0,3,6,9,12))
```

```{r}
#outlier robustness
binary_emoji <- emoji %>% group_by(gameId, repNum, name) %>% 
  select(-target, -playerId, -none) %>% 
  mutate(across(everything(), ~ifelse(.x>1,1,.x))) %>% 
summarize(across(everything(), sum)) %>% 
  mutate(total=lol+think+check+x,
         lol=lol/total,
         think=think/total,
         check=check/total,
         x=x/total) %>% 
  pivot_longer(c("lol","think", "check", "x"), names_to="emoji", values_to="pct")

ggplot(binary_emoji, aes(x=repNum, y=pct, color=emoji))+geom_jitter(width=.1)+geom_smooth()+facet_grid(.~name)
```

# Throw all the models at this

Note, we're being quick and dirty here with lmer.




## log words


```{r}
d.chat <- read_rds(here(data_location, "chat.csv"))


for_graph <- d.chat %>% filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram, name) %>% 
  summarize(words=sum(total_num_words))

ggplot(for_graph, aes(x=repNum, y=log(words), color=name))+
  facet_wrap(.~name, nrow=1)+
  scale_color_brewer(palette="Dark2")+
    geom_line(aes(group=groupxtangram), alpha=.05,method=glm, se=F)+
    #geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian(link = 'log')))+
    geom_smooth(method=lm, alpha=.3)+
  theme(legend.position="null")

```
```{r}

chat_mod <- d.chat |> filter(role=="speaker") |>
  group_by(gameId, repNum, tangram, playerId, name) |> 
  summarize(words=sum(total_num_words)) |> 
  separate(name, into= c("gameSize","channel")) |> 
  mutate(log_words=log(words),
         log_block=log(repNum+1))

log_words <- lm(log_words ~ repNum*channel*gameSize,
                 data=chat_mod)

summary(log_words)
```

## log block

Reduction

```{r}
ggplot(for_graph, aes(x=log(repNum+1), y=words, color=name))+
  facet_wrap(.~name, nrow=1)+
  scale_color_brewer(palette="Dark2")+
    geom_line(aes(group=groupxtangram), alpha=.05,method=glm, se=F)+
    #geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian(link = 'log')))+
    geom_smooth(method=lm, alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
  theme(legend.position="null")

log_block_reduction <- lm(words ~log_block*channel*gameSize,
                          data=chat_mod)

summary(log_block_reduction)
```

Why not try log-log ? 


```{r}

ggplot(for_graph, aes(x=log(repNum+1), y=log(words), color=name))+
  facet_wrap(.~name, nrow=1)+
  scale_color_brewer(palette="Dark2")+
    geom_line(aes(group=groupxtangram), alpha=.05,method=glm, se=F)+
    geom_smooth(method=lm, alpha=.3)+
  theme(legend.position="null")
log_log_reduction <- lm(log_words ~log_block*channel*gameSize,
                          data=chat_mod)

summary(log_log_reduction)
```

Accuracy


```{r}
d.round_results <- read_rds(here(data_location,"round_results.rds"))

d.round_results %>% group_by(playerId,repNum, gameId, name) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  ggplot(aes(x=log(1+repNum), y=correct.num, color=name))+
geom_smooth(method = "lm") + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  #geom_point()+
  scale_color_brewer(palette="Dark2")+
  #scale_y_continuous(limits = c(0,1))+
  labs(x="Log Round Number", y="Fraction correctly selected", title= "Overall accuracy increases over repetitions", color="Player count")+
    theme(legend.position="bottom")

  
```

Note that this accuracy is of players who clicked something!

```{r}
acc_data <- d.round_results %>% select(playerId,repNum, gameId, name, tangram, response, correct) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
    separate(name, into= c("gameSize","channel")) |> 
  mutate(log_block=log(repNum+1))
  


log_block_accuracy <- glm(correct.num ~log_block*channel*gameSize,
                          data=acc_data, family="binomial")

summary(log_block_accuracy)
```