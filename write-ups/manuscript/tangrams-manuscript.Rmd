---
title: Interaction structure constrains the emergence of conventions in group communication

author:
  - name: Veronica Boyce
    email: vboyce@stanford.edu 
    affiliation:
      - Stanford 
    footnote:
      - corresp
  - name: Robert Hawkins
    affiliation: 
      - Stanford
  - name: Noah D. Goodman
    affiliation: 
      - Stanford
  - name: Michael C. Frank 
    affiliation: 
      - Stanford
address:
  - code: Stanford
    address: Stanford University 
footnote:
  - code: corresp
    text: "Corresponding author. Email: vboyce@stanford.edu"
bibliography: ["papers.bib"] # Replace with one or more of your own bibtex files. Better BibTeX for Zotero is your friend
csl: dmk-format.csl # Use any CSL style. See https://www.zotero.org/styles for a good list. Ignored if citation_package: natbib
link-citations: TRUE
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{angles,positioning,arrows.meta, quotes, shapes, shapes.geometric}
  - \usepackage{graphicx}
output:
  bookdown::pdf_document2:
    toc: FALSE
    keep_tex: TRUE
    template: generic_article_template.tex
    #md_extensions: "-autolink_bare_uris"
    number_sections: TRUE
    citation_package: default # Can also be "natbib"
lang: en # Main document language in BCP47 format
geometry: "margin=25mm"
papersize: a4
#linestretch: 2 # for double spacing
endfloat: FALSE # Set to TRUE to turn on latex endfloat package to place figures and tables at end of document
# endfloatoption: # See endfloat documentation for more possibilities
#   - tablesfirst # Default
#   - nomarkers # Default
numberlines: FALSE
authblk: TRUE # FALSE = author affiliations in footnotes; TRUE = author affiliations in a block below author names
footnotehyper: FALSE # TRUE will give you enhanced table footnote capabilities. Set to FALSE to be able to use French blocks. Needed due to what appears to be a latex bug.
urlcolor: blue
linkcolor: blue
citecolor: blue
graphics: TRUE # Needed to be able to include images
tables: TRUE # Needed to be able to include tables

---

<!---------------------- Abstract --------------------->

::: {.abstract data-latex="" lang=en}
reference games are used as test bed for convention formation 
real world has lots of non-dyadic communication, but it's mostly studied dyadically

we look at iterated reference games varying on size, backchannel, and group coherence (possibly match to title language) across NUMBER of games. 

takeaways? groups are successful even in larger groups and with less coherence, although group specific conventions form earlier/ more strongly in smaller or more coherent groups? idk what we want to top like to me, should probably figure out TODO
:::



<!------------ Main text -------------------->
 

```{r set-up, include=FALSE}
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())


knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.crop = F, out.width = "100%", dpi=300,
                      fig.pos = "tb", fig.path='figs/', fig.env="figure",
                      echo=F, warning=F, cache=TRUE, 
                      message=F, sanitize = T)

color_scheme_1 <- c("2"="#FFBDD4", "3"="#FF7DF0","4"="#D24AFF", "5"="#A12EFF","6"="#6940FF")
color_scheme_2 <- c( "6 single speaker"="#00A2FF","6 thin"="#D47E04","6 full feedback"="#425df5")

color_scheme_3 <- c("6 thin"="#D47E04", "6 thick"="#00BDA8",
                  "2 thin"="#FFDA09", "2 thick"="#77F3DB")


		
ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  |> 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"




image_location="write-ups/images"

msum_loc="code/paper_mods/summary"
mform_loc="code/paper_mods/formulae"

source(here("code/prep_ms.R"))

show_summary <- function(model){
  intervals <- gather_draws(model, `b_.*`, regex=T) |> mean_qi()
  
  stats <- gather_draws(model, `b_.*`, regex=T) |> 
    mutate(above_0=ifelse(.value>0, 1,0)) |> 
    group_by(.variable) |> 
    summarize(pct_above_0=mean(above_0)) |> 
   mutate(`P-value equivalent` = signif(2*pmin(pct_above_0,1-pct_above_0), digits=2)) |> 
    left_join(intervals, by=".variable") |> 
    mutate(lower=round(.lower, digits=2),
           upper=round(.upper, digits=2),
           `Credible Interval`=str_c("[",lower,", ", upper,"]"),
           Term=str_sub(.variable, 3, -1),
           Estimate=round(.value, digits=2)) |> 
    select(Term, Estimate, `Credible Interval`, `P-value equivalent`)
  
  stats
}

stats <- function(model, row){
  str_c(model[row,1],": ", model[row,2], " ", model[row,3])
}

stats_text  <- function(model, row){
  str_c( model[row,2],"  ",model[row,3])
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
  str_replace_all("\\*"," $\\\\times$ ") |> 
  str_replace_all("\\+", "&nbsp;+ ") |> 
   str_replace_all("~", "$\\\\sim$ ")
}
```

## intro take n+1
There are challenges associated with communicating in groups. People aren't on the same page; some have the background and want to hear about the new thing, others need the background repeated. Everyone tries to talk at once, resulting in confusion, or possibly side conversations reaching different conclusions. There may be disagreeing factions, who have different ideas about what is being decided and what the group is doing. There may even be meta-disagreements over how the group should be communicating. We've all been in these situations where having a conversation with a half-dozen people at once can devolve into chaos very quickly.

And yet, we do manage to communicate in groups, despite all of the these factors. We manage to catch people up, and we might define what we meant if there's confusion, until everyone is mostly in agreement about what we're talking about. We manage to identify misunderstandings and reach some sort of agreement sometime. We might resort to structuring the conversation, or we might even get knowledge transferred through the chaos. Group communication is a reality of being social beings. 

How do we do this? Unfortunately, despite the ubiquity of group conversations, most of the work on understanding conversation focuses on dyadic communication. 

TODO I don't like this b/c we can either link through size or through efficiency and idk how to do both: could go, well groups are hard, but there is a lot of work on dyads, so build from there. 

establishing reference is important to efficient communication
reference is well studied ex ex etc etc
one form of reference that is less controlled and introduces more of the messiness of working with differing backgrounds/priors is iterated reference game where there aren't clear pre-conventionalized names for objects or ideas, and instead of you to form an ad-hoc way of identifying them. 

This formation of partner-specific referring expression has been productively studied in dyads in foo bar paradigm
describe paradigm
in this paradigm, reduciton is a very robust effect 

so what about larger groups? how do they work and how do other variations factor in...

well, current work ....


One key requirement for efficient communication requires some sort of shared labels for the topics of conversation [@branigan2006;@ginzburg2005;@traum2004]. In many cases, there are widely shared conventionalized expressions for objects or ideas, but in other cases, spontaneous ad-hoc expressions must be invented.

The formation of these new reference expressions is well-studied in dyadic contexts and has been a case study for efficient communication more broadly. @clarkReferringCollaborativeProcess1986 established an experimental method for studying the emergence of new referring expressions that has now become standard [building on @kraussChangesReferencePhrases1964;@kraussConcurrentFeedbackConfirmation1966]. Two participants see the same set of figures; the speaker describes each figure in turn so the listener can select the target from the set of figures. The speaker and listener repeat this process with the same images over a series of blocks. Early descriptions are long and make reference to multiple features in the figure, but in later iterations, shorthand conventional names for each figure emerge; this shortening of utterances is called 'reduction'. 

Recently, online participant recruitment and web-based experiments have made it possible to study this convergence in larger populations [@hawkinsCharacterizingDynamicsLearning2020;@haber2019]. In line with results from face-to-face, oral paradigms, speakers reduced their utterances, producing fewer words per image in later blocks than in earlier blocks.^[Throughout this paper, we use "speaker" and "listener" to refer to the roles describing and selecting targets, regardless of communication modality.]

While this is well-explored in dyadic work, there are complexities to larger group interactions that are missing from dyadic interactions. 
One area of research is on iterated reference games, which look at how interlocuters develop a common language or set of conventions for how to refer to some images that do not come with obvious names to start with. Speakers must invent ad-hoc descriptions, and then come to mutual understanding with a listener or listeners about how these new labels relate to the objects. This formation of (temporary) convention is a useful microcosm for studying communication. 


Communication is a complex beast, so in studying it, researchers often focus on simple paradigms, such as reference games, where the goal of communicating is merely for one person to name or describe an object or image in a tableau so an interlocuter can pick it out. This framework is used productively to probe ideas such as ego-centrism, redundancy, etc etc [TODO list of topics and citations], but for the most part the reference literature has studied dyadic communication with just one speaker and one listener. 


Dyadic work with this paradigm is extensive, and has established that over repeated references to the same target images, dyads will reliably develop partner-specific conventionalized nicknames for the objects. 





## Current work

```{r count, include=F}
# TODO counts for all games
# For abstract (and elsewhere) count things!

games <- combined_results |> select(gameId) |> unique() |> nrow() # 98

players <- combined_results |> select(gameId, numPlayers) |> unique() |> summarize(players=sum(numPlayers)) # 390

words <- combined_chat |> ungroup() |> select(total_num_words) |> summarize(words=sum(total_num_words)) #116000

```




How does this process proceed in multi-party communication? In a dyad, speakers can tailor their utterances to the one listener, but in large groups, speakers must balance the competing needs of different listeners [@schober1989;@tolins2016]. These effects likely vary by both the knowledge state of and communication channels available to the listeners [@fox-tree2013;@horton2002; @horton2005]. 

In our current work, we test how the phenomena extend to larger games and games that vary in how coherent the group is and what communication channels are available to the listener. Using online recruitment and testing, we ran 3 experiments comprising `r players` participants across `r games` groups of 2--6 participants each, who collectively produced `r words` words of utterances. We analyse the results using traditional metrics of accuracy and number of words, and use new NLP tools to get at how the semantic content of utterances shifts over the course of games. 

TODO TOPLINE RESULTS??

topline results:

the characteristic reduction pattern is generally coupled with semantic convergence and divergence patterns. This set of phenomena emerge consistently across different conditions; people can form conventions and communicate effectively, even with larger groups or limited interactions and barriers to common ground. However, we see gradient effects where the less information is shared, whether via the confusion of more people or other structural factors, the harder it is, leading to weaker and slower convention formation. Stronger coherence can compensate for larger groups, whereas smaller groups can cope. 

other points to hit somewhere:
- not all or nothing, see gradient effects, but biggest is either all work or all but 6 thin work
- we have scale compared to some previous work 
- not just number of words, but some similarity between them which a) confirms a bunch of expected things, b) helps with dynamics and c) reveals possibility of reduction and specificity coming apart (but with lower success) 


```{=latex}

\definecolor{baseline6}{HTML}{6940FF}
\definecolor{baseline5}{HTML}{A12EFF}
\definecolor{baseline4}{HTML}{D24AFF}
\definecolor{baseline3}{HTML}{FF7DF0}
\definecolor{baseline2}{HTML}{FFBDD4}

\definecolor{thick6}{HTML}{00BDA8}
\definecolor{thick2}{HTML}{77F3DB}

\definecolor{thin6}{HTML}{D47E04}
\definecolor{thin2}{HTML}{FFDA09}

\definecolor{single}{HTML}{00A2FF}
\definecolor{full}{HTML}{425df5}

\definecolor{expt1col}{HTML}{FF0099}
\definecolor{expt3col}{HTML}{527319}
\definecolor{expt2col}{HTML}{0000FF}

\tikzset{
	expt1/.style={
		draw, circle, color=expt1col, line width=4, align=center, scale=2},
	expt2/.style={
		draw, circle, color=expt2col, line width=4,  align=center, scale=2},
	expt3/.style={
		draw, circle, color=expt3col, line width=4, align=center, scale=2},
		illus/.style={draw, rectangle}
}

\tikzset{nodes={font=\sffamily\bfseries}} 

\begin{figure}
	
	
	
	\begin{tikzpicture}
		
		\def\r{5}
		\draw (0,0) edge[-Stealth, line width=1] ["Backchannel", sloped, pos=.4] (-2*\r/5,  -2*\r/3) ;
		\draw (0,0) edge[-Stealth, line width=1] ["Group Size", pos=1.05] (\r, 0) ;
		\draw (0,0) edge[-Stealth, line width=1] ["Group coherence", sloped, pos=.4] (0, \r);
		
		\node (n2) at (0,0) [expt1, fill=baseline2, label={[expt1col]below:2}] {};
		\node (n3) at (1,0) [expt1, fill=baseline3, label={[expt1col]below:3}]{};
		\node (n4) at (2,0) [expt1, fill=baseline4, label={[expt1col]below:4}] {};
		\node (n5) at (3,0) [expt1, fill=baseline5, label={[expt1col]below:5}] {};
		\node (n6) at (4,0) [expt1, fill=baseline6] {};
		\node[align=center,anchor=north,text=expt1col] at (4.6,-.45) {6 baseline};
		
		\node (n2thick) at (0,4) [expt3, fill=thick2, label= {[expt3col]above right:2 thick}] {};
		\node (n6thick) at (4,4) [expt3, fill=thick6, label={[expt3col]right:6 thick}] {};
		
		\node (nfull) at (4,1.5) [expt2, fill=full, label={[expt2col]right:6 full feedback}] {};
		\node (nsingle) at (4,3) [expt2, fill=single, label={[expt2col]right:6 single speaker}] {};
		
		\node (n2thin) at (-3/2,-5/2) [expt3, fill=thin2, label={[expt3col]below right: 2 thin}] {};
		\node (n6thin2) at (2.7,-2.3) [expt2, fill=thin6, label={[expt2col] right: 6 thin}] {};
		\node (n6thin) at (2.5,-2.5) [expt3, fill=thin6, label={[expt3col]below right: 6 thin}] {};
		
		\node[align=center,anchor=north] (lab1) at (-2,3) {Rotating speaker;\\limited feedback};
		\node[align=center,anchor=north] (lab2) at (-1.5,6) {Single speaker;\\full feedback};
		\node[align=center,anchor=north] (lab3) at (-3,0.2) {Listeners \\use chat};
		\node[align=center,anchor=north] (lab4) at (-3.5,-2) {Listeners \\use emoji};
		
		\node[align=center,anchor=north, text=expt1col] (ex1) at (2,1) {Experiment 1};
		\node[align=center,anchor=north, text=expt2col] (ex1) at (2,2.75) {Experiment 2};
		\node[align=center,anchor=north, text=expt3col] (ex1) at (.7,-1.7) {Experiment 3};
		
	 \node[illus, anchor=north] () at (-3.5,-3.5) {  \includegraphics[height=2.5em]{images/nochat.png}};
	\node[illus, anchor=north] () at (-3.3,-.7) {\includegraphics[height=2.5em]{images/chat.png}};
	
	\node[illus, anchor=north] () at (-3.35,2) {\includegraphics[height=3em]{images/rotate.png}};
	\node[illus, anchor=north] () at (7.5,4.8) {\includegraphics[height=3em]{images/norotate.png}};
	
	
	\node[anchor=north] () at (-1,.7) {\includegraphics[height=1.5em]{images/two.png}};
	\node[ anchor=north] () at (6.8,.8) {\includegraphics[height=2em]{images/six.png}};
	
	\node[illus, anchor=north] () at (-4.3,4) { \includegraphics[height=4em]{images/limited-wrong.png}    %\includegraphics[scale=.1]{images/limited-correct.png}
	};
	\node[illus, anchor=north] () at (8,2.5) {  \includegraphics[height=4em]{images/full-wrong.png}   %\includegraphics[scale=.1]{images/full-correct.png}
		};
		
		\draw[dashed] (n6) edge [] (n6thin);
		\draw[dashed] (n2thin) edge [] (n6thin);
		\draw[dashed] (n2thick) edge [] (n6thick);
		\draw[dashed] (n6) edge [] (n6thick);
		
		
		\node[illus, anchor=north west] () at (4.75, -1.5) {\includegraphics[width=15em]{images/diagram.png}};
		\node[anchor=north west] () at (7, -1) {Trial};
		
		\node[illus, anchor=north west, minimum width=18.5em, minimum height=14.5em] (block) at (4.5, -1) {};
		\node[anchor=north west] () at (7, -.5) {Block};
		\node[anchor=north west] () at (8.5, -5.5) {x 12 images};
		\node[anchor=north west] () at (8.5, -6.1) {x 6 iterations};
		
		\begin{scope}[line width=1 pt, >=Stealth]
			\draw[->] (lab1) -> (n2);
			\draw[->] (lab2) -> (n2thick);
			\draw[->] (lab3) -> (n2);
			\draw[->] (lab4) -> (n2thin);
			
		\end{scope}
		
		
		
	\end{tikzpicture}
	
\caption{ Diagram of the experimental space explored in these experiments. Experiment 1 (pink) has a backchannel where listeners can use the chat and low group coherence from a rotating speaker and limited feedback. Experiment 1's conditions vary the group size from 2 - 6 players. Experiment 2 (blue) games keep group size constant at 6 and vary along the other dimensions. 6 single speaker and 6 full feedback each add one component of group coherence relative to experiment 1. 6 thin varies the backchannel (relative to experiment 1) by having listeners communicate with emoji rather than the full text chat the speaker uses. Experiment 3 (green) tests 4 corners of the space, crossing group size (2 or 6 players) with thin games that have low group coherence and low backchannel or thick games that have high group coherence and high backchannel.  The not-yet-an-inset shows the structure of the experiment, each trial a speaker describes a target image to the listeners, and this process repeats for all 12 images to comprise a block, and the block repeats for a total of 6 iterations. TODO FIX ME AND MY ILLUSTRATION!!! }
	\label{diagram}
\end{figure}

```

# Results

Across the three experiments and multiple conditions, all iterated reference games shared the same structure amd materials so they are inter-comparable. As shown in Figure \ref{diagram}, all of the games used 12 target images arranged in a grid differently for each player [@hawkinsCharacterizingDynamicsLearning2020; @clarkReferringCollaborativeProcess1986]. The speaker knew which image was the target, and their goal was to describe it to their groupmates (listeners) over a chat interface so each listener could select the target. After all listeners had selected, players recieved feedback on the selections. This repeated for all the images with the same speaker to comprise a 12 trial block. Then the whole process repeated for a total of 6 blocks. [TODO possibly can reduce this depending on what's in intro]. 

We extended on the dyadic paradigm of @hawkinsCharacterizingDynamicsLearning2020 by parameterizing the experiments along a few dimensions (see Figure \ref{diagram}). One dimension was game size which varied between 2 and 6 player groups; this explores the gradual effects having a larger audience. Another dimension was group coherence, which was made up of two components: speaker rotation and feedback. In low group coherence games, the speaker rotated each block, while in high group coherence games, one player was the speaker for the entire game. Rotating speakers is a more stringent test of convergence because it compares utterances from different players, but having a single speaker gives one person the job of paying attention to what people understand, which could help hold the group together. In low group coherence games, each listener only recieved feedback on if they were indiviually right or wrong in their selection, while in high group coherence games, listeners (like the speakers in all games) saw who had selected what and what the target had been, thus ensuring people saw what referent was intended and had a sense of how everyone else was doing. The last dimension of variation was listener backchannel: in high backchannel games, the listeners could freely send (text) messages to the shared chat, while in the low backchannel games, listeners could send 4 discrete messages (represented as emojis) to the chat. This dimension was inspired by the claimed importance of listener contributions to convention formation [TODO CIATIONS]

As shown in Figure whatever, Experiment 1 had constant low group coherence and high listener backchannel while varying group size. Experiment 2 held group size constant at 6 and each condition deviated from experiment 1 in one aspect: 6 single speaker and 6 full feedback changed components of group coherence and 6 thin had a low backchannel. Experiment 3 tested 4 corners of the experimental space at larger scale, with thin (low backchannel, low coherence) and thick (high backchannel, high coherence) games with either 2 or 6 players. 

We first compare the results on two behavioral measures of listener accuracy and speaker reduction of words that have been the common markers of reduction phenomena in the literature [CITE]. We then explore semantic patterns of reduction by comparing similarities of utterances to look at how the speaker's language changes within and between games over time. 

## Behavioral results

The two key behavioral outcomes were how accurately listeners selected the target images and how many words the speaker produced each trial.

```{r behavioral, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Behavioral results across all three experiments. A. Listener accuracy at selecting the target image. Dots are per condition, per block estimates with 95\\% bootstrapped CIs. Smooths are binomial fit lines. B. Number of words said by the speaker each trial. Faint dots represent individual trials from individual games. Smooths are quadratic fit lines. Y-axis is truncated, and a few outliers points are not visible. "}
# accuracy

# 1
one <- combined_results |> filter(condition=="rotate") |> group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(numPlayers=as.character(numPlayers)) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=numPlayers))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
  annotate("text", x=3.5,y=1,label="Experiment 1", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_1)
#2

two <- combined_results |> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
    annotate("text", x=3.5,y=1,label="Experiment 2", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
        scale_color_manual(values=color_scheme_2)

#3
 three <- combined_results |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> group_by(playerId,repNum, gameId, condition) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |>
   mutate(condition=str_replace(condition, "_", " ")) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
     annotate("text", x=3.5,y=1,label="Experiment 3", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
   scale_color_manual(values=color_scheme_3)
 
 acc <- plot_grid(one, two, three, nrow=1)
 

#1

one <- combined_chat |> filter(condition=="rotate") |>  filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, numPlayers) |> 
  summarize(words=sum(total_num_words)) |>
    mutate(numPlayers=as.character(numPlayers)) |> 
ggplot(aes(x=repNum+1, y=words, color=numPlayers))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=60,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- combined_chat|> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram,condition) |> 
  summarize(words=sum(total_num_words)) |> 
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |>
ggplot(aes(x=repNum+1, y=words, color=condition))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
annotate("text", x=3.5,y=60,label="Experiment 2", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
    scale_color_manual(values=color_scheme_2)

#3


three <- combined_chat |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, condition) |> 
  summarize(words=sum(total_num_words)) |> 
  mutate(condition=str_replace(condition, "_", " ")) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
  geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
annotate("text", x=3.5,y=60,label="Experiment 3", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

red <- plot_grid(one,two, three, nrow=1)

plot_grid(acc, red, nrow=2, rel_heights = c(.8,1), labels="AUTO", label_size=20)
```



```{r}
acc_1 <- read_rds(here(msum_loc,"acc_1.rds"))

acc_2a <- read_rds(here(msum_loc,"acc_2a.rds"))

acc_2b <- read_rds(here(msum_loc,"acc_2b.rds"))

acc_2c <- read_rds(here(msum_loc,"acc_2c.rds"))

acc_3 <- read_rds(here(msum_loc,"acc_3.rds"))

```

Listeners selected the correct target far above chance in every condition, and in every condition, listener accuracy rose over the course of the game (Figure \@ref(fig:behavioral)A). Experiment 1 found no strong effects of group size on overall accuracy (`r stats(acc_1,4)`) or improvement rate (`r stats(acc_1,2)`). In experiment 3, participants in six player games were less accurate (`r stats(acc_3, 6)`) and slower to improve (`r stats(acc_3, 3)`) than players in 2 player games, but thin versus thick games did not have a clear effect on accuracy  (`r stats(acc_3,2)`) or improvement rate (`r stats(acc_3, 2)`). The high and increasing levels of accuracy indicate that across all of these conditions, participants are able to play the game and succeed in communicating about the images. 





```{r}
red_1 <- read_rds(here(msum_loc, "red_1.rds"))

red_2a <- read_rds(here(msum_loc,"red_2a.rds"))

red_2b <- read_rds(here(msum_loc,"red_2b.rds"))

red_2c <- read_rds(here(msum_loc,"red_2c.rds"))

red_3 <- read_rds(here(msum_loc, "red_3.rds"))

```

The key observation in iterated reference games is that the descriptions the speaker gives of the target images start out long and become shorter over the course of repetitions. This pattern of reduction held across all conditions, with the numbers of words from the speaker decreasing over blocks (Figure \@ref(fig:behavioral)B), although there were substantial differences in how verbose speakers were across games. In experiment 1, the overall effect of being one block later was `r stats_text(red_1,1)` words. Speakers in larger groups said more; the effect of each additional player was  `r stats_text(red_1,4)` words per trial, with no clear interaction between block and group size (`r stats(red_1,2)`). In experiment 2, the result of being one block later on the number of words the speaker said per trial was `r stats(red_2a,1)` for 6 single speaker; `r stats(red_2b,1)` for 6 full feedback, and `r stats(red_2c,1)` for 6 thin. The rate of reduction was lower in the thin condition than in the other conditions. In experiment 3, reduction occurred overall (`r stats(red_3,1)`). The six player games said more to start with (`r stats(red_3, 7)`) and reduced less (`r stats(red_3, 4)`) than the two-player games. There were not significant differences due to channel type (`r stats(red_3, 5)`) or channel type over time (`r stats(red_3, 2)`). 

TODO possibly say more about group to group variation 

These reduction results confirm and extend what was previously known for 2 player games. Behaviorally, larger games are similar to smaller games, but their speakers tend to say more overall, perhaps related to the increased number of listeners to respond to. 

What about the listeners? Compared to how much referential language speakers produce, listeners produce very little, and it is concentrated in the early rounds. TODO say more about listener language including some numbers!!!

<!-- more about listner lang


should do total lang/game (including zeros) on chat conditions listeners don't use that much contentful language ever and it declines quickly 

not sure what to say about non-contentful language use? such as yup / got it and chitchat maybe helpful to speaker (or not) and overlaps other channels. 

Not sure how to talk about emoji since they do get used -- maybe say the do get used, generally used on each trial, but not a direct comparison to contentful language? 



notes: this is a slightly unfair comparison, since it's the filtered chat for the chat ones, but raw emojis for the others which might actually map to the "got it" chitchat. Resolve later.

While listener backchannel is implicated as an important way for listeners to get clarification and reach agreement, listeners don't talk that much. The average number of words of reference language per trial per listener (counting those who say nothing) is less than 5 words TODO real numbers for the first block and declines in later blocks. 
Listeners don't talk very much

Key points about listener talking: They don't do it very much, but they do it a bit. Especially early in the game. Over the course of the game the amount of time any listener talks at all declines, as does the amount that is said. 

-->


## Comparisons of language between and within games


```{=latex}

\begin{figure}


        \definecolor{div}{HTML}{006400}
\tikzset{
mynode/.style={
draw, rectangle, align=center,  text width=4cm, scale=1, font=\small, inner sep=.5ex, anchor=north east},
}

\begin{tikzpicture}
\node[mynode] (a0) at (1.5, 9.6) {\textbf{Round 1:} stomping feet, head is not the highest point of the picture - maybe a shoulder is at the same height, both feet point left};
\node[mynode] (a1) at (1.5, 7.1)  {\textbf{Round 2:} diamond head is almost on back and on right side of body; both feet are pointing left
};
\node[mynode] (a2) at (1.5, 5.4)  {\textbf{Round 3: }sad guy with square backpack, feet to the left
};
\node[mynode] (a3) at (1.5, 4.1) { \textbf{Round 4:} stomping feet pointing left; square backpack on right; nose pointing down on left
};
\node[mynode] (a4) at (1.5, 2.4) { \textbf{Round 5:} sad guy with backpack, legs to the left
};
\node[mynode] (a5)  at (1.5,1.4) {\textbf{Round 6:} sad guy with backpack, legs to the left
};

\node[mynode] (b0) at (-3.5,9.6) {\textbf{Round 1:} like someone dancing, with one foot on the ground and one up a little, facing left, like a head yes, like they are kind of leaning back, foot sticking out a little to the left};
\node[mynode] (b1) at (-3.8,6.6)  {\textbf{Round 2:} Like a man facing left marching with a flag over his shoulder, Face is pointy looking down
};
\node[mynode] (b2) at (-4.1,4.7) {\textbf{Round 3:} looking to the left one leg up pointy face
};
\node[mynode] (b3) at (-4.4,3.6) {\textbf{Round 4:} man marching with flag over shoulder
};
\node[mynode] (b4) at (-4.7,2.5)  { \textbf{Round 5:} marching man with flag over shoulder
};
\node[mynode] (b5)   at (-5,1.2) { \textbf{Round 6:} flag bearer};


\node[align=center, color=blue, anchor=north west] at (-10.5,10) {\textbf{Convergence} \\ \textbf{within a game}};
\node[align=center, color=div, anchor= north west] at (-5,10) {\textbf{Divergence between games}}; 

\node[] at (-10,8) {\includegraphics[width=4em]{images/tangram_A.png}};
	\begin{scope}[line width=1 pt, >=Stealth]
	%\draw [<->]   (a0.west) edge [out=230, in=150] node {.23}  (a5.west);
	%\draw [<->]   (a1.west) edge [out=210, in=150] node [left]{.13} (a5.west);
	%\draw [<->]   (a2.west) edge [bend right] node [left] {.92}(a5.west);
	%\draw [<->]   (a3.west) edge [out=210, in=90] node [left] {.47} (a5.west);
	%\draw [<->]   (a4.south) edge  node [left] {.91} (a5);
	
	\draw [<->, color=blue]   (b0) edge [out=180, in=200] node [inner sep=2ex, left, pos=.1]{.13}  (b5.south west);
	\draw [<->, color=blue]   (b1) edge [out=180, in=200] node [inner sep=3ex, left, pos=.1]{.53}  (b5.west);
	\draw [<->, color=blue]   (b2) edge [out=180, in=150] node  [inner sep=4ex, left, pos=0]{.13}  (b5.west);
	\draw [<->, color=blue]   (b3) edge [out=180, in=150] node [inner sep=3ex, left, pos=0] {.62} (b5.north west);
	\draw [<->, color=blue]   (b4.west) edge [out=270, in=90]node [inner sep=.5ex, left, pos=0]{.63} (b5.north west);
	
	\draw [<->, color=div]   (a0) edge [pos=.5, ".59"] (b0);
	\draw [<->, color=div]   (a1) edge [pos=.8, ".29"] (b1);
	\draw [<->, color=div]   (a2) edge [pos=.8, ".48"] (b2);
	\draw [<->, color=div]   (a3) edge [pos=.5, ".28"] (b3);
	\draw [<->, color=div]   (a4) edge [pos=.5, ".32"] (b4);
	\draw [<->, color=div]   (a5) edge [pos=.5, ".06"] (b5);
	

	
\end{scope}

\end{tikzpicture}
\label{sbert-diagram}
\caption{Example utterances describing the shown tangram figure produced by two 3-player games in Experiment 1. To measure convergence within a game (blue), we measured the cosine similarity between SBERT embeddings of descriptions and the embedding of the round 6 utterance (taken to be the convention). Higher cosine similarity indicates more similar meaning. To measure divergence between games (green), we measured the similarity between utterances from the same round across games.}
\end{figure}
```

In addition to behavioral measures, we can also look at how the descriptions change over time within and between games. The reduction phenomenon is supposed to be a proxy and correlate of a conventionalization of meaning, to something specific to the pair or group. To quantify this and test the relationships of utterances bewteen and within games, we focus on the speaker's description, concatentating it all together into one utterance (this includes any add ons or answers to questions). Then we use SBERT to embed the utterance in a high-dimensional vector space TODO CITATION. This turns each speaker description into a long vector, where the vectors represent some of the semantic content of the utterance. Vectors that are close together represent utterances that are more similar to one another, so by looking at cosine similarity (a metric of how close pairs of vectors are) we can see how similar pairs of utterances are. 

As a measure of convention formation, we can track how utterances describing the same tangram become increasingly similar over the course of a game. If conventions are forming we expect the similarity to the last block utterance to increase over the course of the game. 

If different games go in different directions with their descriptions, we'd expect this similarity between descriptions of the same image in different games to decrease over repetitions. Example utterances and their similiarities are illustrated in Figure \ref{sbert-diagram}. 

```{r sbert, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Language similarity results measured with pairwise cosine similarity between embeddings of two utterances. A. Convergence of utterances within games as measured by similarity between an utterance from block 1-5 to the block 6 utterance in the same game for the same image. Dots are per-game averages, smooths are quadratic. B. Divergence of utterances across games as measured by the similarity between an utterances and utterances produced for the same image by different groups in the same block. Dots are per-image averages, smooths are quadratic."}
#convergence

one_two_converge <- read_rds(here("code/models/one_two_converge.rds"))
three_converge <- read_rds(here("code/models/three_converge.rds"))
#1
one <- one_two_converge |> filter(condition %in% c("2", "3","4","5","6")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3,y=1,label="Experiment 1", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- one_two_converge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3,y=1,label="Experiment 2", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+    scale_color_manual(values=color_scheme_2)



#3



three <- three_converge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |>  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3,y=1,label="Experiment 3", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

conv <- plot_grid(one, two, three, nrow=1)

one_two_diverge <- read_rds(here("code/models/one_two_diverge.rds"))
three_diverge <- read_rds(here("code/models/three_diverge.rds"))
# divergence

#1
one <-  one_two_diverge |> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=.7,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_diverge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
                              ggplot( aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
      coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=.7,label="Experiment 2", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_diverge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |> ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=.7,label="Experiment 3", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_3)

div <- plot_grid(one,two,three, nrow=1)

plot_grid(conv, div, nrow=2, labels="AUTO", rel_heights = c(.8,1), label_size=20)
```


```{r}
tolast_1 <- read_rds(here(msum_loc, "tolast_1.rds"))

tonext_1 <- read_rds(here(msum_loc, "tonext_1.rds"))

tolast_2a <- read_rds(here(msum_loc, "tolast_2a.rds"))

tonext_2a <- read_rds(here(msum_loc, "tonext_2a.rds"))

tolast_2b <- read_rds(here(msum_loc, "tolast_2b.rds"))

tonext_2b <- read_rds(here(msum_loc, "tonext_2b.rds"))

tolast_2c <- read_rds(here(msum_loc, "tolast_2c.rds"))

tonext_2c <- read_rds(here(msum_loc, "tonext_2c.rds"))

tolast_3 <- read_rds(here(msum_loc, "tolast_3.rds"))

tonext_3 <- read_rds(here(msum_loc, "tonext_3.rds"))

```

We first look at convergence, comparing utterances from the first 5 rounds of a game to the "convention" or round 6 utterance for the same figure. As visible in Figure \@ref(fig:sbert)A, similarity the last utterances occurs across all conditions. In experiment 1, the similarity of the first utterance to last utterances is invariant across group size (`r stats_text(tolast_1, 1)`), but smaller groups converge faster (`r stats_text(tolast_1, 3)`). Experiment 2 shows similar patterns of utterances become more similar to the last utterance, particularly in the single speaker condition (`r stats_text(tolast_2a, 1)`) where all the utterances come from the same person, but also in the full feedback condition (`r stats_text(tolast_2b, 1)`) and to a smaller extent, in the thin condition (`r stats_text(tolast_2c, 1)`). In experiment 3, convergence is slower in thin games than thick games (`r stats_text(tolast_3, 4)`) and especially thin 6 player games (`r stats_text(tolast_3, 5)`). 

Not only do groups reduce the lengths of their utterances, but each group is converging towards a semantic description for the figures. This is more prominent in smaller games and games with greater group coherence. 


```{r}
div_1 <- read_rds(here(msum_loc, "div_1.rds"))

div_2a <- read_rds(here(msum_loc, "div_2a.rds"))

div_2b <- read_rds(here(msum_loc, "div_2b.rds"))

div_2c <- read_rds(here(msum_loc, "div_2c.rds"))
div_3 <- read_rds(here(msum_loc, "div_3.rds"))
```

The complement to convergence within groups is divergence between groups, as different groups develop their own ways of identifying the different figures. In experiment 1, descriptions become less similar to those used to describe the same figure in other games (`r stats_text(div_1, 1)`). Group size does not affect the cross-groups similarities in the first block (`r stats_text(div_1, 3)`), but smaller groups diverge from each other faster than larger groups (`r stats_text(div_1,2)`). In experiment 2, divergence is stronger in the single speaker (`r stats_text(div_2a, 1)`) and full feedback conditions (`r stats_text(div_2b, 1)`) than in the 6 thin condition (`r stats_text(div_2c, 1)`). In experiment 3, descriptions from different games get less similar over time (`r stats_text(div_3, 1)`). There are slight differences in the initial starting points across the different conditions, as well as slight condition differences in how fast the games diverge. In particular, 6 player thin games diverge more slowly (`r stats_text(div_3, 3)`). 

TODO possibly say more about 6 thin and check modelling issues

Comparing embeddings of utterances also gives more details. As shown in Appendix figure, the similarity the last utterance can be seen as the cumulative similarities of consecutive utterances. Over time adjacent utterances become more similar as the utterances converge closer to a convention. As group narrow in on descriptions for each image, names for tangrams become more distinctive. While initially, many tangrams might be described in terms of shapes or body parts and directions, as the get nicknames, they differentiate more (See supp figure). All of these confirm expected patterns. 


TODO say more about this 



### TODO there's a note saying to rerun these models for longer with more extensive mixed effects!! (at least of reduction model)






# General Discussion

this isn't the only group dynamic; could imagine situations where listeners can see each others work collaborate (point to each other what htey think, perhaps see feedback from speaker to one listener) which might make things reduce much faster


The emergence of conventions has been a key case study for communication more broadly. Yet this issue has -- for the most part -- been studied only in dyadic communication. While some studies have examined aspects of convention formation in larger groups [e.g., @yoonAdjustingConceptualPacts2014;@yoonAudienceDesignMultiparty2019], basic descriptive work has not yet investigated how group size changes the dynamics of interaction in a standard referential communication task, in part because such tasks can be difficult to administer to larger groups. Taking advantage of a new online multi-player experiment platform, we ran repeated reference games with groups of 2--6 players and characterized the nature of group performance.

Consistent with dyadic games, listeners' selection accuracy increased over blocks at the same time as listeners sped up their selections (question 1). 
Crucially, speakers reduced the length of their descriptive utterances as they conventionalized on concepts for each image (question 2). Because speakers rotated, this reduction finding is robust: not only did speakers say less in later repetitions than they themselves said earlier, speakers later in the order said less than speakers earlier in the rotation. This reduction varied with group size; smaller groups used shorter utterances, but group size did not significantly interact with block (question 3). The trajectory of reduction also depended on whether the current speaker correctly identified the tangram in the prior block and whether the current speaker was new to being speaker. This pattern is consistent with both the 'aim low' and 'aim middle' hypotheses from previous work [@yoonAdjustingConceptualPacts2014;@yoonAudienceDesignMultiparty2019].

What was specifically different across group sizes? Smaller groups showed more agreement in how each tangram was identified across blocks (question 4), coming to consensus earlier: Their overlap between descriptions in the first 5 blocks to the final block was higher, and words in the final block tended to originate earlier. The greater diversity in how tangrams were described in larger groups could be explained by slower convergence to a convention or parallel competing conceptualizations favored by different speakers. Larger groups have more people for the speaker to communicate to, but also more people who might interrupt with questions, and more people who have opinions about what each image looks like. Bigger groups differ from smaller groups in a number of ways, however, and disentangling these differences is an area for future work. 

<!-- ## Limitations -->

Group interactions are rich, and this experiment is necessarily a schematic simplification with a number of limitations. Real-life situations vary widely in who the interlocuters are, their relationships, their goals, and their environment [@fay2000;@carletta1998]. Our participants were a convenience sample of Prolific workers who were strangers to each other; thus we miss richness that could come from prior relationships or shared community.  Reference is only one goal out of many possible communicative goals, and the tangram images are artificial. 
We provided less feedback than previous studies such as @hawkinsCharacterizingDynamicsLearning2020; this regime imitates situations where interlocutors can't show each other examples, but it's not representative of all communicative environments. Further, our text-based online paradigm meant that participants' individual identities were not especially salient. In sum, communication takes place in a plethora of situations; our experiment provides some insights, but also misses many complexities that should be a focus of further experiments. 

<!-- ## Future work -->

The experimental paradigm presented here could be a valuable tool to disentangle the mechanisms of group size and determine which design parameters are relevant to reduction. Luckily, with an online implementation, recruiting for and running experiments is feasible, and thus it will be possible to iterate on this experiment to determine how far the patterns generalize. While much is left to be explored, this initial data set provides a rich corpus of how humans adapt language dynamically to communicate. 

## Limitations

# Methods

We extended the dyadic repeated reference game paradigm of @hawkinsCharacterizingDynamicsLearning2020 along a few dimensions. As diagrammed in Figure \ref{diagram}, three dimensions of variation we considered were group size, listener backchannel, and group coherence. In experiment 1, we expanded from dyadic reference games to group games with 2--6 players who rotated between speaker and listener roles. In experiment 2, we built on the 6 player games by exploring three variations, two which increased group coherence by increasing feedback to listeners or having a single speaker for the entire game, and one that reduced the listener backchannel. For experiment 3, we considered the extremes of group size and performance, informed by the prior experiments. The thin channel repeated the reduced-backchannel, low-group coherence condition, and we created a thick channel by combining the two sources of group coherence together. We then crossed these thick and thin condition with groups of 2 and 6 players and collected more data in each of these conditions. 

For all experiments, we used Empirica [@almaatouqEmpiricaVirtualLab2020] to create real-time multi-player reference games. In each game, one of the players started as the speaker who saw an array of tangrams with one highlighted (Figure \ref{game}A) and communicated which figure to click to the other players (listeners). After the speaker had identified each of the 12 images in turn, the process repeated with the same images, but a total of 6 blocks (72 trials). We recorded what participants said in the chat, as well as who selected what image and how long they took to make their selections. 

These experiments were designed sequentially and pre-registered individually.^[Experiment 1: https://osf.io/cn9f4 for the 2-4 player groups, and https://osf.io/rpz67 for the 5-6 player data run later. Experiment 2: single speaker at  https://osf.io/f9xyd, full feedback at  https://osf.io/j5zbm, and thin at  https://osf.io/k5f4t. Experiment 3: https://osf.io/untzy] TODO more comments on pre-reg

## Participants
```{r participants}

players <- combined_results |> mutate(realPlayer=ifelse(is.na(activePlayerCount), numPlayers, activePlayerCount),
                                       numPlayers=ifelse(condition %in% c("6_thin", "6_thick"), "6*", as.character(numPlayers))) |> group_by(condition, numPlayers, gameId) |> summarize(count=max(realPlayer)) |> group_by(condition, numPlayers) |> summarize(`Total Participants`=sum(count))

summary <- combined_results |> group_by(condition, trialNum, repNum, gameId, numPlayers) |> 
  mutate(numPlayers=ifelse(condition %in% c("6_thin", "6_thick"), "6*", as.character(numPlayers))) |> 
  group_by(gameId, numPlayers, condition) |> 
  summarize(num_trials=max(trialNum)) |> 
  arrange(numPlayers) |> 
  mutate(complete=ifelse(num_trials==71,T,F)) |> 
  group_by(numPlayers,complete, condition) |> 
  tally() |> 
  pivot_wider(names_from=complete, values_from=n) |> 
    left_join(players) |> 
  rename(Players=numPlayers,Complete=`TRUE`, Partial=`FALSE`) |> 
  mutate(Partial=ifelse(is.na(Partial), 0, Partial)) |> 
  mutate(Experiment=factor(condition, levels=c("rotate","no_rotate","full_feedback", "emoji", "2_thin", "6_thin", "2_thick", "6_thick"),
                          labels=c("1: baseline", "2: single speaker", "2: full feedback", "2: thin", "3: thin", "3: thin", "3: thick", "3: thick"))) |> 
  select(Experiment, Players, Complete, Partial, `Total Participants`) |> 
  arrange(Experiment, Players,Complete,Partial, `Total Participants`)

knitr::kable(summary, caption="The number of games in each experiment and condition. Complete games finished all 6 blocks; partial games ended early due to disconnections, but contributed at least one complete block of data. 6* indicates that some games started with fewer than 6 players or continued with fewer than 6 players after participants disconnected.")
```

Participants were recruited using the Prolific platform, and all participants self-reported as fluent native English speakers on Prolific's demographic prescreen. Participants each took part in only one experiment. Experiment 1 took place between May and July 2021, experiment 2 between March and August 2022, and experiment 3 in October 2022. As games varied in length depending on the number of participants, we paid participants based on group size, with the goal of a \$10 hourly rate.  Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, \$10 for 4-player games, and \$11 for 5- and 6-player games. When one player had the speaker role for the entirety of a 6-player game, they gained an addition \$2 bonus. Across all games, each participant could early up to \$2.88 in performance bonuses. A total of 1319 people participated across the 3 experiments. A breakdown of number of games and participants in each condition is shown in Table \@ref(tab:participants). 

## Materials

We used the 12 tangram images used by @hawkinsCharacterizingDynamicsLearning2020 and @clarkReferringCollaborativeProcess1986 (see Figure \ref{game}). These images were displayed in a grid with order randomized for each participant (thus descriptions such as "top left" were ineffective as the image might be in a different place on the speaker's and listeners' screens). The same images were used every block. 

## Procedure

The experimental procedure was very similar across the three experiments. We first describe the procedure used in experiment 1 and then describe the differences in later experiments. 

### Experiment 1
We implemented the experiment using Empirica, a Javascript-based platform for running real-time interactive experiments online [@almaatouqEmpiricaVirtualLab2020].  From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages explaining the game. Participants had to pass a quiz to be able to play the game. They were then directed to a "waiting room" screen until their partners were ready.

Once the game started, participants saw screens like Figure \ref{game}A. Each trial, the speaker described the highlighted tangram image so that the listeners could identify and click it. All participants were free to use the chat box to communicate, but listeners could only click once the speaker had sent a message. Once a listener clicked, they could not change their selection. There was no signal to the speaker or other listeners about who had already made a selection. 

Once all listeners had selected (or a 3-minute timer ran out), participants were given feedback (Figure \ref{game}B). Listeners learned whether they individually had chosen correctly or not; listeners who were incorrect were not told the correct answer. The speaker saw which tangram each listener had selected, but listeners did not. Listeners got 4 points for each correct answer; the speaker got points equal to the average of the listeners' points. These points translated into performance bonus at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the speaker once. The same person was the speaker for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were speakers 3 times in 2-player games, twice in 3-player games, once or twice in 4 and 5-player games, and once in 6-player games. Rotating the speaker was chosen to keep participants more equally engaged (the speaker role is more work), and to give a more robust test for reduction and convention. 

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

### Differences in experiment 2
Experiment 2 consisted of three different variations on Experiment 1, all conducted in 6 player games. Each of these conditions differed from the experiment 1 baseline in one way. The single speaker condition differed only in that one person was designated the speaker for the entire game, rather than having the speaker role rotate. The full feedback condition differed from experiment 1 in that all participants were shown what each person had selected and what the right answer was; listeners still saw text saying whether they individually were right or wrong. This was similar to some dyadic work, such as @hawkinsCharacterizingDynamicsLearning2020 where listeners were shown what the right answer was during feedback. For the thin condition, we altered the chatbox interface for listeners. Instead of a textbox, listeners had 4 buttons, each of which sent a different emoji to the chat. Listeners were given suggested meanings for the 4 emojis during instructions. They could send the emojis as often as desired, for instance, initially indicating confusion, and later indicating understanding. In addition, we added notifications that appeared in the chat box saying when a player had made a selection. 

### Differences in experiment 3

The thin channel condition in experiment 3 was the same as the thin condition in experiment 2, above. The thick condition combined the two group coherency enhancing variations from experiment 2: one perspon was the designated speaker throughout, and the feedback participants received included the right answer and what each player had selected. TODO confirm. Across both conditions in experiment 3, notifications were sent to the chat to indicate when a participant had made a selection. 



## Data pre-processing and exclusions

Participants could use the chat box freely, which meant that the chat transcript contained some non-referential language. The first author skimmed through the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about how well or fast the task was going, and confirmations or denials ("ok", "got it", "yes", "no"). We exclude these utterances from our analyses. Note that chat lines sometimes included non-referential words in addition to words referring to the tangrams ("ok, so it looks like a zombie", "yes, the one with legs"); these lines were retained intact. 

In experiments 1 and 2, games did not start if there were not enough participants and ended if any participant disconnected. In experiment 3, games started after a waiting period even if they were not full and continued even after a participant disconnected (with speaker role reassigned if necessary), unless the game would drop below 2 players. The distribution of playes in these 6* player games is at TODO! The realities of online recruitment and disconnection meant that the number of games varied, although we aimed for 20 games in each condition in experiments 1 and 2, and 40 per condition in experiment 3. We excluded incomplete blocks from analyses, but included complete blocks from partial games (See Table \@ref(tab:participants) for counts).

When skimming transcripts to tag non-referential utterances, we noticed that one game in the 6-player thick game had a speaker who did not give any sort of coherent descriptions, even with substantial listener prompting. We excluded this game from analyses. 

## Modelling strategy
TODO
In experiment 3, some of the 6 player games did not have 6 players for the entire game. We do not model this, as it is unclear at what point in the game group size is most relevant. We note that this is a conservative choice that will underestimate differences between 2 player and (genuine) 6 player games, by labelling some smaller groups as 6 player. 

We ran all models in brms (CITE) with weakly regularizing priors. We were often unable to fit the full mixed effects structure that we had pre-registered in a reasonable amount of time, so we included what heirarchical effects were reasonable. (All model results and formulae are reported in TODO supplement). Accuracy results used a logistic model, other results use linear models. 


# Supplement

```{r}

listeners <- combined_results |> select(condition, playerId, gameId, repNum, trialNum, targetNum, numPlayers)

listener_chat <- combined_chat |> filter(role=="listener") |>  full_join(listeners) |> group_by(condition,  numPlayers, trialNum, repNum, gameId) |> mutate(total_num_words=ifelse(is.na(total_num_words),0, total_num_words)) |> 
  summarize(words=sum(total_num_words)) |> filter(condition %in% c("rotate", "2_thick", "6_thick", "no_rotate", "full_feedback"))

  emojis <- combined_emoji |> mutate(emoji=case_when(
    text=="✅"~  "check",
    text=="🤔" ~ "think",
    text=="❌" ~ "x",
    text=="😂" ~ "lol",
  )) |> full_join(listeners) |> filter(condition %in% c("2_thin", "6_thin", "emoji"))|>
    mutate(is.emoji=ifelse(is.na(emoji), 0, 1)) |> 
    group_by(gameId, trialNum, repNum, condition, numPlayers) 
  
  count_emoji <- emojis |> summarize(words=sum(is.emoji))
  
  all_list <- listener_chat |> union(count_emoji) |> mutate(condition2=ifelse(condition=="rotate", str_c(numPlayers,condition), condition))
```

```{r listeners, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=4, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO this probably goes in a supplement! "}

one <- all_list |>    filter(words!=0)|> filter(condition=="rotate") |>  
    mutate(numPlayers=as.character(numPlayers)) |> 
ggplot(aes(x=repNum+1, y=words, color=numPlayers))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=23,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- all_list|>   filter(words!=0) |> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |>
ggplot(aes(x=repNum+1, y=words, color=condition))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
annotate("text", x=3.5,y=23,label="Experiment 2", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
    scale_color_manual(values=color_scheme_2)

#3


three <- all_list|>   filter(words!=0) |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |>  
  mutate(condition=str_replace(condition, "_", " ")) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
  geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
annotate("text", x=3.5,y=23,label="Experiment 3", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

  plot_grid(one, two, three, nrow=1)

```

```{r listeners2, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=4, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO this probably goes in a supplement! "}

# do any talk per trial

anytalk <- all_list |> group_by(condition, numPlayers, condition2, gameId, trialNum, repNum) |> summarize(words=sum(words)) |> mutate(is.words=ifelse(words>0, 1,0)) 

# maybe try per game trials/block where any listener talked?


one <- anytalk |> filter(condition=="rotate") |>  
    mutate(numPlayers=as.character(numPlayers)) |> 
ggplot(aes(x=repNum+1, y=is.words, color=numPlayers))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )+
#annotate("text", x=3.5,y=23,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- anytalk|> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |> 
ggplot(aes(x=repNum+1, y=is.words, color=condition))+
   geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )+
#annotate("text", x=3.5,y=23,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
    scale_color_manual(values=color_scheme_2)

#3


three <- anytalk|> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |>  
  mutate(condition=str_replace(condition, "_", " ")) |> 
ggplot(aes(x=repNum+1, y=is.words, color=condition))+
geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )+
#annotate("text", x=3.5,y=23,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

  plot_grid(one, two, three, nrow=1)
```

```{r other, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=11, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Stuff probably not to include. A is similarity to first utterance. B is similarity between utterances from adjacent blocks. C is divergence in descriptions of different tangrams within a group", cache=T}

#first

one_two_first <- read_rds(here("code/models/one_two_tofirst.rds"))
three_tofirst <- read_rds(here("code/models/three_tofirst.rds"))
#1
one <- one_two_first |> filter(condition %in% c("2", "3","4","5","6")) |>
  ggplot( aes(x=later+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(2,6))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=4,y=1,label="Experiment 1", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- one_two_first |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
  ggplot( aes(x=later+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(2,6))+
  coord_cartesian(ylim=c(.2,1))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=4,y=1,label="Experiment 2", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+    scale_color_manual(values=color_scheme_2)
#3

three <- three_tofirst |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |>  ggplot( aes(x=later+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(2,6))+
  coord_cartesian(ylim=c(.2,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=4,y=1,label="Experiment 3", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

tofirst <- plot_grid(one, two, three, nrow=1)

one_two_next <- read_rds(here("code/models/one_two_tonext.rds"))
three_next <- read_rds(here("code/models/three_tonext.rds"))
# divergence

#1
one <-  one_two_next|> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,5))+
        coord_cartesian(ylim=c(.1,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=1,label="Experiment 1", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_next |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
                              ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  scale_x_continuous(breaks=seq(1,5))+
      coord_cartesian(ylim=c(.1,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=1,label="Experiment 2", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_next |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |> ggplot(aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  scale_x_continuous(breaks=seq(1,5))+
   coord_cartesian(ylim=c(.1,1))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=1,label="Experiment 3", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_3)

tonext <- plot_grid(one,two,three, nrow=1)

one_two_tandiv<- read_rds(here("code/models/one_two_tangrams_div.rds"))
three_tandiv<- read_rds(here("code/models/three_tangrams_div.rds"))
# divergence

#1
one <-  one_two_tandiv |> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition, tangram1), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=.7,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_tandiv |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
                              ggplot( aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition, tangram1), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
      coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=.7,label="Experiment 2", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_tandiv |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |> ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition, tangram1), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=.7,label="Experiment 3", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_3)

tandiv <- plot_grid(one,two,three, nrow=1)


plot_grid(tofirst, tonext, tandiv, nrow=3, labels="AUTO", rel_heights = c(.8,.8,1), label_size=20)
```

## Distinctiveness of tangrams

```{r}

tandiv_1 <- read_rds(here(msum_loc, "tandiv_1.rds"))
tandiv_spec_1 <- read_rds(here(mform_loc, "tandiv_1.rds"))

```
```{r}

tandiv_2a <- read_rds(here(msum_loc, "tandiv_2a.rds"))
tandiv_spec_2a<- read_rds(here(mform_loc, "tandiv_2a.rds"))

tandiv_2b <- read_rds(here(msum_loc, "tandiv_2c.rds"))

tandiv_2c <- read_rds(here(msum_loc, "tandiv_2c.rds"))

```

```{r}
# file naming screwup TODO fix me and the file that writes me etc
tandiv_3 <- read_rds(here(msum_loc,"tandiv_3.rds"))
tandiv_spec_3 <- read_rds(here(mform_loc, "tandiv_3.rds"))

```

Another way of looking at how language changes over the course of the game is looking at how games start to refer to different tangrams more differently. This could reflect initial overlap in descriping many figures as sitting or standing or by leg and arm and head position. 

Over the course of the game, descriptions for each tangram become more distinctive (`r stats_text(tandiv_1, 1)`). 
In all three subexperiments, the descriptions of tangrams become more distinctive within games across time. (2a `r stats_text(tandiv_2a,1)`, 2b `r stats_text(tandiv_2b, 1)`, 2c `r stats_text(tandiv_2c,1)`). 


Tangram distinctiveness within games increased over time (`r stats_text(tandiv_3, 1)`). There might be more to say about other effects, but it's mostly a starting places being different in larger games and then the slopes also differ a bit? 


### play with more diagrams
Comparing utterances between adjacent rounds reveals similar patterns. Thin games have lower similarity between adjacent blocks (`r stats_text(tonext_3, 1)`) as do larger games (`r stats_text(tonext_3,7)`). Later in the game adjacent blocks are more similar than earlier adjacent blocks (`r stats_text(tonext_3, 3)`), painting an overall nonlinear convergent pattern (as seen in Figure \@ref(fig:other)). 




 
```{r}
form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
      str_replace_all("~", "~$\\\\sim$ ") |> 
  str_replace_all("\\*","~$\\\\times$ ") |> 
  str_replace_all("\\+", "~+ ")
}

do_table <- function(mod, cap){
  model <- read_rds(here(msum_loc,mod))
spec <- read_rds(here(mform_loc,mod))

kable(model |> select(Term, Est.=Estimate, CrI=`Credible Interval`), escape=F, format='latex', booktabs=T,
      caption=str_c(cap, ":\\\\\ ",form(spec)),
      align='lll', pos='h!')
}
```

## Accuracy models

Accuracy models were all run as logistic models with normal(0,1) priors for both betas and sd. This model was not explicitly included in the experiment 1 and 2 pre-registrations; it was included with more ambitious mixed effects (which did not run in a timely manner) in the experiment 3 pre-reg. 

```{r}

do_table("acc_1.rds", "Experiment 1 logistic model of listener accuracy")
do_table("acc_2a.rds", "Experiment 2: 6 single speaker logistic model of listener accuracy")
do_table("acc_2b.rds", "Experiment 2: 6 full feedback logistic model of listener accuracy")
do_table("acc_2c.rds", "Experiment 2: 6 thin logistic model of listener accuracy")
do_table("acc_3.rds", "Experiment 3 logistic model of listener accuracy")

```

\pagebreak

## Reduction models 
Reduction models were run as linear models with an intercept prior of normal(12,20), a beta prior of normal(0,10), an sd prior of normal(0,5) and a correlation prior of lkj(1). This model was pre-registered for each experiment and run with the mixed effects structure as prespecified. 

```{r}

do_table("red_1.rds", "Experiment 1")
do_table("red_2a.rds", "Experiment 2: 6 single speaker")
do_table("red_2b.rds", "Experiment 2: 6 full feedback")
do_table("red_2c.rds", "Experiment 2: 6 thin")
do_table("red_3.rds", "Experiment 3")

```

### Extra reduction model

For experiment 1, we also pre-specified models about whether the speaker's correctness (as a listener) on the prior block had an effect 

Model of whether speaker’s correct/incorrect answer in previous block  has an effect - 
 
words ~ block*player_count + block*was_correct+ (block|tangram) + (1|speaker)
+ (1|tangram*group)+(block|group)

TODO
\pagebreak

## SBERT models

For all of the models of sbert similarity, we used linear models with the priors normal(.5,.2) for intercept, normal(0,.1) for beta, and normal(0,.05) for sd. 

These models were verbally described (but not formally specified) in the pre-registrations for experiment 2 in the full feedback and thin conditions and for experiment 3, for looking at divergence between games, convergence within games (compare to first, next, and last), and divergence between tangrams within games. 

### Convergence within games: comparison to last round
This is the convergence metric presented in the paper. 

```{r}

do_table("tolast_1.rds", "Experiment 1")
do_table("tolast_2a.rds", "Experiment 2: 6 single speaker")
do_table("tolast_2b.rds", "Experiment 2: 6 full feedback")
do_table("tolast_2c.rds", "Experiment 2: 6 thin")
do_table("tolast_3.rds", "Experiment 3")

```

\pagebreak

### Divergence across games

To look at how games diverged from each other ... TODO
```{r}

do_table("div_1.rds", "Experiment 1")
do_table("div_2a.rds", "Experiment 2: 6 single speaker")
do_table("div_2b.rds", "Experiment 2: 6 full feedback")
do_table("div_2c.rds", "Experiment 2: 6 thin")
do_table("div_3.rds", "Experiment 3")

```

\pagebreak

### Divergence across tangrams


```{r}

do_table("tandiv_1.rds", "Experiment 1")
do_table("tandiv_2a.rds", "Experiment 2: 6 single speaker")
do_table("tandiv_2b.rds", "Experiment 2: 6 full feedback")
do_table("tandiv_2c.rds", "Experiment 2: 6 thin")
do_table("tandiv_3.rds", "Experiment 3")

```

\pagebreak

### convergence to next

We also looked at how similar an utterance was to the next round utterance: this can be thought of as the derivative of the to-last comparison. (although cosine similarities are not actually additive in the same way integrals are)
```{r}

do_table("tonext_1.rds", "Experiment 1")
do_table("tonext_2a.rds", "Experiment 2: 6 single speaker")
do_table("tonext_2b.rds", "Experiment 2: 6 full feedback")
do_table("tonext_2c.rds", "Experiment 2: 6 thin")
do_table("tonext_3.rds", "Experiment 3")

```

\pagebreak

### divergence from first

We also looked at how similar an utterance was to the first round utterance. This is not very informative because first round utterances tend to be pretty unwieldy. TODO explain more or don't include
```{r}

do_table("tofirst_1.rds", "Experiment 1")
do_table("tofirst_2a.rds", "Experiment 2: 6 single speaker")
do_table("tofirst_2b.rds", "Experiment 2: 6 full feedback")
do_table("tofirst_2c.rds", "Experiment 2: 6 thin")
do_table("tofirst_3.rds", "Experiment 3")

```

### Extra emoji analysis
Written about 6thin in experiment 2 and for 2 and 6 thin in 3
Additionally, exclusive to this condition, we will analyse the distribution of emoji’s produced as a function of block and its relation to accuracy and speaker utterance length.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent


