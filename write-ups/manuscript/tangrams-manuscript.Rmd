---
title: |
  | Interaction structure constrains 
  | the emergence of conventions in group communication

author:
  - name: Veronica Boyce
    email: vboyce@stanford.edu 
    affiliation:
      - Stanford 
    footnote:
      - corresp
  - name: Robert Hawkins
    affiliation: 
      - Princeton
  - name: Noah D. Goodman
    affiliation: 
      - Stanford
  - name: Michael C. Frank 
    affiliation: 
      - Stanford
address:
  - code: Stanford
    address: Stanford University 
  - code: Princeton
    address: Princeton University
footnote:
  - code: corresp
    text: "Corresponding author. Email: vboyce@stanford.edu"
bibliography: ["papers.bib"] # Replace with one or more of your own bibtex files. Better BibTeX for Zotero is your friend
csl: dmk-format.csl # Use any CSL style. See https://www.zotero.org/styles for a good list. Ignored if citation_package: natbib
link-citations: TRUE
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{angles,positioning,arrows.meta, quotes, shapes, shapes.geometric}
  - \usepackage{graphicx}
output:
  bookdown::pdf_document2:
    toc: FALSE
    keep_tex: TRUE
    template: generic_article_template.tex
    #md_extensions: "-autolink_bare_uris"
    number_sections: FALSE
    citation_package: default # Can also be "natbib"
lang: en # Main document language in BCP47 format
geometry: "margin=1.25in"
linestretch: 1 # for double spacing
endfloat: FALSE # Set to TRUE to turn on latex endfloat package to place figures and tables at end of document
# endfloatoption: # See endfloat documentation for more possibilities
#   - tablesfirst # Default
#   - nomarkers # Default
numberlines: FALSE
authblk: TRUE # FALSE = author affiliations in footnotes; TRUE = author affiliations in a block below author names
footnotehyper: FALSE # TRUE will give you enhanced table footnote capabilities. Set to FALSE to be able to use French blocks. Needed due to what appears to be a latex bug.
urlcolor: blue
linkcolor: blue
citecolor: blue
graphics: TRUE # Needed to be able to include images
tables: TRUE # Needed to be able to include tables

---

<!---------------------- Abstract --------------------->

::: {.abstract data-latex="" lang=en}

Real-world communication frequently requires speakers to address more than one listener at once, yet most psycholinguistic research focuses on one-on-one communication.
As the audience size grows, speakers face new challenges that do not arise in dyads. 
They must consider multiple perspectives and weigh multiple sources of feedback to build shared understanding.
Here, we ask which properties of the group's *interaction structure* facilitates successful communication.
We used a repeated reference game paradigm in which directors instructed between one and five matchers to choose specific targets out of a set of abstract figures. 
Across 313 games ($N=1,319$ participants), we manipulated several key constraints on the group's interaction, including the amount of feedback that matchers could give to directors and the availability of interaction between matchers.
Larger groups suffered disproportionately under interaction constraints, but in less-constrained interaction structures ("thick channels"), they were able to converge on efficient shared conventions as effectively as smaller groups.     
Overall, these results shed new light on the core structural factors that enable communication to thrive in larger groups.

:::

<!------------ Main text -------------------->

```{r set-up, include=FALSE}
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())

knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.crop = F, out.width = "100%", dpi=300,
                      fig.pos = "tb", fig.path='figs/', fig.env="figure",
                      echo=F, warning=F, cache=T, 
                      message=F, sanitize = T)

color_scheme_1 <- c("2"="#FFBDD4", "5"="#A12EFF", "3"="#FF7DF0","6"="#6940FF","4"="#D24AFF")
color_scheme_2 <- c( "6 full feedback"="#425df5", "6 consistent speaker"="#00A2FF","6 thin"="#D47E04")

color_scheme_3 <- c("2 thin"="#FFDA09","6 thin"="#D47E04", 
                    "2 thick"="#77F3DB","6 thick"="#00BDA8")
		
ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  |> 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"
image_location="write-ups/images"
msum_loc="code/paper_mods/summary"
mform_loc="code/paper_mods/formulae"

source(here("code/prep_ms.R"))


stats <- function(model, row, decimal=2){
  model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c("$\\beta=", model[row,2],",\\:95\\%\\:\\mathrm{CrI}=",model[row,3], "$")
}

stats_text  <- function(model, row, decimal=2){
    model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c("", model[row,2],", ($95\\%\\:\\mathrm{CrI}=",model[row,3], "$)")
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
  str_replace_all("\\*"," $\\\\times$ ") |> 
  str_replace_all("\\+", "&nbsp;+ ") |> 
   str_replace_all("~", "$\\\\sim$ ")
}
```

```{r count, include=F}

games <- combined_results |> select(gameId) |> unique() |> nrow() 

players <- combined_results |> select(gameId, numPlayers) |> unique() |> summarize(players=sum(numPlayers))

words <- combined_chat |> ungroup() |> select(total_num_words) |> summarize(words=sum(total_num_words)) 
```

# Introduction

Much of human social life revolves around communication in groups. 
At school, teachers address large classrooms of children [@cazden1988classroom]; at home, we chat with groups of friends and family members over dinner [@tannen2005conversational]; and at work, we attend meetings with colleagues and managers [@caplow1957organizational; @zack1993interactivity].
Such settings present considerable challenges that do not arise in the purely two-party (dyadic) settings typically studied in psychology [@branigan2006; @ginzburg2005; @traum2004]. 
For example, speakers need to account for the fact that different listeners in the group may have different mental states or levels of background understanding [@horton2005; @horton2002; @yoon2018; @yoon2014; @weber2003;@fox-tree2013], while listeners must account for the fact that utterances are not necessarily tailored to them [@fay2000; @carletta1998; @metzing2003; @yoon2019; @rogers2013; @cohngordon; @tolins2016].^[Throughout this paper, we use "speaker" and "listener" -- regardless of communication modality -- to refer to both the general conversation roles played by language producers and comprehenders as well as the the specific roles of describing and selecting targets in reference games of the type we study here.]
What enables speakers and listeners to nevertheless overcome these challenges and navigate multi-party settings with relative ease? 

One promising set of hypotheses centers on the group's *interaction structure*, the set of constraints placed on the group's shared communication channel. 
Many different aspects of interaction structure have been implicated in the effectiveness of dyadic communication, including the availability and quality of concurrent feedback [@krauss1966; @KraussBricker67_Delay; @kraut1982listener], the bandwidth of the communication modality [@KraussEtAl77;@dewhirst1971influence], and the group's access to a shared workspace [@clark2004speaking; @garrod2007foundations].
Yet larger group introduce qualitatively different dimensions of interaction structure, leading to a large but often inconsistent body of findings even for these well-understood factors [@swaab2012communication; @hiltz1986experiments].
While communication is generally expected to deteriorate as groups get larger [@macmillan_communication_2004; @seaman1997communication], several factors that may slow such deterioration have been identified in qualitative work, each of which relates to the structural "thickness" of the feedback channel [@ahern1994effect; @parisi2005evaluating]. 

In this paper, we develop an experimental paradigm for evaluating the relative contribution of these factors: a *multi-party repeated reference game.*
The ability to distinguish one particular entity from other possible entities, known as *reference*, is one of the most primitive and ubiquitous functions of communication.
Reference games [@Wittgenstein1953; @lewis1969convention] have been widely used to study dyadic communication under controlled conditions in the lab. 
They provide a clear metric of communicative effectiveness: how many words are required to allow a listener to successfully choose a target image from a context of distractors? 
*Repeated* reference games, where the same target images appear multiple times in succession, were introduced to examine how interlocutors establish shared reference in the absence of conventional labels [@krauss1964; @clark1986].
At the beginning of the game, long and costly descriptions are typically required to succeed. 
A key finding, however, is that dyads become increasingly efficient over the course of interaction. 
Later utterances require fewer words, but also become more impenetrable to outsiders [@schober1989; @wilkes1992coordinating]. 

In principle, repeated reference games provide a strong operationalization of communicative effectiveness for the problem of multi-party communication: speakers must simultaneously achieve shared reference with multiple listeners. 
However, empirically studying multi-party communication raises a number of difficulties in practice. 
A much larger pool of participants must be recruited to achieve sufficient power at the relevant unit of analysis -- the group -- spanning a very high-dimensional space of possible parameter settings [@almaatouq2022].
We address this problem by drawing on recent technical advances that have made it newly possible to achieve such samples using an interactive web-based platform [@haber2019;@hawkins2023partners]. 
Repeated reference games in online, chat-based paradigms have closely replicated earlier results from face-to-face studies [@hawkins2020], and arguably more closely resemble the interfaces used by modern teams who increasingly communicate through group text threads or popular platforms like Slack or Discord.

We use the multi-party repeated reference game to explore effects of group size and interaction channel thickness through a series of three experiments. Taken together, our findings illuminate the mechanisms of social interaction in larger groups and suggest design features that may ease the communicative overhead associated with larger groups in real-world settings.


```{r diagram,  fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap="(A) Participants played a repeated reference game in groups of size 2 to 6. On each trial, speakers described a target image to the listeners. Each image appeared once per block for six blocks. (B) Diagram of the experimental space. Experiments varied along 3 dimensions: Group size, group coherence, and listener backchannel. (C) Schematic of the axes we manipulated. Experiment 1 (pink) varied group size from 2 to 6 players while holding group coherence and backchannel constant. Experiment 2 (blue) held group size constant at 6 and manipulated the other dimensions. Experiment 3 (green) tested 4 corners of the space, crossing group size (2 vs. 6 players) with the thickness of interaction structure (high vs. low coherence and backchannel)."}
knitr::include_graphics("fig1.pdf")
```

# Results

We recruited `r players` participants through Prolific, an online crowd-sourcing platform.
Participants were organized into `r games` groups of size two to six for a communication game (Figure \@ref(fig:behavioral)A).
On each trial, everyone in the group was shown a gallery of 12 tangram images [@clark1986; @hawkins2020; @ji2022abstract].
One player was designated the *speaker* and the others were designated the *listeners*. 
The speaker was asked to use a chat box interface to describe a privately indicated *target* image. 
After all listeners guessed which of the 12 images was the target, they received task feedback and proceeded to the next trial.
The game consisted of 72 trials structured into 6 repetition blocks, where each image appeared as the target exactly once per block.

We manipulated the interaction structure of this game across 11 distinct conditions in 3 distinct pre-registered experiments (Figure \@ref(fig:behavioral)B). 
We systematically sampled points along four dimensions parameterizing different aspects of the interaction space. 
We manipulated *group size* (ranging from two to six), *role stability* (whether or not participants took turns in the speaker role), richness of *task feedback* (whether or not listeners were able to see each other's responses), and richness of the *listener backchannel* (whether listeners were able to freely respond through a chatbox or asked to use emojis; Figure \@ref(fig:behavioral)C).
Other factors, such as the set of stimuli and background knowledge about one's partners, were held constant across games. 

Experiment 1 investigated how performance scaled with group size.
Based on prior qualitative work, we predicted that larger groups face a more challenging coordination problem. 
We continuously varied the number of players from 2 to 6 while keeping other factors constant. 
For these conditions, the speaker role rotated after each block, so that all players had at least one turn as speaker. 
Listeners had access to an unrestricted chat box, but only received binary task feedback about whether their individual selection was correct without revealing others' selections or the intended target. 

Experiment 2 explored the role of interaction structure purely within the most challenging 6-player groups. 
We manipulated two factors that we expected to increase group coherence and improve performance. 
First, we maintained a consistent speaker rather than a rotating speaker, such that the same individual has the opportunity to aggregate feedback across trials and track which listeners are struggling which which targets. 
Second, we gave the group of listeners full feedback about what every other member of the group had selected, and we showed the intended target. 
We also manipulated a factor that we expected to interfere with the ability to establish mutual understanding and thus impede performance. 
In the limited backchannel condition, listeners were limited to four discrete emojis (green check, thinking face, red x, and laughing-crying face) that could convey simple valence and level of comprehension, but not any referential content.

Experiment 3 crossed the extremes of group size from experiment 1 (2 vs. 6 people) with the extremes of group interactions from Experiment 2 (*thick* vs. *thin* interaction structure). 
In the *thick* condition, we maintained a consistent speaker, gave all listeners full task feedback, and allowed them to freely use a chat box. 
In the *thin* condition, we forced the speaker to rotate on each block, restricted feedback to their own binary correctness, and restricted the backchannel to the four emojis.
Note that the 2-player thick game most closely resembles the design of classic repeated reference games [@clark1986; @hawkins2020].

```{r behavioral, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=7.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Behavioral results across all three experiments. (A-C). Listener accuracy at selecting the target image. Dots are per condition, per block estimates with 95\\% bootstrapped CIs. Smooths are binomial fit lines.  (D-F). Number of words said by the speaker each trial. Faint dots represent individual trials from individual games. Smooths are quadratic fit lines. Y-axis is truncated, and a few outliers points are not visible. **(TODO check ordering of legends!)** **(TODO: it's currently a bit odd that (D-F) is the only figure in the paper with the raw dots in the background, which also forces a real compression of the y-axis making it hard to see big differences between curves. I'd shoot for consistency and either have everything in the main text show the fits only (with 'raw distribution' versions in supplement) or show some 'direct' version of the empirical data in every figure, like the mean dots with error bars at each block size.)**"}
# accuracy
# 1
one <- combined_results |> 
  filter(condition=="rotate") |> 
  group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(numPlayers=as.character(numPlayers)) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=numPlayers))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
    geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
    labs(x="Block", y="Fraction correctly selected", color="", title="Experiment 1")+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
    annotate("text", x=1,y=1,label="A", size=6, fontface="bold")+
    theme(legend.position="none",
          axis.text=element_text(size=12),
          legend.text=element_text(size=13),
          axis.title=element_text(size=14),
          plot.title=element_text(size=16, hjust=.5))+
    scale_color_manual(values=color_scheme_1)

two <- combined_results |>
  filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(condition=case_when(
    condition=="no_rotate" ~ "6 consistent speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin"),
    condition=factor(condition, levels=c("6 full feedback", "6 consistent speaker", "6 thin"))
  ) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
    scale_x_continuous(breaks=seq(1,6))+
    coord_cartesian(ylim=c(.65,1))+
    geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
    labs(x="", y="", color="", title="Experiment 2")+
    annotate("text", x=1,y=1,label="B", size=6, fontface="bold")+     
    annotate("text", x=3.5,y=1,label="Accuracy", size=6)+
    theme(legend.position="none",
          axis.text=element_text(size=12),
          legend.text=element_text(size=14),
          axis.title=element_text(size=14),
          plot.title=element_text(size=16, hjust=.5),
          axis.title.y=element_blank())+ 
    guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
    scale_color_manual(values=color_scheme_2)

#3
three <- combined_results |> 
  filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> 
  group_by(playerId,repNum, gameId, condition) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |>
  mutate(condition=str_replace(condition, "_", " "),
         condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin"))) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
    scale_x_continuous(breaks=seq(1,6))+
    coord_cartesian(ylim=c(.65,1))+
    geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
    annotate("text", x=1,y=1,label="C", size=6, fontface="bold")+
    labs(x="", y="", color="", title="Experiment 3")+
    theme(legend.position="none",
          axis.text=element_text(size=12),
          legend.text=element_text(size=14),
          plot.title=element_text(size=16, hjust=.5),
          axis.title=element_text(size=14),
          axis.title.y=element_blank())+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.1) ) )+
    scale_color_manual(values=color_scheme_3)
 
acc <- plot_grid(one, two, three, nrow=1, rel_widths = c(1.05, 1, 1))
 

#1
one <- combined_chat |> 
  filter(condition=="rotate") |>  
  filter(role=="speaker") |> 
  mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, numPlayers) |> 
  summarize(words=sum(total_num_words)) |>
  mutate(numPlayers=as.character(numPlayers)) |> 
  ggplot(aes(x=repNum+1, y=words, color=numPlayers))+
    geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    coord_cartesian(ylim=c(0,60))+
    scale_x_continuous(breaks=seq(1,6))+
    labs( y="Number of words", x="Block", color="")+
    guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
    annotate("text", x=1,y=60,label="D", size=6, fontface="bold")+
    theme(legend.position="bottom",
          axis.text=element_text(size=12),
          legend.text=element_text(size=13),
          axis.title=element_text(size=14),
          axis.title.x=element_blank())+
    scale_color_manual(values=color_scheme_1)


#2

two <- combined_chat|> 
  filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  filter(role=="speaker") |> 
  mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram,condition) |> 
  summarize(words=sum(total_num_words)) |> 
  mutate(condition=case_when(
    condition=="no_rotate" ~ "6 consistent speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin"),
    condition=factor(condition, levels=c("6 full feedback", "6 consistent speaker", "6 thin"))
  ) |> 
  ggplot(aes(x=repNum+1, y=words, color=condition))+
    geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    coord_cartesian(ylim=c(0,60))+
    scale_x_continuous(breaks=seq(1,6))+
    labs(x="", y="", color="")+
    annotate("text", x=1,y=60,label="E", size=6, fontface="bold")+
    annotate("text", x=3.5,y=60,label="Words from speaker", size=6)+
    theme(legend.position="bottom",
          axis.text=element_text(size=12),
          legend.text=element_text(size=13),
          axis.title=element_blank())+
    scale_color_manual(values=color_scheme_2)

#3
three <- combined_chat |> 
  filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> 
  filter(role=="speaker") |> 
  mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, condition) |> 
  summarize(words=sum(total_num_words)) |> 
  mutate(condition=str_replace(condition, "_", " "),
         condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin"))) |>
  ggplot(aes(x=repNum+1, y=words, color=condition))+
    geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
    coord_cartesian(ylim=c(0,60))+
    scale_x_continuous(breaks=seq(1,6))+
    labs(x="", y="", color="")+
    annotate("text", x=1,y=60,label="F", size=6, fontface="bold")+
    theme(legend.position="bottom",
          axis.text=element_text(size=12),
          legend.text=element_text(size=13),
          axis.title=element_blank())+
    scale_color_manual(values=color_scheme_3)

red <- plot_grid(one,two, three, nrow=1, rel_widths = c(1.05,1,1))
plot_grid(acc, red, nrow=2, rel_heights = c(.95,1))
```

```{r}
acc_1 <- read_rds(here(msum_loc,"acc_1.rds"))

acc_2a <- read_rds(here(msum_loc,"acc_2a.rds"))

acc_2b <- read_rds(here(msum_loc,"acc_2b.rds"))

acc_2c <- read_rds(here(msum_loc,"acc_2c.rds"))

acc_3 <- read_rds(here(msum_loc,"acc_3.rds"))
```

## Group Performance

We characterize group performance along two complementary metrics: (1) listener accuracy and (2) speaker efficiency.
Listener accuracy is given by the percent of listeners on each trial who successfully identify the target referent from the speaker's description. 
Speaker efficiency is given by the number of words produced by the speaker to achieve that degree of listener accuracy in the group.
The degree to which speakers are able to communicate more efficiently without impacting listener accuracy is indicative of convergence on a more effective shared communication protocol within the group.

### Group coherence improves communicative success

We begin by examining the impact of interaction structure on referential success, the ability to correctly transmit the intended target to all listeners (Figure \@ref(fig:behavioral)A-C).
We predicted that larger groups would struggle under thinner interaction structures, but that thicker interaction structures would ease some of the challenges associated with multi-listener communication. 
To test these effects, we constructed a series of logistic mixed-effects regression models predicting accuracy as a function of the manipulated variables, repetition block, and their interactions. (**TODO: clarify whether this is a single big regression for all factors in the 11 conditions, or a separate regression model for each of the three experiments?**)

First, we observed strong main effects of repetition block, indicating improved performance across all conditions (**TODO: STAT**).
Second, we examined the *initial* accuracy as an indicator of the challenges facing groups under different conditions. 
Although group size did not have a strong effect on the *initial* accuracy under the baseline interaction structure of Experiment 1 (Figure \@ref(fig:behavioral)A, `r stats(acc_1,4)`), 6-player thick games had lower initial accuracy than 2-player thick games (Figure \@ref(fig:behavioral)C, `r stats(acc_3,6)`).
Among 6-player games, initial accuracy was also higher when the speaker was consistent (`r stats(acc_2a,2)`) and listeners received full feedback (`r stats(acc_2b, 2)`) than for games with a thin feedback channel (Figure \@ref(fig:behavioral)B, `r stats(acc_2c, 2)`).
The difference between thick and thin 2-player games was not reliable, indicating that interaction structure may be less determinative for smaller groups (`r stats(acc_3,5)`). 

**(TODO: in this paragraph, we should be emphasizing the coefficients that are relevant for asking (1) whether group size (2vs6) matters more for THIN than THICK groups and (2) whether among larger (6p) groups, THICKNESS improves communication accuracy)**
Third, we examined the interaction between condition and repetition block to test whether interaction structure impacts the rate of improvement.
Again, although there was no reliable effect of group size in Experiment 1, 6-player thin games were strictly slower to improve than 2-player thin games (`r stats(acc_3, 3)`). 
Among large groups in Experiment 2, improvement rates were higher for consistent speaker games (`r stats(acc_2a,1)`) and full feedback games (`r stats(acc_2b, 1)`) than for thin games ( `r stats(acc_2c, 1)`).
The difference in improvement rates between thick and thin 2-player games was not reliable (`r stats(acc_3,2)`). 
In sum, although participants may struggle in larger groups, thicker interaction structures lower barriers to communication.

```{r}
red_1 <- read_rds(here(msum_loc, "red_1.rds"))

red_2a <- read_rds(here(msum_loc,"red_2a.rds"))

red_2b <- read_rds(here(msum_loc,"red_2b.rds"))

red_2c <- read_rds(here(msum_loc,"red_2c.rds"))

red_3 <- read_rds(here(msum_loc, "red_3.rds"))

red_3_extra <- read_rds(here(msum_loc, "red_3_extra")) %>% select(diff6, thin2, thin6, thick6)

diff6 <- str_c("$\\beta=", round(red_3_extra[2,1],2),",\\:95\\%\\:\\mathrm{CrI}=[",round(red_3_extra[1,1],2),", ",round(red_3_extra[3,1],1), "]$")

thin2 <- str_c("$\\beta=", round(red_3_extra[2,2],2),", (95\\%\\:\\mathrm{CrI}=[",round(red_3_extra[1,2],2),", ",round(red_3_extra[3,2],1), "]$)")

thin6 <- str_c("$\\beta=", round(red_3_extra[2,3],2),", (95\\%\\:\\mathrm{CrI}=[",round(red_3_extra[1,3],2),", ",round(red_3_extra[3,3],1), "]$)")

thick6 <- str_c("$\\beta=", round(red_3_extra[2,4],2),", (95\\%\\:\\mathrm{CrI}=[",round(red_3_extra[1,4],2),", ",round(red_3_extra[3,4],1), "]$)")
```

### Larger groups require more information.

After establishing that thicker interaction structure eases the challenges of communication faced by larger groups, we turned to the challenges faced by speakers when deciding how much information to provide.
Specifically, we predicted that larger and more heterogeneous groups may initially require more information, but that thicker interaction structure may similarly allow speakers to communicate more effectively over time.
We tested these predictions using linear mixed-effects models predicting the number of words a speaker produced on each trial as a function of condition and block. 
**(TODO: was this just the initial message before listeners had a chance to respond, or all utterances produced by the speaker across a potentially multi-turn dialogue? Whichever it is, it might help to include the other in Supplementary Information. Also, include the exact `brms` formula in Supplemental?)**

First, as predicted, speakers in larger groups used longer descriptions at the outset than speakers in smaller groups in Experiment 1 (Figure \@ref(fig:behavioral)D, `r stats(red_1,4)`)  and Experiment 3 (Figure \@ref(fig:behavioral)F, `r stats(red_3,7)`).
**(TODO: these results would be much cleaner with a unified meta-analytic model combining data across all three experiments)**
Second, although communicative efficiency improved at a similar rate across group size in Experiment 1 (`r stats(red_1,2)`), we found that thicker interaction structure allowed larger groups to improve faster than smaller ones in Experiment 3 (`r stats(red_3, 4)`).  
In more interpretable terms, speakers were able to get away with `r stats_text(red_1,1)` fewer words than the previous block, on average, in Experiment 1. 
In sum, while larger groups of listeners may initially require more information from the speaker, interaction structure modulates the ability of the group to converge on an efficient set of referential conventions. 

**(TODO: I would probably put the following in a (supplemental) table rather than rattling off every condition -- we should only include the most theoretical central comparisons in the text)**
Meanwhile, the interaction structure manipulations in Experiment 2 allowed for `r stats_text(red_2a,1)` fewer words for consistent speakers and `r stats_text(red_2b,1)` fewer words given full feedback, compared with `r stats_text(red_2c,1)` fewer words in the thin condition. 
In experiment 3, the effect of being one block later was `r stats_text(red_3,1)` for 2 thick condition, `r thin2` for the 2 thin condition, `r thin6` for the 6 thin condition, and `r thick6` for the 6 thick condition. 
Thin 2-player games were similar to thick 2-player games in initial verbosity (Figure \@ref(fig:behavioral)F, `r stats(red_3, 5)`) and reduction rate ( `r stats(red_3, 2)`). 

```{r}
list_1 <- read_rds(here(msum_loc, "list_1.rds"))
list_spec_1 <- read_rds(here(mform_loc, "list_1.rds"))

anylist_1 <- read_rds(here(msum_loc, "anylist_1.rds"))
anylist_spec_1 <- read_rds(here(mform_loc, "anylist_1.rds"))
```

### Listeners in larger groups rely more heavily on backchannels 

Finally, we examine the back-and-forth interactions between the speaker and the group of listeners.
The backchannel allows listeners to actively provide feedback and seek clarification about the speaker's referring expressions.
**(TODO: ideally we could include an example here. e.g. were there any cases where one listener answered another listener's question in a larger group? these are the kinds of lateral interactions that motivate the utility of thicker interaction structures.)**
We predicted that larger groups would initially rely more heavily on lateral peer interactions, the ability to deliberate and assist one another.
However, as groups converged, we expected the use of these backchannels to decline.
To test these predictions, we constructed a logistic regression predicting the presence of listener utterances (or emojis) as a function of group size and block (see Supplement for a similar analysis of the number of words produced by listeners).

Overall, larger groups displayed a higher proportion of trials where at least one listener backchannel response was produced (Supplement Figure 2A, `r stats(anylist_1, 4)`), which declined across blocks (`r stats(anylist_1, 1)`). 
This pattern is consistent with early listener involvement in establishing a common conceptualization by asking questions and offering alternative descriptions. 
We found that emoji use in Experiment 3 followed similar trends (Supplement Figure 3).

### Interim summary 

We examined three metrics of communicative performance in groups of different sizes and interaction structures.
Broadly, as groups get larger, speakers must provide more information and listeners must provide more feedback to achieve similar accuracy.
However, thicker interaction structures ease the burdens of larger group sizes. 
Six-person groups can only approach the performance of two-person groups when listeners are free to ask specific clarifying questions and speakers are able to aggregate information across multiple repetition blocks. 

## Linguistic Content

```{r sbert-diagram, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Example utterances describing the shown tangram figure produced by two 3-player games in Experiment 1. To measure convergence within a game (blue), we measured the cosine similarity between SBERT embeddings of descriptions and the embedding of the round 6 utterance (taken to be the convention). Higher cosine similarity indicates more similar meaning. To measure divergence between games (green), we measured the similarity between embeddings of utterances from the same round across games."}
knitr::include_graphics("sbert.pdf")
```

In the previous sections, we explored the functional challenges facing multi-listener communication and the solutions afforded by thicker interaction structure.
Here, we aim to better understand the mechanisms that make these solutions effective. 
In particular, we explore the hypothesis that interaction structure affects performance by acting through a *convention formation* process [@clark1986]. 
Under a recent models of convention formation [@hawkins2023partners], groups are able to leverage their shared history to coordinate on stable expectations about how to refer to particular images.
This model makes specific predictions about how interaction structure affects the ability to coordinate, in terms of the available feedback.

First, due to heterogeneity in the group -- 6 individuals who may have diverging conceptualizations --- a rational speaker should provide a strictly more detailed initial description to hedge against multiple possible misunderstandings, as we previously observed. 
Second, all groups should display the characteristic dynamics of conventions: *stability*, or convergence within group, and *arbitrariness*, or divergence to multiple equilibria across groups. 
Third, convergence should be faster when a single individual is consistently in the speaker role and when listeners are able to freely respond in natural language, as speakers are able to aggregate feedback about the effectiveness of their own utterances from block to block and also immediately correct specific misunderstandings within a given trial.

To assess the dynamics of speaker descriptions, we examine the *semantic similarity* of descriptions within and across games.
We quantified description similarity by concatenating speaker messages together within a trial and embedding this description into a high-dimensional vector space using SBERT. 
SBERT is a BERT-based sentence embedder designed to map semantically similar sentences to embeddings that are nearby in embedding space.
Semantically meaningful comparisons between sentences are made by taking pairwise cosine similarities between the embeddings [@reimers2019]. 

To measure stability, or convergence within groups, we compared utterances from blocks one through five to the final (block six) description for the same image from the same game. 
To measure arbitrariness, or divergence across groups, depending on group-specific history, we compared utterances produced by different speakers for the same image in the corresponding blocks. 
Figure \@ref(fig:sbert-diagram) illustrates these two measures with example concatenated utterances and their within-game and between-game cosine similarities. 


```{r sbert, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=7.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Language similarity results measured with pairwise cosine similarity between embeddings of two utterances. A-C. Convergence of descriptions within games as measured by similarity between an utterance from block 1-5 to the block 6 utterance in the same game for the same image. Dots are per-game averages, smooths are quadratic. D-F. Divergence of descriptions across games as measured by the similarity between two utterances produced for the same image by different groups in the same block. Dots are per-image averages, smooths are quadratic. **(TODO check ordering of legends!)**"}
#convergence

one_two_converge <- read_rds(here("code/models/one_two_converge.rds"))
three_converge <- read_rds(here("code/models/three_converge.rds"))
#1
one <- one_two_converge |> filter(condition %in% c("2", "3","4","5","6")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="", title="Experiment 1")+

  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  annotate("text", x=1,y=1,label="A", size=6, fontface="bold")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        plot.title=element_text(hjust=.5, size=16),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- one_two_converge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 consistent speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  #guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
 # labs(y="Cosine Similarity", x="Block", color="")+
    labs(x="", y="", color="", title="Experiment 2")+
    annotate("text", x=1,y=1,label="B", size=6, fontface="bold")+
annotate("text", x=3,y=1,label="Within game", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        plot.title=element_text(hjust=.5, size=16),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+    scale_color_manual(values=color_scheme_2)



#3



three <- three_converge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |>  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
 # labs(y="Cosine Similarity", x="Block", color="")+

    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  annotate("text", x=1,y=1,label="C", size=6, fontface="bold")+
    labs(x="", y="", color="", title="Experiment 3")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14),
        plot.title=element_text(hjust=.5, size=16),
        axis.title.y = element_blank())+
  scale_color_manual(values=color_scheme_3)

conv <- plot_grid(one, two, three, nrow=1, rel_widths = c(1.05, 1,1))

one_two_diverge <- read_rds(here("code/models/one_two_diverge.rds"))
three_diverge <- read_rds(here("code/models/three_diverge.rds"))
# divergence

#1
one <-  one_two_diverge |> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  #  labs(x="", y="", color="")+
  annotate("text", x=1,y=.7,label="D", size=6, fontface="bold")+
  theme(legend.position="bottom",
        axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_diverge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 consistent speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin"),
     condition=factor(condition, levels=c("6 full feedback", "6 consistent speaker", "6 thin"))) |>
                              ggplot( aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.1,.7))+
  labs(x="", y="", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
    annotate("text", x=1,y=.7,label="E", size=6, fontface="bold")+
annotate("text", x=3.5,y=.7,label="Between games", size=6)+
  theme(legend.position="bottom",
                axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_diverge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1)),                    condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin"))) |> 
  ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
    labs(x="", y="", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
  annotate("text", x=1,y=.7,label="F", size=6, fontface="bold")+
  theme(legend.position="bottom",
                axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+
scale_color_manual(values=color_scheme_3)

div <- plot_grid(one,two,three, nrow=1, rel_widths = c(1.05, 1, 1))

plot_grid(conv, div, nrow=2,  rel_heights = c(.95,1))
```


```{r}
tolast_1 <- read_rds(here(msum_loc, "tolast_1.rds"))

tonext_1 <- read_rds(here(msum_loc, "tonext_1.rds"))

tolast_2a <- read_rds(here(msum_loc, "tolast_2a.rds"))

tonext_2a <- read_rds(here(msum_loc, "tonext_2a.rds"))

tolast_2b <- read_rds(here(msum_loc, "tolast_2b.rds"))

tonext_2b <- read_rds(here(msum_loc, "tonext_2b.rds"))

tolast_2c <- read_rds(here(msum_loc, "tolast_2c.rds"))

tonext_2c <- read_rds(here(msum_loc, "tonext_2c.rds"))

tolast_3 <- read_rds(here(msum_loc, "tolast_3.rds"))

tonext_3 <- read_rds(here(msum_loc, "tonext_3.rds"))
```

### Descriptions converge within groups

Across conditions, speaker descriptions increased in semantic similarity to the final description over repetition; convergence was fastest in smaller and higher coherence groups, and was least strong in the 6-player thin condition (Figure \@ref(fig:sbert)A-C).
We modeled semantic convergence by looking at the similarity between a block 1-5 utterance and the corresponding block 6 utterance as a function of the earlier block number and condition. 
The similarity of the first utterance to the last utterance was invariant across group size (`r stats(tolast_1, 1,3)`), but smaller groups converged faster (Figure \@ref(fig:sbert)A, `r stats(tolast_1, 3,3)`). 
The 6-player thick games started off with greater distance between first and last utterances than 2-player thick games (`r stats(tolast_3, 7,3)`) but closed the gap over time (`r stats(tolast_3, 6,3)`). 
Overall, smaller games reach a stable description faster than larger games. 

Convergence was especially rapid for the consistent speaker condition, where all the utterances came from the same person (Figure \@ref(fig:sbert)B, `r stats(tolast_2a, 1,3)`). 
Convergence was slower in thin games than thick games (Figure \@ref(fig:sbert)C, `r stats(tolast_3, 4,3)`). 
Beyond the generally slower convergence in thin games, 6-player thin games showed substantially slower convergence even compared to 2-player thin games (expt 3, `r stats(tolast_3, 5,3)`). 
Across games, convergence towards the last utterance was driven by cumulative increasing similarity between pairs of utterances in adjacent blocks (Supplement Figure 4D-F). In early rounds, descriptions could change substantially between rounds, but by later rounds, many descriptions had already reduced and solidified and varied little round to round. 
All conditions showed some convergence toward a conventional nickname for the picture, but the speed of convergence was affected both by group size and channel width. Overall, descriptions were more similar if provided by the same person, if fewer people were in the game, and if listeners could contribute via a text channel. 

```{r}
div_1 <- read_rds(here(msum_loc, "div_1.rds"))

div_2a <- read_rds(here(msum_loc, "div_2a.rds"))

div_2b <- read_rds(here(msum_loc, "div_2b.rds"))

div_2c <- read_rds(here(msum_loc, "div_2c.rds"))
div_3 <- read_rds(here(msum_loc, "div_3.rds"))
```


### Games diverges from one another faster with thicker channels

While groups may initially overlap in their descriptions, including details of shapes or body parts, their descriptions are predicted to become increasingly dissimilar as groups increasingly adapt to their shared history.
We modeled semantic divergence using a mixed-effects linear regression model predicting the similarity between a pair of utterances for the same image as a function of the block number and condition (Figure \@ref(fig:sbert)D-F). 
Initial similarities between groups were the same regardless of group size (Figure \@ref(fig:sbert)D, `r stats(div_1, 3,3)`), 
and divergence between groups, indicating increasing group-specificity of descriptions, occurred across all conditions to some degree. 

However, different interaction structure conditions revealed different patterns.
Broadly, thicker structure was associated with stronger group-specific divergence.
In Experiment 2, divergence was stronger in the consistent speaker (Figure \@ref(fig:sbert)E, `r stats(div_2a, 1,3)`) and full feedback conditions ( `r stats(div_2b, 1,3)`) than in the thin condition ( `r stats(div_2c, 1,3)`). 
In Experiment 3, the interaction between group size and thickness indicated a much lower rate of divergence under thin structure in large groups (Figure \@ref(fig:sbert)F, `r stats(div_3, 3,3)`). 
The 6-player thin games barely diverged at all, indicating a failure of group adaptation.

**(TODO: again, if we're going to report all effects, it might be easier just to point to a supplemental table with the full brms output?)**
The 2-player thick condition diverged at a moderate speed (Figure \@ref(fig:sbert)F, `r stats(div_3, 1,3)`), and the 6-player thick condition had initially higher similarity (`r stats(div_3, 7,3)` and faster divergence (`r stats(div_3, 4,3)` in comparison.
2-player thin games started with slightly higher similarity (Figure \@ref(fig:sbert)F `r stats(div_3, 5, 3)`) and diverged slightly more slowly (`r stats(div_3, 2,3)`) than 2-player thick games. 

### Interim summary 

Smaller groups show higher within-group similarities and between-group differences, sometimes showing up in the initial round and sometimes developing as a change over time. The thicker the games the faster and stronger the divergence and convergence patterns. The combination of a large game and a thin communication channel hampers within-game convergence and between-game divergence much more than either game size or thinness independently, as seen in the difference between 6 thin and either 2 thin or 6 thick. 

# General Discussion

Communication often occurs in multi-party settings, but research on referential communication typically does not focus on such settings -- largely due to practical obstacles. 
Dyadi reference games have been used to measure informational efficiency, characterized by speaker-listener pairs creating conventional (stable but somewhat arbitrary) labels which are not shared by other groups. 
In the current work work, we asked how this process of reference formation unfolds in larger groups and under varying interaction structures. 
Across 3 online experiments and 11 experimental conditions, we varied game features including group size, form of listener backchannel, and degree of group coherence. 
All conditions replicated classic phenomena: increasing accuracy, reduction in speaker utterances, semantic convergence within games, and differentiation of descriptions between groups. 
However, we also found that the interaction structure of a group substantially affects how rapidly groups develop partner-specific conventions. 
Small groups may be able to succeed under limited feedback, but larger groups require thicker interaction structure.
Multi-player groups thus reveal important factors for communication which are masked in purely dyadic settings.

<!-- ## Efficiency without semantic convergence  -->

Increasing efficiency has often been taken as an index of group-specific convention formation [@clark1986; @brennan1996; @yoon2014; @yoon2018]. 
In our work, however, we observe distinct patterns for measures of raw utterance length compared to the dynamics of semantic content. 
In Experiment 3, thin 6-person games showed much less group-specific divergence despite comparable accuracy and efficiency. 
This gap raises the possibility that it is possible to become more efficient without converging on a unified group-specific label. 
Instead, they may be converging to a multi-modal solution based on group priors [@guilbeault2021]. 
Thus, we encourage measures of semantic content (and not just performance) when evaluating convention formation.

<!-- ## Limitations and future directions.  -->

Just within the general framework of iterated reference, there is a high dimensional feature space of possible experiments. We sampled only a few points along a few dimensions in the space that felt salient. In our experiment 3, we grouped some factors together in order to have more games in each condition: a fully factorial design would have been too expensive to power adequately. We instantiated a "thin" channel by limited listeners to 4 discrete utterances (emojis), but there are other ways to manipulate channel width for speakers and listeners, such as rate limiting typing or adding time pressure. Future work could sample other points in the experimental space, including exploring other manipulations on channel thickness, the effects of different target images, or groups of people with real-life prior connections. 

We cannot make claims about causal mechanisms between how experimental set-ups such as group size resulted in different outcomes: for instance, there are many differences between being in a 2-person group versus a 6-person group that could lead to the different outcomes. In a dyad, speakers can tailor their utterances to the one listener, but in large groups, speakers must balance the competing needs of different listeners [@schober1989;@tolins2016]. These effects likely vary by both the knowledge state of and communication channels available to the listeners [@fox-tree2013;@horton2002; @horton2005]. Further work digging into the language used and the interactions between participants might unearth plausible mechanisms for how differences in group size and interaction structure influence outcomes, and this in turn could then point towards future experimental conditions. 

<!-- ## Conclusion  -->

Communication occurs across a broad range of situations, varying on many dimensions, including group size, medium of interaction, and group structure. 
A narrow focus on dyads with rich communication channels can lead to theories that mispredict how interactions play out in multi-party groups with varying interaction structure. 
Sampling from a broader range of communicative situations is thus a critical part of better understanding human communication. 

# Methods

For all experiments, we used Empirica [@almaatouq2020] to create real-time multi-player iterated reference games. In each game, one of the players started as the speaker who saw an array of tangrams with one highlighted and communicated which figure to click to the other players (listeners). After the speaker had described each of the 12 images in turn, the process repeated with the same images over a total of 6 such blocks (72 trials). We recorded what participants said in the chat, as well as who selected what image and how long they took to make their selections. 

These experiments were designed sequentially and pre-registered individually.^[Experiment 1: https://osf.io/cn9f4 for the 2-4 player groups, and https://osf.io/rpz67 for the 5-6 player data run later. Experiment 2: consistent speaker at  https://osf.io/f9xyd, full feedback at  https://osf.io/j5zbm, and thin at  https://osf.io/k5f4t. Experiment 3: https://osf.io/untzy] We followed the analysis plan for each, although some additional analyses were added to early experiments that were only pre-registered in later experiments. Results from some pre-registered models are omitted from the main text for brevity but are shown in the Supplement.

## Participants

Participants were recruited using the Prolific platform, and all participants self-reported as fluent native English speakers on Prolific's demographic prescreen. Participants each took part in only one experiment. Experiment 1 took place between May and July 2021, experiment 2 between March and August 2022, and experiment 3 in October 2022. As games varied in length depending on the number of participants, we paid participants based on group size, with the goal of a \$10 hourly rate.  Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, \$10 for 4-player games, and \$11 for 5- and 6-player games. When one player had the speaker role for the entirety of a 6-player game, they gained an additional \$2 bonus. Across all games, each participant could earn up to \$2.88 in performance bonuses. A total of 1319 people participated across the 3 experiments, for roughly 20 games in each condition in experiments 1 and 2 and 40 games per condition in experiment 3. A breakdown of number of games and participants in each condition is shown in the Supplement. 

## Materials

We used the 12 tangram images used by @hawkins2020 and @clark1986. These images were displayed in a grid with order randomized for each participant (thus descriptions such as "top left" were ineffective as the image might be in a different place on the speaker's and listeners' screens). The same images were used every block. 

## Procedure

The experimental procedure was very similar across the three experiments. We first describe the procedure used in experiment 1 and then describe the differences in later experiments. 

### Experiment 1
From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages explaining the game. Participants had to pass a quiz on the instructions to be able to play the game. They were then directed to a "waiting room" screen until their partner(s) were ready.

On each trial, the speaker described the highlighted tangram image so that the listeners could identify and click it. All participants were free to use the chat box to communicate, but listeners could only click once the speaker had sent a message. Once a listener clicked, they could not change their selection. There was no signal to the speaker or other listeners about who had already made a selection. 

Once all listeners had selected (or a 3-minute timer ran out), participants were given feedback. Listeners learned whether they had chosen correctly or not; listeners who were incorrect were not told the correct answer. The speaker saw which tangram each listener had selected, but listeners did not. Listeners got 4 points for each correct answer; the speaker got points equal to the average of the listeners' points. These points were translated into performance bonuses at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the speaker once. The same person was the speaker for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were speakers 3 times in 2-player games, twice in 3-player games, once or twice in 4 and 5-player games, and once in 6-player games. Rotating the speaker was chosen in this first experiment to keep participants more equally engaged (the speaker role is more work), and to provide a more robust test of our hyppotheses regarding efficiency and convention formation. 

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

### Experiment 2
Experiment 2 consisted of three different variations on Experiment 1, all conducted in 6-player games. Each of these conditions differed from the experiment 1 baseline in one way. The consistent speaker condition differed only in that one person was designated the speaker for the entire game, rather than having the speaker role rotate. The full feedback condition differed from experiment 1 in that all participants were shown what each person had selected and what the right answer was; listeners still saw text saying whether they individually were right or wrong. This condition was similar to some dyadic work, such as @hawkins2020, where listeners were shown the right answer during feedback. For the thin condition, we altered the chatbox interface for listeners. Instead of a textbox, listeners had 4 buttons, each of which sent a different emoji to the chat. Listeners were given suggested meanings for the 4 emojis during instructions. They could send the emojis as often as desired, for instance, initially indicating confusion, and later indicating understanding. In addition, we added notifications that appeared in the chat box saying when a player had made a selection. 

### Experiment 3

The thin channel condition in experiment 3 was the same as the thin condition in experiment 2, above. The thick condition combined the two group coherency enhancing variations from experiment 2: one person was the designated speaker throughout, and the feedback to participants included the right answer and what each player had selected. Across both conditions in experiment 3, notifications were sent to the chat to indicate when a participant had made a selection. 

## Data pre-processing and exclusions

Participants could use the chat box freely, which meant that the chat transcript contained some non-referential language. The first author skimmed the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about how well the task was going, and confirmations or denials ("ok", "got it", "yes", "no"). We excluded these utterances from our analyses. Note that chat lines sometimes included non-referential words in addition to words referring to the tangrams ("ok, so it looks like a zombie", "yes, the one with legs"); these lines were retained intact. 

In experiments 1 and 2, games did not start if there were not enough participants and ended if any participant disconnected. In experiment 3, games started after a waiting period even if they were not full and continued even after a participant disconnected (with speaker role reassigned if necessary), unless the game dropped below 2 players. The distribution of players in these games that were initially recruited to be 6 player games is in Supplement Figure 1. The realities of online recruitment and disconnection meant that the number of games varied between conditions. We excluded incomplete blocks from analyses, but included complete blocks from partial games (See Supplement Table 1).

When skimming transcripts to tag non-referential utterances, we noticed that one game in the 6-player thick condition had a speaker who did not give any sort of coherent descriptions, even with substantial listener prompting. We excluded this game from analyses. 

## Modelling strategy

We fit all regression models in brms [@burkner2018] with weakly regularizing priors.
We were often unable to fit the full mixed effects structure that we had pre-registered in a reasonable amount of time, so we included what hierarchical effects were reasonable. (All model results and priors and formulae are reported in the Supplement). 
Models of listener accuracy were logistic models with normal(0,1) priors for both betas and sd. 
Models of speaker efficiency were run as linear models with an intercept prior of normal(12,20), a beta prior of normal(0,10), an sd prior of normal(0,5) and a correlation prior of lkj(1). 
For all of the models of SBERT similarity, we used linear models with the priors normal(.5,.2) for intercept, normal(0,.1) for beta, and normal(0,.05) for sd. 

We also needed to decide how to handle dropout in Experiment 3, as some of the 6-player games did retain all 6 players for the entire game. 
Our decision was to follow an intent-to-treat analysis and treat data as missing completely at random. 
We note that this choice will underestimate differences between 2-player and (genuine) 6-player games, by labeling some smaller groups as 6-player groups. 

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent


