---
title: Interaction structure constrains the emergence of conventions in group communication

author:
  - name: Veronica Boyce
    email: vboyce@stanford.edu 
    affiliation:
      - Stanford 
    footnote:
      - corresp
  - name: Robert Hawkins
    affiliation: 
      - Princeton
  - name: Noah D. Goodman
    affiliation: 
      - Stanford
  - name: Michael C. Frank 
    affiliation: 
      - Stanford
address:
  - code: Stanford
    address: Stanford University 
  - code: Princeton
    address: Princeton University
footnote:
  - code: corresp
    text: "Corresponding author. Email: vboyce@stanford.edu"
bibliography: ["papers.bib"] # Replace with one or more of your own bibtex files. Better BibTeX for Zotero is your friend
csl: dmk-format.csl # Use any CSL style. See https://www.zotero.org/styles for a good list. Ignored if citation_package: natbib
link-citations: TRUE
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{angles,positioning,arrows.meta, quotes, shapes, shapes.geometric}
  - \usepackage{graphicx}
output:
  bookdown::pdf_document2:
    toc: FALSE
    keep_tex: TRUE
    template: generic_article_template.tex
    #md_extensions: "-autolink_bare_uris"
    number_sections: FALSE
    citation_package: default # Can also be "natbib"
lang: en # Main document language in BCP47 format
geometry: "margin=25mm"
papersize: a4
#linestretch: 2 # for double spacing
endfloat: FALSE # Set to TRUE to turn on latex endfloat package to place figures and tables at end of document
# endfloatoption: # See endfloat documentation for more possibilities
#   - tablesfirst # Default
#   - nomarkers # Default
numberlines: FALSE
authblk: TRUE # FALSE = author affiliations in footnotes; TRUE = author affiliations in a block below author names
footnotehyper: FALSE # TRUE will give you enhanced table footnote capabilities. Set to FALSE to be able to use French blocks. Needed due to what appears to be a latex bug.
urlcolor: blue
linkcolor: blue
citecolor: blue
graphics: TRUE # Needed to be able to include images
tables: TRUE # Needed to be able to include tables

---

<!---------------------- Abstract --------------------->

::: {.abstract data-latex="" lang=en}

Multi-party communication is ubiquitous, but the need to take multiple interlocuter's perspectives into account presents challenges not found in dyadic communication. One test case for communication is iterated reference games, where the phenomenon of reduction over repeated reference is well-attested in dyadic contexts and could explain how pairs of people build shared meanings. We extend the repeated reference game paradigm to groups of 2 to 6 people under varied interaction structure constraints across 313 games (1319 participants). Across conditions, groups shorten their utterances and form shared descriptions. Smaller groups and groups with thicker communication channels converge to shared conventions more rapidly than larger groups with thin communication channels. [TODO need another sentence translating this back to the unique challenges of multi-party communication and exposing the relevance of the results for theory/application (e.g. 'Taken together, these results provide new insight into the conditions under which group communication can thrive, with implications for eduction, management, and ...')] Taken together, these results provide new insight into the conditions under which group communication can succeed and even thrive. 

:::



<!------------ Main text -------------------->

```{r set-up, include=FALSE}
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())


knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.crop = F, out.width = "100%", dpi=300,
                      fig.pos = "tb", fig.path='figs/', fig.env="figure",
                      echo=F, warning=F, cache=T, 
                      message=F, sanitize = T)

color_scheme_1 <- c("2"="#FFBDD4", "5"="#A12EFF", "3"="#FF7DF0","6"="#6940FF","4"="#D24AFF")
color_scheme_2 <- c( "6 full feedback"="#425df5", "6 consistent speaker"="#00A2FF","6 thin"="#D47E04")

color_scheme_3 <- c("2 thin"="#FFDA09","6 thin"="#D47E04", 
                    "2 thick"="#77F3DB","6 thick"="#00BDA8")


		
ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  |> 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"




image_location="write-ups/images"

msum_loc="code/paper_mods/summary"
mform_loc="code/paper_mods/formulae"

source(here("code/prep_ms.R"))


stats <- function(model, row, decimal=2){
  model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c("$\\beta=", model[row,2],",\\:95\\%\\:\\mathrm{CrI}=",model[row,3], "$")
}

stats_text  <- function(model, row, decimal=2){
    model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c("", model[row,2],", ($95\\%\\mathrm{CrI}=",model[row,3], "$)")
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
  str_replace_all("\\*"," $\\\\times$ ") |> 
  str_replace_all("\\+", "&nbsp;+ ") |> 
   str_replace_all("~", "$\\\\sim$ ")
}
```

```{r count, include=F}

games <- combined_results |> select(gameId) |> unique() |> nrow() 

players <- combined_results |> select(gameId, numPlayers) |> unique() |> summarize(players=sum(numPlayers))

words <- combined_chat |> ungroup() |> select(total_num_words) |> summarize(words=sum(total_num_words)) 

```

TODO what does Mike's abstract comment mean ("question?")
TODO forshadow interaction structure in intro (re group size and channel width) 
(TODO check ordering of legends on Figures! )
TODO fix discussion

TODO for supplement: fulfill promised analysis of 
Written about 6thin in experiment 2 and for 2 and 6 thin in 3
Additionally, exclusive to this condition, we will analyse the distribution of emojiâ€™s produced as a function of block and its relation to accuracy and speaker utterance length.

TODO update crossrefs with supplement



---


While most psychological studies of communication focus on one-on-one conversations, much of our daily lives center around communicating in larger groups. In school, children sit in classrooms with peers and teachers; at home, we have dinner with multiple friends and family; and in the office, we attend meetings with colleagues and managers. 

Communicating in groups can present challenges not present in two-party (dyadic) communication [@branigan2006;@ginzburg2005;@traum2004]. Speakers need to produce utterances for multiple listeners who may have different levels of background understanding [@horton2005; @horton2002;@yoon2018; @yoon2014; @weber2003;@fox-tree2013]. Listeners must comprehend utterances that are less tailored to them due to the presence of other interlocuters [@fay2000; @carletta1998; @metzing2003; @yoon2019; @rogers2013; @cohngordon; @schober1989;@tolins2016]. In spite of these considerable challenges, however, speakers are often able to navigate multi-party settings with ease. What aspects of communication channels and interaction structure determine how efficiently a group can communicate?

One component of effective communication is establishing shared reference, that is a joint understanding among interlocuters that a certain phrase uttered by the speaker refers to a certain object or idea in the world. Sometimes, shared reference is the end goal (in for example, "can you hand me the small bowl?"), and sometimes shared reference is a pre-requisite to larger conversational goals (example, in a debate, interlocuters still need a mutual understanding of what the words mean).  In many cases, conventional semantic meanings of words from a shared language plus culturally shared conventions around language use are sufficient for two people to establish shared reference. In other cases, mappings between words and objects may rely on shared history to be understood (ex. "pass me my favorite cup.").

Reference is a component of communication that can be isolated and tested in experimentally manipulated contexts, so it has been used as a case study for efficient communication more broadly TODO ADD CITATIONS. Some reference games examine how interlocuters communicate in the absence of conventional labels. In these cases, interlocuters must invent ad-hoc reference expressions to communicate about objects without canonical names. 

The formation of these new reference expressions is well-studied in dyadic contexts. @clark1986 established an experimental method for studying the emergence of new referring expressions that has now become standard [building on @krauss1964;@krauss1966]. Two participants see the same set of figures; the speaker describes each figure in turn so the listener can select the target from the set of figures. The speaker and listener repeat this process many times with the same images. 

Early descriptions are long and make reference to multiple features in the figure, but over the course of the game, shorthand conventional names for each figure emerge; this shortening of utterances is called 'reduction'. Not only are later utterances shorter than earlier utterances, but later utterances are a tacitly agreed upon name, understandable within the dyad, but different from the conventions chosen by other dyads. 

Recently, online participant recruitment and web-based experiments have made it possible to study this convergence in larger populations [@hawkins2020;@haber2019]. In line with results from face-to-face, oral paradigms, in these online, chat-based paradigms, speakers reduced their utterances, producing fewer words per image in later blocks than in earlier blocks. (Throughout this paper, we use "speaker" and "listener" to refer to the roles describing and selecting targets, regardless of communication modality.)

What aspects of conversational infrastructure are needed to support this reduction to efficient referring expressions? In the current work, we address how components of interaction structure, including group size and communication channels, shape how successfully groups form partner-specific conventionalized names for target objects over the course of an iterated reference game. We recruited `r players` participants who were organized into `r games` groups distributed across 3 online experiments and 11 conditions. Collectively, players produced `r words |> round(-3)` words during their games. We analysed the games along 4 metrics: two group performance metrics of 1) listener accuracy and 2) number of words produced per trial, as well as two computational measures of semantic similarity that addressed 3) how utterances converge towards a conventions with a game and 4) how utterances diverge from descriptions in other games as they become more partner-specific. 




```{r diagram,  fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap="A: Diagram of the experimental space. Experiments varied along 3 dimensions: Group size, group coherence, and listener backchannel. Each condition is shown as a dot. Experiment 1 (pink labels) varied group size from 2-6 players while holding group coherence and backchannel constant. Experiment 2 (blue labels) keep group size constant at 6 and varied the other dimensions. Relative to experiment 1, 6 consistent speaker and 6 full feedback each added one component of group coherence, and 6 thin reduced the backchannel. Experiment 3 (green labels) tested 4 corners of the space, crossing group size (2 or 6 players) with thin games (low coherence, low backchannel) or thick games (high coherence, high backchannel).   B: Each trial a speaker described a target image to the listeners, and this process repeated for all 12 images to comprise a block, and the block repeated for a total of 6 iterations. \\ C: Differences between conditions. See text for explanation."}
knitr::include_graphics("expt-diagram2.pdf")

```
# Results

Reference game experiments can vary along numerous dimensions: how many people are participating, whether they have any prior relationships with one another, what roles they have within the game, what types of targets they are describing, what type of communication channel they have, and what sorts of feedback they get on their selections, among others. This makes for a very large space of possible iterated reference game experiments [@almaatouq2022]! 

We focused on dimensions that could affect how groups interacted with each other and sampled along four dimensions that parameterized the interaction space. Our experiments varied along the dimensions of game size, speaker rotation, level of feedback, and the form of the listener backchannel; other possible dimensions, such as what the target images were or if participants had prior relationships, were held constant across games. Across the three experiments, we sampled 11 different points in the experimental space, illustrated in Figure \@ref(fig:diagram)A. 

All games followed the iterated reference game framework, where a set of target images are described repeatedly over a series of blocks. Our games used 12 tangram images, previously used in in  @clark1986 and @hawkins2020. Our games were run online, with crowd-sourced participants who were strangers to one another. The speaker knew which image was the target, and their goal was to describe it to the listeners over a chat interface so each listener could select the target. After all listeners had selected, players received feedback on the selections. The process repeated with the same speaker describing each of the 12 images to form one block. The games consisted of 6 blocks, for a total of 72 trials, where each image was described 6 times over the course of the game (Figure \@ref(fig:diagram)B). 

In experiment 1, we varied the size of the games continuously from *2 to 6 players* while keeping other factors constant to explore what how performance varied across group size. For these conditions, the *speaker role rotated* after each block, so that all players had at least one turn as speaker. We gave *limited feedback* to listeners, showing each listener only whether their individual selection was correct or not, but not revealing others' selections or the right answer. Listeners had access to a *chat box* as their backchannel, so they could freely type questions and offer their own descriptions to the group. 

In experiment 2, we explored varying different factors within 6-player games. We tried two different variations that we thought might improve group coherence and lead to better performance: having a *consistent speaker* rather than a rotating speaker, and separately, showing all the listeners *full feedback* on what each person in the group had selected and what the right answer had been. Additionally, we tested the role of listener contributions in establishing mutual understanding with a condition where listeners' backchannel was limited to four *emojis*. Listeners could send 4 discrete messages (green check, thinking face, red x, and laughing-crying face) to the chat. This limited backchannel allowed listeners to convey valence and level of comprehension, but not to contribute any referential content.

In experiment 3, we crossed the extremes of group size from experiment 1 (2 or 6 people) with extremes of group interactions from experiment 2. In the *thick* condition, we combined a consistent speaker with full feedback to create *high group coherence* and let listeners use the chat freely. In the *thin* condition, we repeated the emoji backchannel condition from experiment 2, which had *low group coherence* and an emoji backchannel. The 2-player thick game was similar to the condition used in @hawkins2020. 

<!--We analysed these 3 experiments on 4 key measures: listener accuracy, speaker reduction, convergence of descriptions within games, and divergence of descriptions between games. -->


## Group Performance

In dyadic reference games, listener accuracy remains high while the amount of referential language decreases dramatically over repetitions [@clark1986, @hawkins2020]. Listener accuracy measures how successful speakers are at communicating the target referent to the listeners. The combination of accuracy and reduction of speaker descriptions indicates that speaker and listeners have formed a shared conceptualization of the target that can be distilled into a shorter form, while still retaining the same level of informativity to listeners.


```{r behavioral, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Behavioral results across all three experiments. A-C. Listener accuracy at selecting the target image. Dots are per condition, per block estimates with 95\\% bootstrapped CIs. Smooths are binomial fit lines.   D-F. Number of words said by the speaker each trial. Faint dots represent individual trials from individual games. Smooths are quadratic fit lines. Y-axis is truncated, and a few outliers points are not visible. "}
# accuracy

# 1
one <- combined_results |> filter(condition=="rotate") |> group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(numPlayers=as.character(numPlayers)) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=numPlayers))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
  annotate("text", x=1,y=1,label="A", size=6, fontface="bold")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_1)
#2

two <- combined_results |> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(condition=case_when(
    condition=="no_rotate" ~ "6 consistent speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin"),
    condition=factor(condition, levels=c("6 full feedback", "6 consistent speaker", "6 thin"))) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  #labs(x="Block", y="Fraction correctly selected", color="")+
  labs(x="", y="", color="")+
    annotate("text", x=1,y=1,label="B", size=6, fontface="bold")+     
  annotate("text", x=3.5,y=1,label="Accuracy", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+ 
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
        scale_color_manual(values=color_scheme_2)

#3
 three <- combined_results |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> group_by(playerId,repNum, gameId, condition) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |>
   mutate(condition=str_replace(condition, "_", " "),
          condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin"))) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
 # labs(x="Block", y="Fraction correctly selected", color="")+
     annotate("text", x=1,y=1,label="C", size=6, fontface="bold")+
     labs(x="", y="", color="")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.1) ) )+
   scale_color_manual(values=color_scheme_3)
 
 acc <- plot_grid(one, two, three, nrow=1, rel_widths = c(1.05, 1, 1))
 

#1

one <- combined_chat |> filter(condition=="rotate") |>  filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, numPlayers) |> 
  summarize(words=sum(total_num_words)) |>
    mutate(numPlayers=as.character(numPlayers)) |> 
ggplot(aes(x=repNum+1, y=words, color=numPlayers))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
annotate("text", x=1,y=60,label="D", size=6, fontface="bold")+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.x=element_blank())+
  scale_color_manual(values=color_scheme_1)


#2

two <- combined_chat|> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram,condition) |> 
  summarize(words=sum(total_num_words)) |> 
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 consistent speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin"),
        condition=factor(condition, levels=c("6 full feedback", "6 consistent speaker", "6 thin"))) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
    labs(x="", y="", color="")+
annotate("text", x=1,y=60,label="E", size=6, fontface="bold")+
  annotate("text", x=3.5,y=60,label="Words from speaker", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_blank())+
    scale_color_manual(values=color_scheme_2)

#3


three <- combined_chat |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, condition) |> 
  summarize(words=sum(total_num_words)) |> 
  mutate(condition=str_replace(condition, "_", " "),
                   condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin"))) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
  geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
    labs(x="", y="", color="")+
annotate("text", x=1,y=60,label="F", size=6, fontface="bold")+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_blank())+
  scale_color_manual(values=color_scheme_3)

red <- plot_grid(one,two, three, nrow=1, rel_widths = c(1.05,1,1))

plot_grid(acc, red, nrow=2, rel_heights = c(.8,1))
```
```{r}
acc_1 <- read_rds(here(msum_loc,"acc_1.rds"))

acc_2a <- read_rds(here(msum_loc,"acc_2a.rds"))

acc_2b <- read_rds(here(msum_loc,"acc_2b.rds"))

acc_2c <- read_rds(here(msum_loc,"acc_2c.rds"))

acc_3 <- read_rds(here(msum_loc,"acc_3.rds"))


```




### Accuracy was high and increased.


In our experiments, listener accuracy rose over repetitions in all conditions and approached ceiling in most conditions; however, 6-player thin games were the least accurate (Figure \@ref(fig:behavioral)A-C). We constructed logistic models to predict accuracy as a function of the manipulated variables, block, and their interactions. Both initial accuracy and improvement rate showed some variation based on group size and channel width, with smaller and thicker games having better and faster improving accuracy in some experiments. 

Group size did not have a strong effect on initial accuracy when measured continuously in the baseline condition (Figure \@ref(fig:behavioral)A, `r stats(acc_1,4)`), but 6-player thick games had lower accuracy than 2-player thick games (Figure \@ref(fig:behavioral)C, `r stats(acc_3, 6)`). Improvement rates were similar, with no effect of group size in the baseline condition (`r stats(acc_1,2)`), but 6-person thick games were slower to improve than 2-person thick games (`r stats(acc_3, 3)`). 

Initial accuracy was somewhat higher for consistent speaker games (`r stats(acc_2a,2)`) and full feedback games (`r stats(acc_2b, 2)`) than for 6 thin games (Figure \@ref(fig:behavioral)B, `r stats(acc_2c, 2)`), but the difference between thick and thin 2-player games was not reliable (Figure \@ref(fig:behavioral)C, `r stats(acc_3,5)`). Similarly, improvement rates were higher for consistent speaker games (`r stats(acc_2a,1)`) and full feedback games (`r stats(acc_2b, 1)`) than for 6 thin games ( `r stats(acc_2c, 1)`), but the difference in improvement rates between thick and thin 2-player games was not reliable (`r stats(acc_3,2)`). 

Across experiments, the high and increasing levels of accuracy indicate that across all of these conditions, participants are able to succeed in communicating about the images. 


```{r}
red_1 <- read_rds(here(msum_loc, "red_1.rds"))

red_2a <- read_rds(here(msum_loc,"red_2a.rds"))

red_2b <- read_rds(here(msum_loc,"red_2b.rds"))

red_2c <- read_rds(here(msum_loc,"red_2c.rds"))

red_3 <- read_rds(here(msum_loc, "red_3.rds"))

```


### Speakers said more in larger games.

Speakers in larger games were more verbose than speakers in smaller games, and in some cases, these speakers showed sharper reduction from initial wordiness to eventual concision (Figure \@ref(fig:behavioral)D-F). We constructed linear models of the number of words a speaker said each trial as a function of condition and block. 

Speakers in larger groups said more to start with than speakers in smaller groups in both baseline conditions (Figure \@ref(fig:behavioral)D, `r stats_text(red_1,4)`) and thick conditions (Figure \@ref(fig:behavioral)F, `r stats(red_3,7)`). The numbers of words said decreased at a similar rate across group size in baseline conditions (`r stats(red_1,2)`), but 6-player thick games decreased faster than 2-player thick games (`r stats(red_3, 4)`).  

Thin games were similar to thick games in initial verbosity (Figure \@ref(fig:behavioral)F, `r stats(red_3, 5)`) and reduction rate ( `r stats(red_3, 2)`).
  
The main effect of being one block later was `r stats_text(red_1,1)` words per trial in experiment 1; `r stats_text(red_2a,1)` words for 6 consistent speaker; `r stats_text(red_2b,1)` words for 6 full feedback, `r stats_text(red_2c,1)` words for 6 thin; and `r stats_text(red_3,1)` for the 2 thick condition of experiment 3. 


Overall, all conditions exhibited reduction, with variations in the speed at which speaker utterances got shorter which partially covaried with how initially verbose speakers were. 

```{r}
list_1 <- read_rds(here(msum_loc, "list_1.rds"))
list_spec_1 <- read_rds(here(mform_loc, "list_1.rds"))

anylist_1 <- read_rds(here(msum_loc, "anylist_1.rds"))
anylist_spec_1 <- read_rds(here(mform_loc, "anylist_1.rds"))


```

### Larger groups lead to more listener backchannels. 

Listeners talk much less than speakers, and listener contributions are concentrated in early trials. The more listeners, the more likely it was that some listener talked, and the more listeners said if they talked (TODO CROSSREF SUPPLEMENT IMAGE). We constructed a logistic regression predicting the presence of any listener utterances in experiment 1 as a function of group size and block, and a linear regression predicting the number of words said by listeners in experiment 1 as a function of group size and block. 

The number of trials where any listener said anything related to the image was higher in larger groups (`r stats(anylist_1, 4)`) and declined across blocks (`r stats(anylist_1, 1)`). When referential language was produced, larger groups produced more language (`r stats(list_1, 4)`), but the difference in group size closed in later blocks (`r stats(list_1, 2)`). 

This pattern is consistent with early listener involvement in establishing a common conceptualization by asking questions and offering alternative descriptions. Once a shared reference description was in place, listener descriptions are rarer and more perfunctory. 

Emoji use is not directly comparable to referential language, but similar trends occurred in the thin games. Emoji use was more common in the 6-player games than the 2-player games and decreased over the course of the game (SUPP FIGURE). 

### Interim summary 

According to these metrics of group performance and efficiency in iterated reference games, larger games are similar to smaller games, except with more talking, especially early in the games. Larger groups seem to generally take the time to elaborate descriptions in order for most listeners to understand, especially when listeners can ask specific clarifying questions. This leads to more communication by both speaker and listeners in early rounds for larger games, sometimes followed by sharp reduction once a shared conceptualization is agreed upon. 

## Linguistic Content


```{r sbert-diagram, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Example utterances describing the shown tangram figure produced by two 3-player games in Experiment 1. To measure convergence within a game (blue), we measured the cosine similarity between SBERT embeddings of descriptions and the embedding of the round 6 utterance (taken to be the convention). Higher cosine similarity indicates more similar meaning. To measure divergence between games (green), we measured the similarity between embeddings of utterances from the same round across games."}
knitr::include_graphics("sbert.pdf")

```



Partner-specific reduction is characterized by high accuracy and shortening utterances, but the key phenomena of interest is that pairs are forming joint conventions about how to refer to particular images. How well groups are able to do this may vary based on game condition: we might predict that it's easier for two people to agree on a label, but harder when the labels are coming from 6 different individuals who may have different conceptualizations. Convergence to a shared name might be faster if only one person provides the labels, since they can match their own labels. Feedback and listener contributions may help a group get on the same page about what descriptions go with what images, letting a speaker reduce to shorthand expressions. While initially many groups may overlap with descriptions that include descriptions of the shapes or body parts in the image, their descriptions are predicted to become increasingly dissimilar as these descriptive portions drop out, leaving just the conventionalized nicknames that are group-dependent.

To assess the linguistic patterns of speaker descriptions, we examine the *semantic similarity* of descriptions within and across games. We quantified description similarity by concatenating speaker messages together within a trial and embedding this description into a high-dimensional vector space using SBERT. SBERT is a BERT-based sentence embedder designed to map semantically similar sentences to embeddings that are near each other in embedding space, which enables making semantically meaningful comparisons between sentences by taking pairwise cosine similarities between the embeddings [@reimers2019]. Thus, we measure the similarity between two utterances by the cosine similarity between their embeddings.

We looked at the similarity between utterances within a game compared to the final description of that image as a measure of convergence to a shared nickname. We looked at similarity between utterances across games for the same image in the same block as a measure of divergence between games, predicted to occur as each develops a different nickname. Figure \@ref(fig:sbert-diagram) illustrates these two measures with example concatenated utterances and their within-game and between-game cosine similarities. 


```{r sbert, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Language similarity results measured with pairwise cosine similarity between embeddings of two utterances. A-C. Convergence of descriptions within games as measured by similarity between an utterance from block 1-5 to the block 6 utterance in the same game for the same image. Dots are per-game averages, smooths are quadratic. D-F. Divergence of descriptions across games as measured by the similarity between two utterances produced for the same image by different groups in the same block. Dots are per-image averages, smooths are quadratic."}
#convergence

one_two_converge <- read_rds(here("code/models/one_two_converge.rds"))
three_converge <- read_rds(here("code/models/three_converge.rds"))
#1
one <- one_two_converge |> filter(condition %in% c("2", "3","4","5","6")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="")+

  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  annotate("text", x=1,y=1,label="A", size=6, fontface="bold")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- one_two_converge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 consistent speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  #guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
 # labs(y="Cosine Similarity", x="Block", color="")+
    labs(x="", y="", color="")+
    annotate("text", x=1,y=1,label="B", size=6, fontface="bold")+
annotate("text", x=3,y=1,label="Within game", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),

        legend.text=element_text(size=14),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+    scale_color_manual(values=color_scheme_2)



#3



three <- three_converge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |>  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
 # labs(y="Cosine Similarity", x="Block", color="")+

    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  annotate("text", x=1,y=1,label="C", size=6, fontface="bold")+
    labs(x="", y="", color="")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14),
        axis.title.y = element_blank())+
  scale_color_manual(values=color_scheme_3)

conv <- plot_grid(one, two, three, nrow=1, rel_widths = c(1.05, 1,1))

one_two_diverge <- read_rds(here("code/models/one_two_diverge.rds"))
three_diverge <- read_rds(here("code/models/three_diverge.rds"))
# divergence

#1
one <-  one_two_diverge |> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  #  labs(x="", y="", color="")+
  annotate("text", x=1,y=.7,label="D", size=6, fontface="bold")+
  theme(legend.position="bottom",
        axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_diverge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 consistent speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin"),
     condition=factor(condition, levels=c("6 full feedback", "6 consistent speaker", "6 thin"))) |>
                              ggplot( aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.1,.7))+
  labs(x="", y="", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
    annotate("text", x=1,y=.7,label="E", size=6, fontface="bold")+
annotate("text", x=3.5,y=.7,label="Between games", size=6)+
  theme(legend.position="bottom",
                axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_diverge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1)),                    condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin"))) |> 
  ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
    labs(x="", y="", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) )+
  annotate("text", x=1,y=.7,label="F", size=6, fontface="bold")+
  theme(legend.position="bottom",
                axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+
scale_color_manual(values=color_scheme_3)

div <- plot_grid(one,two,three, nrow=1, rel_widths = c(1.05, 1, 1))

plot_grid(conv, div, nrow=2,  rel_heights = c(.8,1))
```


```{r}
tolast_1 <- read_rds(here(msum_loc, "tolast_1.rds"))

tonext_1 <- read_rds(here(msum_loc, "tonext_1.rds"))

tolast_2a <- read_rds(here(msum_loc, "tolast_2a.rds"))

tonext_2a <- read_rds(here(msum_loc, "tonext_2a.rds"))

tolast_2b <- read_rds(here(msum_loc, "tolast_2b.rds"))

tonext_2b <- read_rds(here(msum_loc, "tonext_2b.rds"))

tolast_2c <- read_rds(here(msum_loc, "tolast_2c.rds"))

tonext_2c <- read_rds(here(msum_loc, "tonext_2c.rds"))

tolast_3 <- read_rds(here(msum_loc, "tolast_3.rds"))

tonext_3 <- read_rds(here(msum_loc, "tonext_3.rds"))

```


### Descriptions converge within groups. 

Across conditions, speaker descriptions increased in semantic similarity to the final description over repetition; convergence was fastest in smaller and higher coherence groups, and was least strong in the 6-player thin condition (Figure \@ref(fig:sbert)A-C). We modeled semantic convergence by looking at the similarity between a block 1-5 utterance and the corresponding block 6 utterance as a function of the earlier block number and condition. 

The similarity of the first utterance to the last utterance was invariant across group size (`r stats(tolast_1, 1,3)`), but smaller groups converged faster (Figure \@ref(fig:sbert)A, `r stats(tolast_1, 3,3)`). The 6-player thick games started off with greater distance between first and last utterances than 2-player thick games (`r stats(tolast_3, 7,3)`) but closed the gap over time (`r stats(tolast_3, 6,3)`). Overall, smaller games reach a stable description faster than larger games. 

Convergence was especially rapid for the consistent speaker condition  where all the utterances come from the same person (Figure \@ref(fig:sbert)B, `r stats(tolast_2a, 1,3)`). Convergence was slower in thin games than thick games (Figure \@ref(fig:sbert)C, `r stats(tolast_3, 4,3)`). 

Beyond the slower convergence in thin games, 6-player thin games showed substantially slower convergence even compared to 2-player thin games (expt 3, `r stats(tolast_3, 5,3)`). 

Across games, convergence towards the last utterance was driven by cumulative increasing similarity between pairs of utterances in adjacent blocks (see TODO SUPPLMENT). In early rounds, descriptions could change substantially between rounds, but by later rounds, many descriptions had already reduced and solidified and varied little round to round. 

All conditions showed some convergence toward a conventional nickname for the picture, but the speed of convergence was affected both by group size and channel width. Overall, descriptions were more similar if provided by the same person, if fewer people were in the game, and if listeners could contribute via a text channel. 

```{r}
div_1 <- read_rds(here(msum_loc, "div_1.rds"))

div_2a <- read_rds(here(msum_loc, "div_2a.rds"))

div_2b <- read_rds(here(msum_loc, "div_2b.rds"))

div_2c <- read_rds(here(msum_loc, "div_2c.rds"))
div_3 <- read_rds(here(msum_loc, "div_3.rds"))
```


### Language in thicker games diverges faster from other games. 

Over repetitions, speaker descriptions diverged from descriptions used in other groups: divergence was fastest in groups with thick communication channels, while the 6-player thin condition games barely diverged at all (Figure \@ref(fig:sbert)D-F). We modeled semantic divergence by looking at the similarity between a pair of utterances for the same image from the same block across different games as a function of the block number and condition. 

Initial similarities between groups were the same regardless of group size (Figure \@ref(fig:sbert)D, `r stats(div_1, 3,3)`), but smaller groups diverged from each other slightly faster than larger groups (`r stats(div_1,2,3)`). The 2-player thick condition diverged at a moderate speed (Figure \@ref(fig:sbert)F, `r stats(div_3, 1,3)`), and the 6-player thick condition had initially higher similarity (`r stats(div_3, 7,3)` and faster divergence (`r stats(div_3, 4,3)` in comparison.

Divergence was stronger in the consistent speaker (Figure \@ref(fig:sbert)E, `r stats(div_2a, 1,3)`) and full feedback conditions ( `r stats(div_2b, 1,3)`) than in the 6 thin condition ( `r stats(div_2c, 1,3)`). Compared to the 2-player thick games, 2-player thin games started with slightly higher similarity (Figure \@ref(fig:sbert)F `r stats(div_3, 5, 3)`) and diverged slightly more slowly (`r stats(div_3, 2,3)`). 

The most noticeable effect in this analysis was that the 6-player thin games diverged much more slowly than the other conditions. The interaction between larger group size and thinner channel was associated with a much lower rate of divergence (Figure \@ref(fig:sbert)F, `r stats(div_3, 3,3)`). 

Divergence between groups, a sign of increasing group-specificity of descriptions, occurred across all conditions. Smaller games and games with thicker channels diverged more than larger or thinner games. In particular, the 6-player thin games showed a qualitatively different pattern of minimal divergence, diverging even less than would have been expected based on the rates in the other 3 conditions in the 2x2 experiment. 

### Interim summary 

Smaller groups show higher within-group similarities and between-group differences, sometimes showing up in the initial round and sometimes developing as a change over time. The thicker the games the faster and stronger the divergence and convergence patterns. The combination of a large game and a thin communication channel hampers within-game convergence and between-game divergence much more than either game size or thinness independently, as seen in the difference between 6 thin and either 2 thin or 6 thick. 

# General Discussion

Communication often occurs in multi-party settings, but research on referential communication often does not. In dyadic work, iterated reference games have been used to establish a phenomena of reduction over repeated reference, characterized by speaker-listener pairs creating short nicknames that they mutually understand, but which are not shared by other groups. In this work, we asked how this process of reference formation unfolds under varying interaction structures. 

## All conditions show hallmarks of reduction, and interaction structure constrains speed of convention formation. 
Across 3 online experiments and 11 experimental conditions, we varied game features including group size, form of listener backchannel, and degree of group coherence. All conditions showed the hallmarks of reduction: increasing accuracy, reduction in speaker utterances, semantic convergence within games, and differentiation of descriptions between groups. Even with larger groups and more constrained means of communication, reduction still occurs. 

However, while results are directionally the same across conditions, the interaction structure of a group substantially affects how rapidly groups develop partner-specific conventions. Smaller groups and games with thicker communication channels converged faster and more robustly than games that were larger or had thinner communication channels. These factors add together to form the overall group experience. The differences between the 6-player thin condition and both the 2-player thin condition and other 6-player conditions point to an interaction: 2-player games can cope with limited feedback mechanisms, but 6-player games suffer without access to more feedback. Group dynamics differ depending on group size, and larger groups may be more sensitive to other factors affecting interaction structure. Multi-player groups thus make for a richer and more sensitive environment to study communication phenomena applicable to both pairs and small groups. 

## Reduction and partner-specific convention formation pattern separately. 
Theoretical approaches treat reduction in referring expression length as a consequence of partner-specific convention formation [@clark1986; @brennan1996; @yoon2014; @yoon2018], but in our current work, reduction and semantic measures of partner-specificity pattern differently in the 6-player thin condition. The 6-player thin games show much less divergence between games and convergence within games, even compared to the 2 thin and 6 thick conditions, but 6-player thin games showed smaller (and statistically inconconclusive) differences to 6 thick games for accuracy and reduction. This gap between the group performance measures and the semantic measures raises the possibility that it is possible to become more concise (and more accurate) without developing group-specific nicknames, but instead perhaps relying on group priors and reducing the amount of detail [@guilbeault2021]. This gap highlights the need to use measures of the type of language (and not just amount of language) when looking for convention-formation phenomena. 

## Limitations and future directions. 
Just within the general framework of iterated reference, there is a high dimensional feature space of possible experiments. We sampled only a few points along a few dimensions in the space that felt salient. In our experiment 3, we grouped some factors together in order to have more games in each condition: a fully factorial design would have been too expensive to power adequately. Future work could sample other points in the experimental space, perhaps exploring the effects of different target images, or groups of people with real-life prior connections. 

We cannot make claims about causal mechanisms between how experimental set-ups such as group size resulted in different outcomes: for instance, there are many differences between being in a 2-person group versus a 6-person group that could lead to the different outcomes. In a dyad, speakers can tailor their utterances to the one listener, but in large groups, speakers must balance the competing needs of different listeners [@schober1989;@tolins2016]. These effects likely vary by both the knowledge state of and communication channels available to the listeners [@fox-tree2013;@horton2002; @horton2005]. Further work digging into the language used and the interactions between participants might unearth plausible mechanisms for how differences in group size and interaction structure influence outcomes, and this in turn could then point towards future experimental conditions. 

## Conclusion 
Communication occurs across a broad range of situations, varying on many dimensions, including group size, medium of interaction, and group structure. A narrow focus on dyads with rich communication channels can lead to theories that mispredict how interactions play out in multi-party groups with varying interaction structure. Sampling from a broader range of communication space is necessary to better characterize the phenomena of interest.   

# Methods

For all experiments, we used Empirica [@almaatouq2020] to create real-time multi-player iterated reference games. In each game, one of the players started as the speaker who saw an array of tangrams with one highlighted and communicated which figure to click to the other players (listeners). After the speaker had identified each of the 12 images in turn, the process repeated with the same images, but a total of 6 blocks (72 trials). We recorded what participants said in the chat, as well as who selected what image and how long they took to make their selections. 

These experiments were designed sequentially and pre-registered individually.^[Experiment 1: https://osf.io/cn9f4 for the 2-4 player groups, and https://osf.io/rpz67 for the 5-6 player data run later. Experiment 2: consistent speaker at  https://osf.io/f9xyd, full feedback at  https://osf.io/j5zbm, and thin at  https://osf.io/k5f4t. Experiment 3: https://osf.io/untzy] We followed the analysis plan, although additional analyses were added to early experiments that were only pre-registered in later experiments. Results from some pre-registered models were omitted from the main text, but are shown in the supplement TODO.

## Participants

Participants were recruited using the Prolific platform, and all participants self-reported as fluent native English speakers on Prolific's demographic prescreen. Participants each took part in only one experiment. Experiment 1 took place between May and July 2021, experiment 2 between March and August 2022, and experiment 3 in October 2022. As games varied in length depending on the number of participants, we paid participants based on group size, with the goal of a \$10 hourly rate.  Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, \$10 for 4-player games, and \$11 for 5- and 6-player games. When one player had the speaker role for the entirety of a 6-player game, they gained an addition \$2 bonus. Across all games, each participant could early up to \$2.88 in performance bonuses. A total of 1319 people participated across the 3 experiments, for roughly 20 games in each condition in experiments 1 and 2 and 40 games per condition in experiment 3. A breakdown of number of games and participants in each condition is shown in TODO supplement.

## Materials

We used the 12 tangram images used by @hawkins2020 and @clark1986. These images were displayed in a grid with order randomized for each participant (thus descriptions such as "top left" were ineffective as the image might be in a different place on the speaker's and listeners' screens). The same images were used every block. 

## Procedure

The experimental procedure was very similar across the three experiments. We first describe the procedure used in experiment 1 and then describe the differences in later experiments. 

### Experiment 1
From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages explaining the game. Participants had to pass a quiz to be able to play the game. They were then directed to a "waiting room" screen until their partner(s) were ready.

Each trial, the speaker described the highlighted tangram image so that the listeners could identify and click it. All participants were free to use the chat box to communicate, but listeners could only click once the speaker had sent a message. Once a listener clicked, they could not change their selection. There was no signal to the speaker or other listeners about who had already made a selection. 

Once all listeners had selected (or a 3-minute timer ran out), participants were given feedback. Listeners learned whether they individually had chosen correctly or not; listeners who were incorrect were not told the correct answer. The speaker saw which tangram each listener had selected, but listeners did not. Listeners got 4 points for each correct answer; the speaker got points equal to the average of the listeners' points. These points translated into performance bonus at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the speaker once. The same person was the speaker for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were speakers 3 times in 2-player games, twice in 3-player games, once or twice in 4 and 5-player games, and once in 6-player games. Rotating the speaker was chosen to keep participants more equally engaged (the speaker role is more work), and to give a more robust test for reduction and convention. 

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

### Differences in experiment 2
Experiment 2 consisted of three different variations on Experiment 1, all conducted in 6-player games. Each of these conditions differed from the experiment 1 baseline in one way. The consistent speaker condition differed only in that one person was designated the speaker for the entire game, rather than having the speaker role rotate. The full feedback condition differed from experiment 1 in that all participants were shown what each person had selected and what the right answer was; listeners still saw text saying whether they individually were right or wrong. This was similar to some dyadic work, such as @hawkins2020 where listeners were shown what the right answer was during feedback. For the thin condition, we altered the chatbox interface for listeners. Instead of a textbox, listeners had 4 buttons, each of which sent a different emoji to the chat. Listeners were given suggested meanings for the 4 emojis during instructions. They could send the emojis as often as desired, for instance, initially indicating confusion, and later indicating understanding. In addition, we added notifications that appeared in the chat box saying when a player had made a selection. 

### Differences in experiment 3

The thin channel condition in experiment 3 was the same as the thin condition in experiment 2, above. The thick condition combined the two group coherency enhancing variations from experiment 2: one person was the designated speaker throughout, and the feedback participants received included the right answer and what each player had selected. Across both conditions in experiment 3, notifications were sent to the chat to indicate when a participant had made a selection. 

## Data pre-processing and exclusions

Participants could use the chat box freely, which meant that the chat transcript contained some non-referential language. The first author skimmed the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about how well the task was going, and confirmations or denials ("ok", "got it", "yes", "no"). We excluded these utterances from our analyses. Note that chat lines sometimes included non-referential words in addition to words referring to the tangrams ("ok, so it looks like a zombie", "yes, the one with legs"); these lines were retained intact. 

In experiments 1 and 2, games did not start if there were not enough participants and ended if any participant disconnected. In experiment 3, games started after a waiting period even if they were not full and continued even after a participant disconnected (with speaker role reassigned if necessary), unless the game would drop below 2 players. The distribution of players in these 6* player games is at TODO SUPPLEMENT! The realities of online recruitment and disconnection meant that the number of games varied between conditions. We excluded incomplete blocks from analyses, but included complete blocks from partial games (See SUPPLEMENT TABLE for counts).

When skimming transcripts to tag non-referential utterances, we noticed that one game in the 6-player thick game had a speaker who did not give any sort of coherent descriptions, even with substantial listener prompting. We excluded this game from analyses. 

## Modelling strategy
In experiment 3, some of the 6-player games did not have 6 players for the entire game. We do not model this, as it is unclear at what point in the game group size is most relevant. We note that this is a conservative choice that will underestimate differences between 2-player and (genuine) 6-player games, by labelling some smaller groups as 6-player. 

We ran all models in BRMS [@burkner2018] with weakly regularizing priors. We were often unable to fit the full mixed effects structure that we had pre-registered in a reasonable amount of time, so we included what heirarchical effects were reasonable. (All model results and priors and formulae are reported in TODO supplement). Accuracy models were run as logistic models with normal(0,1) priors for both betas and sd. Reduction models were run as linear models with an intercept prior of normal(12,20), a beta prior of normal(0,10), an sd prior of normal(0,5) and a correlation prior of lkj(1). For all of the models of sbert similarity, we used linear models with the priors normal(.5,.2) for intercept, normal(0,.1) for beta, and normal(0,.05) for sd. 


# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent


