---
title: Interaction structure constrains the emergence of conventions in group communication

author:
  - name: Veronica Boyce
    email: vboyce@stanford.edu 
    affiliation:
      - Stanford 
    footnote:
      - corresp
  - name: Robert Hawkins
    affiliation: 
      - Princeton
  - name: Noah D. Goodman
    affiliation: 
      - Stanford
  - name: Michael C. Frank 
    affiliation: 
      - Stanford
address:
  - code: Stanford
    address: Stanford University 
  - code: Princeton
    address: Princeton University
footnote:
  - code: corresp
    text: "Corresponding author. Email: vboyce@stanford.edu"
bibliography: ["papers.bib"] # Replace with one or more of your own bibtex files. Better BibTeX for Zotero is your friend
csl: dmk-format.csl # Use any CSL style. See https://www.zotero.org/styles for a good list. Ignored if citation_package: natbib
link-citations: TRUE
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{angles,positioning,arrows.meta, quotes, shapes, shapes.geometric}
  - \usepackage{graphicx}
output:
  bookdown::pdf_document2:
    toc: FALSE
    keep_tex: TRUE
    template: generic_article_template.tex
    #md_extensions: "-autolink_bare_uris"
    number_sections: FALSE
    citation_package: default # Can also be "natbib"
lang: en # Main document language in BCP47 format
geometry: "margin=25mm"
papersize: a4
#linestretch: 2 # for double spacing
endfloat: FALSE # Set to TRUE to turn on latex endfloat package to place figures and tables at end of document
# endfloatoption: # See endfloat documentation for more possibilities
#   - tablesfirst # Default
#   - nomarkers # Default
numberlines: FALSE
authblk: TRUE # FALSE = author affiliations in footnotes; TRUE = author affiliations in a block below author names
footnotehyper: FALSE # TRUE will give you enhanced table footnote capabilities. Set to FALSE to be able to use French blocks. Needed due to what appears to be a latex bug.
urlcolor: blue
linkcolor: blue
citecolor: blue
graphics: TRUE # Needed to be able to include images
tables: TRUE # Needed to be able to include tables

---

<!---------------------- Abstract --------------------->

::: {.abstract data-latex="" lang=en}
Group communication is ubiquitous, but it presents some challenges not found in two-person communication, which is the primary focus of the experimental literature. One test case for communication that is  iterated reference games, where the phenomenon of reduction over repeated reference is well-attested in dyadic contexts and could explain how pairs of people can build shared meanings. We extend the repeated reference game paradigm to groups of 2 to 6 people under varied interaction structure constraints across 313 games (1319 participants). Across conditions, reduction and convergence to shared descriptions occurs, but there is a gradient where smaller groups and groups with thicker communication channels show faster and stronger convergence than larger games or groups with thinner communication channels. 

:::



<!------------ Main text -------------------->
 
# TODOs
 <!--
 Comments on tangrams ms draft!
[yellow highlight means “had a question about this”, pink means “highlighting this sentence”]
“How does the formation of shared conventions proceed in multi party … ” - this is tagged as the key research question by position in the paragraph, but it’s a bit more descriptive than our key question about the nature of interaction structure. I think we might want to think about how best to set up the intro to frame a question about interaction structure. First part of the intro nicely sets up the broad idea, but then from there it’s tricker…

Biggest remaining writing challenge here is writing narrative results focused on what the take homes are. You can do this in a way that is responsible to the data but structured around particular expository points. Remember when we did the cogsci paper, we set up key signatures in the intro and then looked at them in the results. Same thing will be helpful here - you can do it super explicitly with headings and numbers or a little more implicitly with prose, but the principle is the same - we need to understand why particular patterns relate to interpretations (“interaction structure constrains emergence of conventions” - what in our data tells us this?). This gets set up in intro and then reinforced in the results.

perhaps a figure on reduction as one panel of the multi-panel design figure?
-->
* Fix first sentence of abstract (somehow?)
* how to prep for interaction structure in intro

* Fix tense issues everywhere!
* Fill in some missing citations

* !!!!front load take aways in results-cosine and results-not-cosine
* Reoutline takeaways, propogate to set up/intro, results, GD
* everything gets a topic sentence

* Clean up supp figs / exile supplement


```{r set-up, include=FALSE}
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())


knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.crop = F, out.width = "100%", dpi=300,
                      fig.pos = "tb", fig.path='figs/', fig.env="figure",
                      echo=F, warning=F, cache=T, 
                      message=F, sanitize = T)

color_scheme_1 <- c("2"="#FFBDD4", "3"="#FF7DF0","4"="#D24AFF", "5"="#A12EFF","6"="#6940FF")
color_scheme_2 <- c( "6 single speaker"="#00A2FF","6 thin"="#D47E04","6 full feedback"="#425df5")

color_scheme_3 <- c("6 thin"="#D47E04", "6 thick"="#00BDA8",
                  "2 thin"="#FFDA09", "2 thick"="#77F3DB")


		
ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  |> 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"




image_location="write-ups/images"

msum_loc="code/paper_mods/summary"
mform_loc="code/paper_mods/formulae"

source(here("code/prep_ms.R"))


stats <- function(model, row, decimal=2){
  model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c(model[row,1],": ", model[row,2], " ", model[row,3])
}

stats_text  <- function(model, row, decimal=2){
    model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c( model[row,2],"  ",model[row,3])
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
  str_replace_all("\\*"," $\\\\times$ ") |> 
  str_replace_all("\\+", "&nbsp;+ ") |> 
   str_replace_all("~", "$\\\\sim$ ")
}
```

```{r count, include=F}

games <- combined_results |> select(gameId) |> unique() |> nrow() 

players <- combined_results |> select(gameId, numPlayers) |> unique() |> summarize(players=sum(numPlayers))

words <- combined_chat |> ungroup() |> select(total_num_words) |> summarize(words=sum(total_num_words)) 

```

<!--TODO: need to replace - sign with a non-breaking hyphen re: statistical results!!!
TODO: add clear sub part labels of what graphs are showing-->

Communicating in groups can be challenging. Listeners may have different levels of background knowledge that the rest of the groups may be unaware of. Some interlocuters may interrupt with questions, and others might pipe in to explain their views, collectively leading to everyone talking at once. Multiple conversations threads may split off that need to merge back together for the group to reach agreement. Different people may understand the same speaker as meaning different things, resulting in disagreements and misunderstandings. Disagreements may even escalate to the point where meta-discussion is needed to define terms or struction the conversation differently. 

TODO FIX We've all been in situations that look like this, where a conversation with half-a-dozen people devolves into chaos and results in inefficient communication. Yet, despite all of these impediments, we often communicate successfully in groups. How?


One key requirement for efficient communication in groups of any size is a shared vocabulary, or shared mappings between linguistic units and objects or concepts [@branigan2006;@ginzburg2005;@traum2004]. Because reference is a requirement of communcation that can be isolated and tested in experimentally manipulated contexts, it has been a case study for efficient communication more broadly. In many cases, ther are widely shared convention mappings between objects and descriptions that people can rely on, but in other cases, interlocuters must invent ad-hoc reference expressions to communicate about objects without canonical names. 

The formation of these new reference expressions is well-studied in dyadic contexts. @clarkReferringCollaborativeProcess1986 established an experimental method for studying the emergence of new referring expressions that has now become standard [building on @kraussChangesReferencePhrases1964;@kraussConcurrentFeedbackConfirmation1966]. Two participants see the same set of figures; the speaker describes each figure in turn so the listener can select the target from the set of figures. The speaker and listener repeat this process with the same images over a series of blocks. Early descriptions are long and make reference to multiple features in the figure, but in later iterations, shorthand conventional names for each figure emerge; this shortening of utterances is called 'reduction'. Not only are later utterances shorter than earlier utterances, but later utterances are a tacitly agreed upon name, understandable within the group, but different from the conventions chosen in other groups. 

Recently, online participant recruitment and web-based experiments have made it possible to study this convergence in larger populations [@hawkinsCharacterizingDynamicsLearning2020;@haber2019]. In line with results from face-to-face, oral paradigms, speakers reduced their utterances, producing fewer words per image in later blocks than in earlier blocks. (Throughout this paper, we use "speaker" and "listener" to refer to the roles describing and selecting targets, regardless of communication modality.)

How generally does this reduction phenomena occur? 

What aspects of conversational infrastructure are needed to support this convergence pattern? Can a speaker for a convention when they are interacting with several listeners at once? Do listeners need to be able to ask questions or get feedback on the correct answers for the convention to form? Can conventions still form when a different person is the speaker each block? Even if it is possible to form conventions under these circumstances, is it harder to, compared to a speaker-listener pair with consistent roles and a wide communication channel? 

In the current work, we address how components of interaction structure, including group size and communication channels, shape how successfully groups form partner-specific conventionalized names for target objects over the course of an iterated reference game. We recruited `r players` participants who were organized into `r games` groups distributed across 3 online  experiments and 11 conditions. Collectively, players produced `r words |> round(-3)` words during their games. Our key question was how do differences in communication channel structure impact the formation of conventionalized names in an iterated reference game.  We analysed the results using traditional metrics of accuracy and number of words produced, and we used computation measures of semantic similarity to understand how utterances evolve during the games. 


We find that the characteristic pattern of increasing accuracy and decreasing utterance length that is noted in the dyadic literature also occurs across conditions in multi-player games. Reduction is coupled with semantic shifts as utterances converge toward the eventual conventionalized name and away from descriptions used by other groups or for other tangrams. These convention-formation phenomena emerge across disparate conditions; however, larger groups and groups with narrower communication channels are less effective and converge more slowly and weakly than other groups. 




```{r diagram,  fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap="TODO: needs some visual help!. \\ A: Diagram of the experimental space explored in these experiments. Experiments varied along 3 dimensions: Group size, group coherence, and listener backchannel. Each condition is shown as a dot. Experiment 1 (pink labels) varied group size from 2-6 players while holding group coherence and backchannel constant. Experiment 2 (blue labels) keep group size constant at 6 and varied the other dimensions. Relative to experiment1, 6 single speaker and 6 full feedback each added one component of group coherence, and 6 thin reduced the backchannel. Experiment 3 (green labels) tested 4 corners of the space, crossing group size (2 or 6 players) with thin games (low coherence, low backchannel) or thick games (high coherence, high backchannel). \\  B: Each trial a speaker described a target image to the listeners, and this process repeated for all 12 images to comprise a block, and the block repeated for a total of 6 iterations. \\ C: Differences between conditions. See text for explanation."}
knitr::include_graphics("expt-diagram.pdf")

```

# Claims

How does the formation of shared conventions proceed in multi-party communication? 

Behaviorally,
larger games are similar to smaller games, but their speakers tend to say more overall, perhaps related
to the increased number of listeners to respond to.

However, the interaction stucture of a group affects how rapidly groups converge to partner-specific
conventions, whether measured via reduction or via semantic convergence. 
We can interpret the experiment 3 pattern as saying that 2-player games can cope with limited feedback
mechanisms, but 6-player games suffer without access to more feedback.

Do the phenomena observed in dyadic reference games extend to larger games and games with more constrained interaction structure? 
How does interaction structure and game size modulate the strength of effects? Are the effects weaker in groups with more constrained interaction structure? 
something something linguistic analyses -- do they track the verbal patterns of similarity? Are the effects weaker in some groups than others?

Listeners accuracy rose over repetitions in all games, and approached ceiling in most conditions; however, 6 player thin games were less accurate than other games (Figure \@ref(fig:behavioral)A). 

All conditions showed reduction, where speakers produced fewer words of description in later repetitions than in earlier repetitions. Speakers with more listeners talked more across blocks, and in some cases, showed sharper reduction from their wordier starting points. This is likely related to having more listeners to respond to. 

According to the traditional metrics of iterated reference games, larger games are similar to small games, except that speakers say more in larger games. 
Listeners do not talk as much as speakers, but they talk much less in later blocks than in earlier blocks. When there are more listeners, it is more likely that some listener will talk. 

Over repetitions, speaker descriptions became increasingly similiar to the final description for the target image. This convergence occurred faster in smaller and higher coherence groups, and was least strong for the 6-player thin condition. 

Over repetitions, speaker descriptions in one group became increasingly dissimilar to descriptions from other groups. This divergence was faster in smaller and thicker conditions, and barely occurred in the 6-player thin condition. 

# Results

[mini-methods]

We extended on the dyadic paradigm of @hawkinsCharacterizingDynamicsLearning2020 by parameterizing the experiments along a few dimensions while keeping other aspects of the experiment constant. As shown in Figure \ref{diagram} inset, all of the games used the same 12 target images [@hawkinsCharacterizingDynamicsLearning2020; @clarkReferringCollaborativeProcess1986]. The speaker knew which image was the target, and their goal was to describe it to the listeners over a chat interface so each listener could select the target. After all listeners had selected, players received feedback on the selections. The process repeated with the same speaker describing each of the 12 images to form one block. The games consisted of 6 blocks, for a total of 72 trials, where each image was described 6 times over the course of the game. 

Figure \@ref(fig:diagram) schematically illustrates the dimensions of variation between games and where each condition fit in the experimental space. Game size (shown on the x-axis) which varied between 2 and 6 players groups to explore the gradual effects having a larger audience. Group coherence (y-axis) was made up of two components: speaker rotation and feedback. In low group coherence games, the speaker rotated each block, while in high group coherence games, one player was the speaker for the entire game. Rotating speakers is a more stringent test of convention formation because it compares utterances from different players, but having a single speaker adds continuity that can help hold a group together. In low group coherence games, each listener only received feedback on if they were individually right or wrong in their selection; while in high group coherence games, listeners (like the speakers in all games) saw who had selected what and what the target had been, thus ensuring people saw what referent was intended and had a sense of how everyone else was doing. Listener backchannel (z-axis) varied how listeners could communicate with the group.  In high backchannel games, the listeners could type text messages to the shared chat; while in low backchannel games, listeners could send 4 discrete messages (represented as emojis) to the chat. This dimension was inspired by the claimed importance of listener contributions to convention formation [CITE].

Experiment 1 varied group size with games of 2, 3, 4, 5, or 6 players all with low group coherence and high listener backchannel. Experiment 2 held group size constant at 6 while each condition deviated from experiment 1 in one aspect: 6 single speaker and 6 full feedback changed components of group coherence and 6 thin switched to a low backchannel. Finally, experiment 3 tested 4 corners of the experimental space at larger scale, with thin (low backchannel, low coherence) and thick (high backchannel, high coherence) games with either 2 or 6 players. 

We compared across all of these conditions on the two behavior measures that are the common markers of reduction in the literature:  listener accuracy and speaker reduction [CITE]. Additionally, we measured the similarities between speaker's descriptions to explore how the descriptions developed over time. For analyses, we used a Bayesian multi-level regression framework with weakly regularizing priors; listener accuracy used a logistic regression, all other analyses used linear regression [CITE BRMS] [See methods for full priors, and supplement for a full list of models and model results].  


## Accuracy and language quantity

The canonical findings from dyadic reference games are that, over repetitions, listener accuracy remains high and increases towards a ceiling effect while the amount of referential language decreases dramatically. Listener accuracy is a measure of how successfully groups are completing the task, that is, whether speakers are succeeding in communicating the target referent to the listeners. Reduction of speaker descriptions is an indication that speaker and listeners have formed a shared conceptualization of the target, that can be distilled into a shorter and less descriptive form, while still retaining the same level of informativity to listeners. CITATIONS


```{r behavioral, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Behavioral results across all three experiments. A. Listener accuracy at selecting the target image. Dots are per condition, per block estimates with 95\\% bootstrapped CIs. Smooths are binomial fit lines. B. Number of words said by the speaker each trial. Faint dots represent individual trials from individual games. Smooths are quadratic fit lines. Y-axis is truncated, and a few outliers points are not visible. "}
# accuracy

# 1
one <- combined_results |> filter(condition=="rotate") |> group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(numPlayers=as.character(numPlayers)) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=numPlayers))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
  #annotate("text", x=3.5,y=1,label="Experiment 1", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_1)
#2

two <- combined_results |> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  #labs(x="Block", y="Fraction correctly selected", color="")+
  labs(x="", y="", color="")+
    #annotate("text", x=3.5,y=1,label="Accuracy", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+ 
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
        scale_color_manual(values=color_scheme_2)

#3
 three <- combined_results |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> group_by(playerId,repNum, gameId, condition) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |>
   mutate(condition=str_replace(condition, "_", " ")) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
 # labs(x="Block", y="Fraction correctly selected", color="")+
  #   annotate("text", x=3.5,y=1,label="Experiment 3", size=6)+
     labs(x="", y="", color="")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
   scale_color_manual(values=color_scheme_3)
 
 acc <- plot_grid(one, two, three, nrow=1)
 

#1

one <- combined_chat |> filter(condition=="rotate") |>  filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, numPlayers) |> 
  summarize(words=sum(total_num_words)) |>
    mutate(numPlayers=as.character(numPlayers)) |> 
ggplot(aes(x=repNum+1, y=words, color=numPlayers))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
#annotate("text", x=3.5,y=60,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- combined_chat|> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram,condition) |> 
  summarize(words=sum(total_num_words)) |> 
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin") |> factor(levels=c("6 single speaker", "6 full feedback", "6 thin"))) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
 # labs( y="Number of words", x="Block", color="")+
    labs(x="", y="", color="")+

#annotate("text", x=3.5,y=60,label="Speaker Reduction", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
    scale_color_manual(values=color_scheme_2)

#3


three <- combined_chat |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> filter(role=="speaker") |> 
    mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, condition) |> 
  summarize(words=sum(total_num_words)) |> 
  mutate(condition=str_replace(condition, "_", " ")) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
  geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
 # labs( y="Number of words", x="Block", color="")+
    labs(x="", y="", color="")+
#annotate("text", x=3.5,y=60,label="Experiment 3", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

red <- plot_grid(one,two, three, nrow=1)

plot_grid(acc, red, nrow=2, rel_heights = c(.8,1), labels="AUTO", label_size=20)
```

```{r}
acc_1 <- read_rds(here(msum_loc,"acc_1.rds"))

acc_2a <- read_rds(here(msum_loc,"acc_2a.rds"))

acc_2b <- read_rds(here(msum_loc,"acc_2b.rds"))

acc_2c <- read_rds(here(msum_loc,"acc_2c.rds"))

acc_3 <- read_rds(here(msum_loc,"acc_3.rds"))


```

In our current experiments, listener accuracy rose over repetitions in all conditions and approached ceiling in most conditions; however, 6 player thin games were the least accurate (Figure \@ref(fig:behavioral)A). In experiment 1, varying group size did not have a strong effect on initial accuracy (`r stats(acc_1,4)`) or improvement rate (`r stats(acc_1,2)`). In experiment 3, the 6 player games had lower initial accuracy (`r stats(acc_3, 6)`) and were slower to improve (`r stats(acc_3, 3)`) than the 2 player games. Thin games were not reliably worse than thick games on initial accuracy (`r stats(acc_3,5)`) or improvement rate (`r stats(acc_3, 2)`). The high and increasing levels of accuracy indicate that across all of these conditions, participants are able to succeed in communicating about the images. 

```{r}
red_1 <- read_rds(here(msum_loc, "red_1.rds"))

red_2a <- read_rds(here(msum_loc,"red_2a.rds"))

red_2b <- read_rds(here(msum_loc,"red_2b.rds"))

red_2c <- read_rds(here(msum_loc,"red_2c.rds"))

red_3 <- read_rds(here(msum_loc, "red_3.rds"))

```

The key reduction phenomena is the reduction in the number of words used to describe the images over the course of the game. The result appeared in all condition where speakers produced fewer words in later repetitions than in earlier repetitions (Figure \@ref(fig:behavioral)B). 

Speakers in larger games tended to be more verbose than speakers in smaller games, and in some cases, these speakers showed sharper reduction from initial wordiness to eventual concision. In experiment 1, the overall effect of being one block later was `r stats_text(red_1,1)` words per trial. Speakers in larger groups said more; the effect of each additional player was  `r stats_text(red_1,4)` more words per trial, with no clear interaction between block and group size. In experiment 2, the result of being one block later was `r stats(red_2a,1)` words per trial for 6 single speaker; `r stats(red_2b,1)` words per for 6 full feedback, and `r stats(red_2c,1)` words per trial for 6 thin.  In experiment 3, the six player games said `r stats_text(red_3, 7)` more words in in the first block, but reduced faster (`r stats(red_3, 4)`) than the two-player games. Thin games were similar to thick games in initial verbosity (`r stats(red_3, 5)`) and reduction rate (`r stats(red_3, 2)`). 

```{r}
list_1 <- read_rds(here(msum_loc, "list_1.rds"))
list_spec_1 <- read_rds(here(mform_loc, "list_1.rds"))

anylist_1 <- read_rds(here(msum_loc, "anylist_1.rds"))
anylist_spec_1 <- read_rds(here(mform_loc, "anylist_1.rds"))


```

Listeners talk much less frequently than speakers, but their role in convention formation is thought to be important CITATION. 

Listeners descriptions reduced over the course of the game, with more language occurring in larger games (CROSSREF SUPPLEMENT IMAGE). In experiment 1, the number of trials where any listener says anything related to the description of the image is higher in larger groups (`r stats(anylist_1, 4)`), and declines across blocks (`r stats(anylist_1, 1)`). When referential language is produced, more is produced in larger groups (`r stats(list_1, 4)`), but the difference in group size closes in later blocks (`r stats(list_1, 2)`). This pattern is consistent with early listener involvement in establishing a common conceptualization by asking questions and offering alternative descriptions. Once a shared idea is in place, listener descriptions are rarer and more perfunctory.

[could say more, but not sure how much to say] In games where listeners could only send 4 emoji, emoji use is common in the 6 player games, but also decreases over the course of the game (CITE FIGURE). 

According to the traditional metrics of iterated reference games, larger games are similar to smaller games, except with more talking, especially early in the games. At a given level of understanding, there's a accuracy-reduction trade-off: saying more may lead to more of the group understanding the referent, but it takes time and words. Larger groups seem to generally take the time to elaborate and increase accuracy, especially when listeners can ask specific clarifying questions. This leads to more talking in early rounds for larger games, sometimes followed by sharp reduction once a shared conceptualization is agreed upon. 

## Linguistic content analyses



```{r sbert-diagram, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Example utterances describing the shown tangram figure produced by two 3-player games in Experiment 1. To measure convergence within a game (blue), we measured the cosine similarity between SBERT embeddings of descriptions and the embedding of the round 6 utterance (taken to be the convention). Higher cosine similarity indicates more similar meaning. To measure divergence between games (green), we measured the similarity between utterances from the same round across games."}
knitr::include_graphics("sbert.pdf")

```

The reduction in words is thought to be a signal of the formation of a partner-specific conceptualization of the target image that leads to an efficient way to refer to it CITATIONS. We can measure this concept formation more directly by looking at shifts in the semantic similarity of descriptions. As a group converges to a nickname for a target, descriptions within a game, to the same target should become more similar to each other and to the eventual convention. At the same time, the partner specificity means that as different groups latch onto different features as the key concept, descriptions of the same image from different groups should decrease in similarity over time. 


TO quantify the level of similarity between descriptions, we concatenated the speaker's messaged within a trial together and embedded the description into a high-dimensional vector space using SBERT (CITE). Then, we compare the similarity between any pair of utterances by taking the cosine similiarty between their embeddings. These two metrics are illustrated with examples in Figure \@ref(fig:sbert-diagram). 

```{r sbert, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Language similarity results measured with pairwise cosine similarity between embeddings of two utterances. A. Convergence of utterances within games as measured by similarity between an utterance from block 1-5 to the block 6 utterance in the same game for the same image. Dots are per-game averages, smooths are quadratic. B. Divergence of utterances across games as measured by the similarity between an utterances and utterances produced for the same image by different groups in the same block. Dots are per-image averages, smooths are quadratic."}
#convergence

one_two_converge <- read_rds(here("code/models/one_two_converge.rds"))
three_converge <- read_rds(here("code/models/three_converge.rds"))
#1
one <- one_two_converge |> filter(condition %in% c("2", "3","4","5","6")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
#annotate("text", x=3,y=1,label="Experiment 1", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- one_two_converge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
 # labs(y="Cosine Similarity", x="Block", color="")+
    labs(x="", y="", color="")+
annotate("text", x=3,y=1,label="Within game", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+    scale_color_manual(values=color_scheme_2)



#3



three <- three_converge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |>  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
 # labs(y="Cosine Similarity", x="Block", color="")+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
#annotate("text", x=3,y=1,label="Experiment 3", size=6)+
    labs(x="", y="", color="")+

  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

conv <- plot_grid(one, two, three, nrow=1)

one_two_diverge <- read_rds(here("code/models/one_two_diverge.rds"))
three_diverge <- read_rds(here("code/models/three_diverge.rds"))
# divergence

#1
one <-  one_two_diverge |> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
 # labs(y="Cosine Similarity", x="Block", color="")+
    labs(x="", y="", color="")+
#annotate("text", x=3.5,y=.7,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_diverge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
                              ggplot( aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
      coord_cartesian(ylim=c(.1,.7))+
  #labs(y="Cosine Similarity", x="Block", color="")+
    labs(x="", y="", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=.7,label="Between games", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_diverge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |> ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  #labs(y="Cosine Similarity", x="Block", color="")+
    labs(x="", y="", color="")+
#annotate("text", x=3.5,y=.7,label="Experiment 3", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_3)

div <- plot_grid(one,two,three, nrow=1)

plot_grid(conv, div, nrow=2, labels="AUTO", rel_heights = c(.8,1), label_size=20)
```


```{r}
tolast_1 <- read_rds(here(msum_loc, "tolast_1.rds"))

tonext_1 <- read_rds(here(msum_loc, "tonext_1.rds"))

tolast_2a <- read_rds(here(msum_loc, "tolast_2a.rds"))

tonext_2a <- read_rds(here(msum_loc, "tonext_2a.rds"))

tolast_2b <- read_rds(here(msum_loc, "tolast_2b.rds"))

tonext_2b <- read_rds(here(msum_loc, "tonext_2b.rds"))

tolast_2c <- read_rds(here(msum_loc, "tolast_2c.rds"))

tonext_2c <- read_rds(here(msum_loc, "tonext_2c.rds"))

tolast_3 <- read_rds(here(msum_loc, "tolast_3.rds"))

tonext_3 <- read_rds(here(msum_loc, "tonext_3.rds"))

```

Across conditions, speaker descriptions converged toward the final description, as shown Figure \@ref(fig:sbert)A. This convergence occurred faster in smaller and higher coherence groups, and was least strong for the 6-player thin condition. 


In experiment 1, the similarity of the first utterance to the last last utterance was invariant across group size (`r stats_text(tolast_1, 1,3)`), but for smaller groups, similarity increases rapidly, and they converge faster (`r stats_text(tolast_1, 3,3)`). Convergence was especially rapid in the experiment 2 single speaker condition (`r stats_text(tolast_2a, 1,3)`) where all the utterances come from the same person. In experiment 3, convergence was slower in thin games than thick games (`r stats_text(tolast_3, 4,3)`) and especially thin 6 player games (`r stats_text(tolast_3, 5,3)`). This convergence towards the last utterance is driven by  cumulative increasing similarity between pairs of adjacent utterances (i.e. blocks 5 and 6 are closer to each other than block 1 is to 2), illustrated in  TODO SEE SUPPLEMENT FIGURE. 

```{r}
div_1 <- read_rds(here(msum_loc, "div_1.rds"))

div_2a <- read_rds(here(msum_loc, "div_2a.rds"))

div_2b <- read_rds(here(msum_loc, "div_2b.rds"))

div_2c <- read_rds(here(msum_loc, "div_2c.rds"))
div_3 <- read_rds(here(msum_loc, "div_3.rds"))
```

Veronica is here in rewrite pass

Over repetitions, speaker descriptions in one group became increasingly dissimilar to descriptions from other groups. This divergence was faster in smaller and thicker conditions, and barely occurred in the 6-player thin condition. 
The complement to convergence within groups is divergence between groups, as different groups develop their own ways of identifying the different figures. In experiment 1, descriptions become less similar to those used to describe the same figure in other games (`r stats_text(div_1, 1,3)`). Group size does not affect the cross-groups similarities in the first block (`r stats_text(div_1, 3,3)`), but smaller groups diverge from each other faster than larger groups (`r stats_text(div_1,2,3)`). In experiment 2, divergence is stronger in the single speaker (`r stats_text(div_2a, 1,3)`) and full feedback conditions (`r stats_text(div_2b, 1,3)`) than in the 6 thin condition (`r stats_text(div_2c, 1,3)`). In experiment 3, descriptions from different games get less similar over time in the 2-player thick condition (`r stats_text(div_3, 1,3)`). The 6 player thick condition has initially higher similarity (`r stats_text(div_3, 7,3)`, but diverges faster (`r stats_text(div_3, 4,3)`. The two-player thin has slightly higher similarity (`r stats_text(div_3, 5, 3)`) and slightly slower divergence (`r stats_text(div_3, 2,3)`). Most noticeably, the 6 player thin games diverge much more slowly than the other conditions (`r stats_text(div_3, 3,3)`). 

As group narrow in on descriptions for each image that differ from other groups, the names for each tangram differentiate with a group (See supp figure TODO). 

These semantic patterns are all consistent with the partner-specific convention development and differentiation proposed by CITE someone must have verbally described the pattern.  

Discuss how the condition patterns of reduction and condition patterns of SBERT aren't quite the same!!

# General Discussion

TODO fix me!
Communication often occurs in multi-party settings, but much of the research on communication has been on dyads. One common paradigm for studying communication has been iterated reference games, where the phenomenon of reduction over repeated reference has been robustly established. How does the formation of shared conventions proceed in multi-party communication? 


We build on this tradition by expanding the reference game paradigm to larger groups under various interaction structures. Across 3 online experiments and 11 experimental conditions, we varied game features including group size, form of listener backchannel, and degree of group coherence. All conditions shows the same patterns of increasing accuracy, reduction in speaker utterances, and semantic convergence within and divergence between groups. Thus, the classic reduction phenomena can occur even under situations with constrained interaction structure. 

However, the interaction stucture of a group affects how rapidly groups converge to partner-specific conventions, whether measured via reduction or via semantic convergence. Smaller groups and games with thicker communication channels converged faster and more robustly than games that were larger or had thinner communication channels. These factors add together to form the overall group experience. We can interpret the experiment 3 pattern as saying that 2-player games can cope with limited feedback mechanisms, but 6-player games suffer without access to more feedback. 

The 6 thin condition also presents intriguing evidence that reduction and partner-specific utterance formation might not be closely tethered: this condition shows reduction that is not substantially different than in the 6 thick condition, but it shows much less semantic convergence than other conditions. This is just one condition, but it suggests that descriptions can shorten without differentiating, perhaps all shortening to a common prior. CITE THAT PAPER ABOUT GROUP SIZE This highlights the importance of measuring semantics separately from just length proxies. 
Our goal here was to further explore the space; not to directly adjudicate theories. However, given how little listeners talked, and the success of games where listeners had a limited backchannel, it seems that people are readily able to jointly agree on conventions without talking (consistent with RSA-etc CITATIONS models). 

Overall, we have a number of groups, and a large corpus of language that could be probed further. The number of groups in any one condition is limited, but overall, there's a lot of people and a lot of language. TODO needs work 

[not sure if/where to include] My biggest take away from this is that the hard part seems to be getting first contact with a shared meaning (and knowing you have done this), and the "reducing" part is easier since you have something to work with. So, how ideas of how to describe are sampled might be worth exploring more? 



## Limitations
Just within the general framework of iterated reference, there is a high dimensional feature space of possible experiments. We sampled only a few points along a few dimensions in the space that felt salient. In our experiment 3, we grouped some factors together in order to have more games in each condition: a fully factorial design would have been too expensive to power adequately. Future work could sample other points in the experimental space, perhaps exploring the effects of different target images, or groups of people with real-life prior connections. Group to group variability is high, as individual differences in communication style and shape description ability interacted. Coupled with small numbers of groups in some conditions, measures may be somewhat noisy depending on the random assignment of participants to games and conditions. 

We cannot make claims about causal mechanisms between how experimental set-ups such as group size resulted in different outcomes: for instance, there are many differences between being in a 2-person group versus a 6-person group that could lead to the different outcomes. In a dyad, speakers can tailor their utterances to the one listener, but in large groups, speakers must balance the competing needs of different listeners [@schober1989;@tolins2016]. These effects likely vary by both the knowledge state of and communication channels available to the listeners [@fox-tree2013;@horton2002; @horton2005]. Further work digging into the language used and the interactions between participants might unearth plausible mechanisms for differences in group size that could then lead to more experimental conditions. 



## Conclusion ??
something something about how set-ups like this could explore related phenomena picking other points in reference game / ref game adjacent space 

TODO 

# Methods

For all experiments, we used Empirica [@almaatouqEmpiricaVirtualLab2020] to create real-time multi-player reference games. In each game, one of the players started as the speaker who saw an array of tangrams with one highlighted (Figure \ref{game}A) and communicated which figure to click to the other players (listeners). After the speaker had identified each of the 12 images in turn, the process repeated with the same images, but a total of 6 blocks (72 trials). We recorded what participants said in the chat, as well as who selected what image and how long they took to make their selections. 

These experiments were designed sequentially and pre-registered individually.^[Experiment 1: https://osf.io/cn9f4 for the 2-4 player groups, and https://osf.io/rpz67 for the 5-6 player data run later. Experiment 2: single speaker at  https://osf.io/f9xyd, full feedback at  https://osf.io/j5zbm, and thin at  https://osf.io/k5f4t. Experiment 3: https://osf.io/untzy] We followed the analysis plan, although additional analyses were added to early experiments that were only pre-registered in later experiments. Some pre-registered models were omitted from the main text, but are shown in the supplement TODO.

## Participants
```{r participants}

players <- combined_results |> mutate(realPlayer=ifelse(is.na(activePlayerCount), numPlayers, activePlayerCount),
                                       numPlayers=ifelse(condition %in% c("6_thin", "6_thick"), "6*", as.character(numPlayers))) |> group_by(condition, numPlayers, gameId) |> summarize(count=max(realPlayer)) |> group_by(condition, numPlayers) |> summarize(`Total Participants`=sum(count))

summary <- combined_results |> group_by(condition, trialNum, repNum, gameId, numPlayers) |> 
  mutate(numPlayers=ifelse(condition %in% c("6_thin", "6_thick"), "6*", as.character(numPlayers))) |> 
  group_by(gameId, numPlayers, condition) |> 
  summarize(num_trials=max(trialNum)) |> 
  arrange(numPlayers) |> 
  mutate(complete=ifelse(num_trials==71,T,F)) |> 
  group_by(numPlayers,complete, condition) |> 
  tally() |> 
  pivot_wider(names_from=complete, values_from=n) |> 
    left_join(players) |> 
  rename(Players=numPlayers,Complete=`TRUE`, Partial=`FALSE`) |> 
  mutate(Partial=ifelse(is.na(Partial), 0, Partial)) |> 
  mutate(Experiment=factor(condition, levels=c("rotate","no_rotate","full_feedback", "emoji", "2_thin", "6_thin", "2_thick", "6_thick"),
                          labels=c("1: baseline", "2: single speaker", "2: full feedback", "2: thin", "3: thin", "3: thin", "3: thick", "3: thick"))) |> 
  select(Experiment, Players, Complete, Partial, `Total Participants`) |> 
  arrange(Experiment, Players,Complete,Partial, `Total Participants`)

knitr::kable(summary, caption="The number of games in each experiment and condition. Complete games finished all 6 blocks; partial games ended early due to disconnections, but contributed at least one complete block of data. 6* indicates that some games started with fewer than 6 players or continued with fewer than 6 players after participants disconnected.")
```

Participants were recruited using the Prolific platform, and all participants self-reported as fluent native English speakers on Prolific's demographic prescreen. Participants each took part in only one experiment. Experiment 1 took place between May and July 2021, experiment 2 between March and August 2022, and experiment 3 in October 2022. As games varied in length depending on the number of participants, we paid participants based on group size, with the goal of a \$10 hourly rate.  Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, \$10 for 4-player games, and \$11 for 5- and 6-player games. When one player had the speaker role for the entirety of a 6-player game, they gained an addition \$2 bonus. Across all games, each participant could early up to \$2.88 in performance bonuses. A total of 1319 people participated across the 3 experiments. A breakdown of number of games and participants in each condition is shown in Table \@ref(tab:participants). 

## Materials

We used the 12 tangram images used by @hawkinsCharacterizingDynamicsLearning2020 and @clarkReferringCollaborativeProcess1986 (see Figure \ref{game}). These images were displayed in a grid with order randomized for each participant (thus descriptions such as "top left" were ineffective as the image might be in a different place on the speaker's and listeners' screens). The same images were used every block. 

## Procedure

The experimental procedure was very similar across the three experiments. We first describe the procedure used in experiment 1 and then describe the differences in later experiments. 

### Experiment 1
We implemented the experiment using Empirica, a Javascript-based platform for running real-time interactive experiments online [@almaatouqEmpiricaVirtualLab2020].  From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages explaining the game. Participants had to pass a quiz to be able to play the game. They were then directed to a "waiting room" screen until their partners were ready.

Once the game started, participants saw screens like Figure \ref{game}A. Each trial, the speaker described the highlighted tangram image so that the listeners could identify and click it. All participants were free to use the chat box to communicate, but listeners could only click once the speaker had sent a message. Once a listener clicked, they could not change their selection. There was no signal to the speaker or other listeners about who had already made a selection. 

Once all listeners had selected (or a 3-minute timer ran out), participants were given feedback (Figure \ref{game}B). Listeners learned whether they individually had chosen correctly or not; listeners who were incorrect were not told the correct answer. The speaker saw which tangram each listener had selected, but listeners did not. Listeners got 4 points for each correct answer; the speaker got points equal to the average of the listeners' points. These points translated into performance bonus at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the speaker once. The same person was the speaker for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were speakers 3 times in 2-player games, twice in 3-player games, once or twice in 4 and 5-player games, and once in 6-player games. Rotating the speaker was chosen to keep participants more equally engaged (the speaker role is more work), and to give a more robust test for reduction and convention. 

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

### Differences in experiment 2
Experiment 2 consisted of three different variations on Experiment 1, all conducted in 6 player games. Each of these conditions differed from the experiment 1 baseline in one way. The single speaker condition differed only in that one person was designated the speaker for the entire game, rather than having the speaker role rotate. The full feedback condition differed from experiment 1 in that all participants were shown what each person had selected and what the right answer was; listeners still saw text saying whether they individually were right or wrong. This was similar to some dyadic work, such as @hawkinsCharacterizingDynamicsLearning2020 where listeners were shown what the right answer was during feedback. For the thin condition, we altered the chatbox interface for listeners. Instead of a textbox, listeners had 4 buttons, each of which sent a different emoji to the chat. Listeners were given suggested meanings for the 4 emojis during instructions. They could send the emojis as often as desired, for instance, initially indicating confusion, and later indicating understanding. In addition, we added notifications that appeared in the chat box saying when a player had made a selection. 

### Differences in experiment 3

The thin channel condition in experiment 3 was the same as the thin condition in experiment 2, above. The thick condition combined the two group coherency enhancing variations from experiment 2: one person was the designated speaker throughout, and the feedback participants received included the right answer and what each player had selected. Across both conditions in experiment 3, notifications were sent to the chat to indicate when a participant had made a selection. 

## Data pre-processing and exclusions

Participants could use the chat box freely, which meant that the chat transcript contained some non-referential language. The first author skimmed through the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about how well or fast the task was going, and confirmations or denials ("ok", "got it", "yes", "no"). We exclude these utterances from our analyses. Note that chat lines sometimes included non-referential words in addition to words referring to the tangrams ("ok, so it looks like a zombie", "yes, the one with legs"); these lines were retained intact. 

In experiments 1 and 2, games did not start if there were not enough participants and ended if any participant disconnected. In experiment 3, games started after a waiting period even if they were not full and continued even after a participant disconnected (with speaker role reassigned if necessary), unless the game would drop below 2 players. The distribution of playes in these 6* player games is at TODO SUPPLEMENT! The realities of online recruitment and disconnection meant that the number of games varied, although we aimed for 20 games in each condition in experiments 1 and 2, and 40 per condition in experiment 3. We excluded incomplete blocks from analyses, but included complete blocks from partial games (See Table \@ref(tab:participants) for counts).

When skimming transcripts to tag non-referential utterances, we noticed that one game in the 6-player thick game had a speaker who did not give any sort of coherent descriptions, even with substantial listener prompting. We excluded this game from analyses. 

## Modelling strategy
In experiment 3, some of the 6 player games did not have 6 players for the entire game. We do not model this, as it is unclear at what point in the game group size is most relevant. We note that this is a conservative choice that will underestimate differences between 2 player and (genuine) 6 player games, by labelling some smaller groups as 6 player. 

We ran all models in brms (CITE) with weakly regularizing priors. We were often unable to fit the full mixed effects structure that we had pre-registered in a reasonable amount of time, so we included what heirarchical effects were reasonable. (All model results and priors and formulae are reported in TODO supplement). Accuracy results used a logistic model, other results use linear models. Accuracy models were all run as logistic models with normal(0,1) priors for both betas and sd. Reduction models were run as linear models with an intercept prior of normal(12,20), a beta prior of normal(0,10), an sd prior of normal(0,5) and a correlation prior of lkj(1). For all of the models of sbert similarity, we used linear models with the priors normal(.5,.2) for intercept, normal(0,.1) for beta, and normal(0,.05) for sd. 


# Supplement
This supplement will get moved to a separate file, but for now is tacked on. 

## Figures of listener performance

Emoji use is common in the 6 player thin games where most trials at least one listener used at least one emoji, but emoji use declines over blocks. SEE FIGURE WHATEVER IN SUPPLEMENT  The use of emoji in the thin games is not directly comparable to listener contributes, since some emoji usage (such as the green checkmark) are most likely equivalent to non-referential listener language ("got it" etc.) that was excluded. The higher rate of emoji use versus referential language could be due to it's non-equivalence, a lower level of accuracy in thin games, or emojis being a lower threshold for sending than written out questions. 
 
```{r}

listeners <- combined_results |> select(condition, playerId, gameId, repNum, trialNum, targetNum, numPlayers)

listener_chat <- combined_chat |> filter(role=="listener") |>  full_join(listeners) |> group_by(condition,  numPlayers, trialNum, repNum, gameId) |> mutate(total_num_words=ifelse(is.na(total_num_words),0, total_num_words)) |> 
  summarize(words=sum(total_num_words)) |> filter(condition %in% c("rotate", "2_thick", "6_thick", "no_rotate", "full_feedback"))

  emojis <- combined_emoji |> mutate(emoji=case_when(
    text=="✅"~  "check",
    text=="🤔" ~ "think",
    text=="❌" ~ "x",
    text=="😂" ~ "lol",
  )) |> full_join(listeners) |> filter(condition %in% c("2_thin", "6_thin", "emoji"))|>
    mutate(is.emoji=ifelse(is.na(emoji), 0, 1)) |> 
    group_by(gameId, trialNum, repNum, condition, numPlayers) 
  
  count_emoji <- emojis |> summarize(words=sum(is.emoji))
  
  all_list <- listener_chat |> union(count_emoji) |> mutate(condition2=ifelse(condition=="rotate", str_c(numPlayers,condition), condition))
```

```{r emoji, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=4, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Fraction of trials on which at least one listener produced the labelled emoji (or any emoji." }
combined_emoji |> mutate(emoji=case_when(
    text=="✅"~  "check",
    text=="🤔" ~ "think",
    text=="❌" ~ "x",
    text=="😂" ~ "lol",
  )) |>  filter(!is.na(emoji)) |> full_join(listeners) |> 
  filter(condition %in% c("2_thin", "6_thin", "emoji"))|> 
  unique() |> 
  mutate(is.emoji=ifelse(is.na(emoji), 0, 1)) |> 
    pivot_wider(names_from=emoji, values_from=is.emoji, values_fill=0) |> 
  select(-`NA`) |> 
  mutate(total=check+think+x+lol) |> 
  pivot_longer(`think`:`total`, names_to="emoji", values_to="count") |> 
  group_by(gameId, trialNum, repNum, condition, numPlayers, emoji) |> mutate(num=ifelse(count>1, 1, count)) |> group_by(gameId,trialNum, repNum, condition, emoji) |> summarize(n=sum(num)) |> mutate(any=ifelse(n>1, 1, n)) |>  ggplot(aes(x=repNum, y=any, color=emoji))+geom_smooth(method="lm")+facet_wrap(~condition)

```



```{r listeners, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=4, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Number of words of referential language produced by listeners over time. Excludes trials where no listeners contributed descriptive language.  "}

one <- all_list |>    filter(words!=0)|> filter(condition=="rotate") |>  
    mutate(numPlayers=as.character(numPlayers)) |> 
ggplot(aes(x=repNum+1, y=words, color=numPlayers))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=23,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- all_list|>   filter(words!=0) |> filter(condition %in% c("no_rotate","full_feedback")) |>
  filter(numPlayers==6) |> 
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |>
ggplot(aes(x=repNum+1, y=words, color=condition))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
annotate("text", x=3.5,y=23,label="Experiment 2", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
    scale_color_manual(values=color_scheme_2)

#3


three <- all_list|>   filter(words!=0) |> filter(condition %in% c( "2_thick", "6_thick")) |>  
  mutate(condition=str_replace(condition, "_", " ")) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
  geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
annotate("text", x=3.5,y=23,label="Experiment 3", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

  plot_grid(one, two, three, nrow=1)

```

```{r listeners2, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=4, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Fraction of trials when any reference language (or emoji) was produced by any listener."}

# do any talk per trial

anytalk <- all_list |> group_by(condition, numPlayers, condition2, gameId, trialNum, repNum) |> summarize(words=sum(words)) |> mutate(is.words=ifelse(words>0, 1,0)) 

# maybe try per game trials/block where any listener talked?


one <- anytalk |> filter(condition=="rotate") |>  
    mutate(numPlayers=as.character(numPlayers)) |> 
ggplot(aes(x=repNum+1, y=is.words, color=numPlayers))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )+
#annotate("text", x=3.5,y=23,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- anytalk|> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |> 
ggplot(aes(x=repNum+1, y=is.words, color=condition))+
   geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )+
#annotate("text", x=3.5,y=23,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
    scale_color_manual(values=color_scheme_2)

#3


three <- anytalk|> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |>  
  mutate(condition=str_replace(condition, "_", " ")) |> 
ggplot(aes(x=repNum+1, y=is.words, color=condition))+
geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )+
#annotate("text", x=3.5,y=23,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

  plot_grid(one, two, three, nrow=1)
```

```{r other, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=11, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Additional measures of convergence and divergence. A is similarity to first utterance. B is similarity between utterances from adjacent blocks. C is divergence in descriptions of different tangrams within a group", cache=T}

#first

one_two_first <- read_rds(here("code/models/one_two_tofirst.rds"))
three_tofirst <- read_rds(here("code/models/three_tofirst.rds"))
#1
one <- one_two_first |> filter(condition %in% c("2", "3","4","5","6")) |>
  ggplot( aes(x=later+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(2,6))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=4,y=1,label="Experiment 1", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- one_two_first |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
  ggplot( aes(x=later+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(2,6))+
  coord_cartesian(ylim=c(.2,1))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=4,y=1,label="Experiment 2", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+    scale_color_manual(values=color_scheme_2)
#3

three <- three_tofirst |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |>  ggplot( aes(x=later+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(2,6))+
  coord_cartesian(ylim=c(.2,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=4,y=1,label="Experiment 3", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

tofirst <- plot_grid(one, two, three, nrow=1)

one_two_next <- read_rds(here("code/models/one_two_tonext.rds"))
three_next <- read_rds(here("code/models/three_tonext.rds"))
# divergence

#1
one <-  one_two_next|> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,5))+
        coord_cartesian(ylim=c(.1,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=1,label="Experiment 1", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_next |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
                              ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  scale_x_continuous(breaks=seq(1,5))+
      coord_cartesian(ylim=c(.1,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=1,label="Experiment 2", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_next |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |> ggplot(aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  scale_x_continuous(breaks=seq(1,5))+
   coord_cartesian(ylim=c(.1,1))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=1,label="Experiment 3", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_3)

tonext <- plot_grid(one,two,three, nrow=1)

one_two_tandiv<- read_rds(here("code/models/one_two_tangrams_div.rds"))
three_tandiv<- read_rds(here("code/models/three_tangrams_div.rds"))
# divergence

#1
one <-  one_two_tandiv |> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition, tangram1), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=.7,label="Experiment 1", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_tandiv |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
                              ggplot( aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition, tangram1), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
      coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3.5,y=.7,label="Experiment 2", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_tandiv |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |> ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition, tangram1), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
annotate("text", x=3.5,y=.7,label="Experiment 3", size=6)+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
scale_color_manual(values=color_scheme_3)

tandiv <- plot_grid(one,two,three, nrow=1)


plot_grid(tofirst, tonext, tandiv, nrow=3, labels="AUTO", rel_heights = c(.8,.8,1), label_size=20)
```

## Distinctiveness of tangrams

```{r}

tandiv_1 <- read_rds(here(msum_loc, "tandiv_1.rds"))
tandiv_spec_1 <- read_rds(here(mform_loc, "tandiv_1.rds"))

```
```{r}

tandiv_2a <- read_rds(here(msum_loc, "tandiv_2a.rds"))
tandiv_spec_2a<- read_rds(here(mform_loc, "tandiv_2a.rds"))

tandiv_2b <- read_rds(here(msum_loc, "tandiv_2c.rds"))

tandiv_2c <- read_rds(here(msum_loc, "tandiv_2c.rds"))

```

```{r}
tandiv_3 <- read_rds(here(msum_loc,"tandiv_3.rds"))
tandiv_spec_3 <- read_rds(here(mform_loc, "tandiv_3.rds"))

```

Another way of looking at how language changes over the course of the game is looking at how games start to refer to different tangrams more differently. This could reflect initial overlap in descriping many figures as sitting or standing or by leg and arm and head position. 

Over the course of the game, descriptions for each tangram become more distinctive (`r stats_text(tandiv_1, 1,3)`). 
In all three subexperiments, the descriptions of tangrams become more distinctive within games across time. (2a `r stats_text(tandiv_2a,1,3)`, 2b `r stats_text(tandiv_2b, 1,3)`, 2c `r stats_text(tandiv_2c,1,3)`). 


Tangram distinctiveness within games increased over time (`r stats_text(tandiv_3, 1,3)`). There might be more to say about other effects, but it's mostly a starting places being different in larger games and then the slopes also differ a bit? 


### play with more diagrams
Comparing utterances between adjacent rounds reveals similar patterns. Thin games have lower similarity between adjacent blocks (`r stats_text(tonext_3, 1,3)`) as do larger games (`r stats_text(tonext_3,7,3)`). Later in the game adjacent blocks are more similar than earlier adjacent blocks (`r stats_text(tonext_3, 3,3)`), painting an overall nonlinear convergent pattern (as seen in Figure \@ref(fig:other)). 




 
```{r}
form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
      str_replace_all("~", "~$\\\\sim$ ") |> 
  str_replace_all("\\*","~$\\\\times$ ") |> 
  str_replace_all("\\+", "~+ ") |> 
   str_replace_all("_", "")
}

do_table <- function(mod, cap,decimal=2){
  model <- read_rds(here(msum_loc,mod)) |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Term=str_replace_all(Term, "_", ""),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)

spec <- read_rds(here(mform_loc,mod))

kable(model |> select(Term, Est.=Estimate, CrI=`Credible Interval`), escape=F, format='latex', booktabs=T,
      caption=str_c(cap, ":\\\\\ ",form(spec)),
      align='lll', pos='h!')
}
```
## Models

Note that for all models, block was 0 indexed, so intercepts are what happened during the first block. 

## Accuracy models

Accuracy models were all run as logistic models with normal(0,1) priors for both betas and sd. This model was not explicitly included in the experiment 1 and 2 pre-registrations; it was included with more ambitious mixed effects (which did not run in a timely manner) in the experiment 3 pre-reg. 

```{r}

do_table("acc_1.rds", "Experiment 1 logistic model of listener accuracy")
do_table("acc_2a.rds", "Experiment 2: 6 single speaker logistic model of listener accuracy")
do_table("acc_2b.rds", "Experiment 2: 6 full feedback logistic model of listener accuracy")
do_table("acc_2c.rds", "Experiment 2: 6 thin logistic model of listener accuracy")
do_table("acc_3.rds", "Experiment 3 logistic model of listener accuracy")

```

\pagebreak

## Reduction models 
Reduction models were run as linear models with an intercept prior of normal(12,20), a beta prior of normal(0,10), an sd prior of normal(0,5) and a correlation prior of lkj(1). This model was pre-registered for each experiment and run with the mixed effects structure as prespecified. 

```{r}

do_table("red_1.rds", "Experiment 1")
do_table("red_2a.rds", "Experiment 2: 6 single speaker")
do_table("red_2b.rds", "Experiment 2: 6 full feedback")
do_table("red_2c.rds", "Experiment 2: 6 thin")
do_table("red_3.rds", "Experiment 3")

```

### Extra reduction model

For experiment 1, we also pre-specified models about whether the speaker's correctness (as a listener) on the prior block had an effect 

Model of whether speaker’s correct/incorrect answer in previous block  has an effect 

```{r}

read_rds(here(mform_loc, "weird_1.rds")) |> form()
do_table("weird_1.rds", "Experiment 1")

```

### Listener models

```{r}

do_table("list_1.rds", "Experiment 1")

do_table("anylist_1.rds", "Experiment 1")


```
\pagebreak

## SBERT models

For all of the models of sbert similarity, we used linear models with the priors normal(.5,.2) for intercept, normal(0,.1) for beta, and normal(0,.05) for sd. 

These models were verbally described (but not formally specified) in the pre-registrations for experiment 2 in the full feedback and thin conditions and for experiment 3, for looking at divergence between games, convergence within games (compare to first, next, and last), and divergence between tangrams within games. 

### Convergence within games: comparison to last round
This is the convergence metric presented in the paper. 

```{r}

do_table("tolast_1.rds", "Experiment 1", decimal=3)
do_table("tolast_2a.rds", "Experiment 2: 6 single speaker", decimal=3)
do_table("tolast_2b.rds", "Experiment 2: 6 full feedback", decimal=3)
do_table("tolast_2c.rds", "Experiment 2: 6 thin", decimal=3)
do_table("tolast_3.rds", "Experiment 3", decimal=3)

```

\pagebreak

### Divergence across games

To look at how games diverged from each other ... TODO
```{r}

do_table("div_1.rds", "Experiment 1", decimal=3)
do_table("div_2a.rds", "Experiment 2: 6 single speaker",decimal=3)
do_table("div_2b.rds", "Experiment 2: 6 full feedback",decimal=3)
do_table("div_2c.rds", "Experiment 2: 6 thin",decimal=3)
do_table("div_3.rds", "Experiment 3",decimal=3)

```

\pagebreak

### Divergence across tangrams


```{r}

do_table("tandiv_1.rds", "Experiment 1",decimal=3)
do_table("tandiv_2a.rds", "Experiment 2: 6 single speaker",decimal=3)
do_table("tandiv_2b.rds", "Experiment 2: 6 full feedback",decimal=3)
do_table("tandiv_2c.rds", "Experiment 2: 6 thin",decimal=3)
do_table("tandiv_3.rds", "Experiment 3",decimal=3)

```

\pagebreak

### convergence to next

We also looked at how similar an utterance was to the next round utterance: this can be thought of as the derivative of the to-last comparison. (although cosine similarities are not actually additive in the same way integrals are)
```{r}

do_table("tonext_1.rds", "Experiment 1",decimal=3)
do_table("tonext_2a.rds", "Experiment 2: 6 single speaker",decimal=3)
do_table("tonext_2b.rds", "Experiment 2: 6 full feedback",decimal=3)
do_table("tonext_2c.rds", "Experiment 2: 6 thin",decimal=3)
do_table("tonext_3.rds", "Experiment 3",decimal=3)

```

\pagebreak

### divergence from first

We also looked at how similar an utterance was to the first round utterance. This is not very informative because first round utterances tend to be pretty unwieldy. TODO explain more or don't include
```{r}

do_table("tofirst_1.rds", "Experiment 1",decimal=3)
do_table("tofirst_2a.rds", "Experiment 2: 6 single speaker",decimal=3)
do_table("tofirst_2b.rds", "Experiment 2: 6 full feedback",decimal=3)
do_table("tofirst_2c.rds", "Experiment 2: 6 thin",decimal=3)
do_table("tofirst_3.rds", "Experiment 3",decimal=3)

```

### Extra emoji analysis
Written about 6thin in experiment 2 and for 2 and 6 thin in 3
Additionally, exclusive to this condition, we will analyse the distribution of emoji’s produced as a function of block and its relation to accuracy and speaker utterance length.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent


