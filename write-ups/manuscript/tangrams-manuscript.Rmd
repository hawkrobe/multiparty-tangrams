---
title: Interaction structure constrains the emergence of conventions in group communication

author:
  - name: Veronica Boyce
    email: vboyce@stanford.edu 
    affiliation:
      - Stanford 
    footnote:
      - corresp
  - name: Robert Hawkins
    affiliation: 
      - Stanford
  - name: Noah D. Goodman
    affiliation: 
      - Stanford
  - name: Michael C. Frank 
    affiliation: 
      - Stanford
address:
  - code: Stanford
    address: Stanford University 
footnote:
  - code: corresp
    text: "Corresponding author. Email: vboyce@stanford.edu"
bibliography: ["papers.bib"] # Replace with one or more of your own bibtex files. Better BibTeX for Zotero is your friend
csl: dmk-format.csl # Use any CSL style. See https://www.zotero.org/styles for a good list. Ignored if citation_package: natbib
link-citations: TRUE
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{angles,positioning,arrows.meta, quotes, shapes, shapes.geometric}
output:
  bookdown::pdf_document2:
    toc: FALSE
    keep_tex: TRUE
    template: generic_article_template.tex
    #md_extensions: "-autolink_bare_uris"
    number_sections: TRUE
    citation_package: default # Can also be "natbib"
  bookdown::word_document2: 
    # Produces largely readable output, though some cross-referencing may fail. Useful for collaboration.
    toc: TRUE
lang: en # Main document language in BCP47 format
geometry: "margin=25mm"
papersize: a4
#linestretch: 2 # for double spacing
endfloat: FALSE # Set to TRUE to turn on latex endfloat package to place figures and tables at end of document
# endfloatoption: # See endfloat documentation for more possibilities
#   - tablesfirst # Default
#   - nomarkers # Default
numberlines: FALSE
authblk: TRUE # FALSE = author affiliations in footnotes; TRUE = author affiliations in a block below author names
footnotehyper: FALSE # TRUE will give you enhanced table footnote capabilities. Set to FALSE to be able to use French blocks. Needed due to what appears to be a latex bug.
urlcolor: blue
linkcolor: blue
citecolor: blue
graphics: TRUE # Needed to be able to include images
tables: TRUE # Needed to be able to include tables

---

<!---------------------- Abstract --------------------->

::: {.abstract data-latex="" lang=en}
*This is an abstract in italics.*

This is the second paragraph not in italics.
:::

<!-- Use class keywords to format keywords section -->
::: {.keywords data-latex="" lang=en}
One keyword; Yet another keyword
:::



<!------------ Main text -------------------->
 

```{r global_options, include=FALSE}
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())


knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.crop = F, out.width = "100%", dpi=300,
                      fig.pos = "tb", fig.path='figs/', fig.env="figure",
                      echo=F, warning=F, cache=TRUE, 
                      message=F, sanitize = T)

color_scheme_1 <- c("2"="#FFBDD4", "3"="#FF7DF0","4"="#D24AFF", "5"="#A12EFF","6"="#6940FF")
color_scheme_2 <- c( "6 single speaker"="#00A2FF","6 thin"="#D47E04","6 full feedback"="#425df5")

color_scheme_3 <- c("6 thin"="#D47E04", "6 thick"="#00BDA8",
                  "2 thin"="#FFDA09", "2 thick"="#77F3DB")


		

```


```{r set-up, include=F}

ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  %>% 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"




image_location="write-ups/images"

msum_loc="code/paper_mods/summary"
mform_loc="code/paper_mods/formulae"

source(here("code/prep_ms.R"))

show_summary <- function(model){
  intervals <- gather_draws(model, `b_.*`, regex=T) %>% mean_qi()
  
  stats <- gather_draws(model, `b_.*`, regex=T) %>% 
    mutate(above_0=ifelse(.value>0, 1,0)) %>% 
    group_by(.variable) %>% 
    summarize(pct_above_0=mean(above_0)) %>% 
   mutate(`P-value equivalent` = signif(2*pmin(pct_above_0,1-pct_above_0), digits=2)) %>% 
    left_join(intervals, by=".variable") %>% 
    mutate(lower=round(.lower, digits=2),
           upper=round(.upper, digits=2),
           `Credible Interval`=str_c("[",lower,", ", upper,"]"),
           Term=str_sub(.variable, 3, -1),
           Estimate=round(.value, digits=2)) %>% 
    select(Term, Estimate, `Credible Interval`, `P-value equivalent`)
  
  stats
}

stats <- function(model, row){
  str_c(model[row,1],": Est=", model[row,2], ", CrI=", model[row,3])
}

stats_text  <- function(model, row){
  str_c( model[row,2], " (CrI=", model[row,3],")")
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) %>% str_replace_all(" ","") %>% 
  str_replace_all("\\*"," $\\\\times$ ") %>% 
  str_replace_all("\\+", "&nbsp;+ ") %>% 
   str_replace_all("~", "$\\\\sim$ ")
}
```

# Introduction 

- communication is important and takes place in non-dyadic situations
- one interesting thing about comm is ad-hoc expressions, adaptation to speaker/ listener pairs

- prior work has focused a lot on dyads: what happens with more people? Do theories predict anything? 

- groups also vary in compositional type aspects so mimics of these might matter

- do we want to set up other theoretical frames? do I need to read more about theory??


Verbal communication is an integral part of our daily lives. We coordinate schedules with partners, socialize with friends over board games, learn and teach in seminar classes, and listen to podcasts. Communicative environments range in size from one-on-one dialogue to broadcast communication to large groups, but the goal of efficient communication is shared across these [@branigan2006;@ginzburg2005;@traum2004]. Shared referring expressions are a necessity for efficient communication; a thing or an idea needs some sort of name that the interlocutors will jointly understand. In many cases, there are widely shared conventionalized expressions for objects or ideas, but in other cases, spontaneous ad-hoc expressions must be invented. 

The formation of these new reference expressions is well-studied in dyadic contexts and has been a case study for efficient communication more broadly. But these dynamics may be different in larger groups, which are less studied. Our current work builds on the dyadic reference game tradition by extending it to larger groups.

<!-- ## Dyadic reference games -->

@clarkReferringCollaborativeProcess1986 established an experimental method for studying the emergence of new referring expressions that has now become standard [building on @kraussChangesReferencePhrases1964;@kraussConcurrentFeedbackConfirmation1966]. Two participants see the same set of tangram figures; the speaker describes each figure in turn so the listener can select the target from the set of figures. The speaker and listener repeat this process with the same images over a series of blocks. Early descriptions are long and make reference to multiple features in the figure, but in later iterations, shorthand conventional names for each figure emerge; this shortening of utterances is called 'reduction'. 

Recently, online participant recruitment and web-based experiments have made it possible to study this convergence in larger populations [@hawkinsCharacterizingDynamicsLearning2020;@haber2019]. In @hawkinsCharacterizingDynamicsLearning2020, 83 pairs completed a similar iterated reference experiment where they communicated via a chat box. Speakers reduced their utterances, producing fewer words per image in later blocks than in earlier blocks, in line with results from face-to-face, oral paradigms.^[We use "speaker" and "listener" to refer to the roles describing and selecting targets, regardless of communication modality.]
<!-- ## Multi-party communication -->

How does this process proceed in multi-party communication? In a dyad, speakers can tailor their utterances to the one listener, but in large groups, speakers must balance the competing needs of different listeners [@schober1989;@tolins2016]. These effects likely vary by both the knowledge state of and communication channels available to the listeners [@fox-tree2013;@horton2002; @horton2005]. Prior work has focused on manipulating knowledge states by adding new listeners to established groups.




```{r interface, fig.env = "figure*", fig.pos = "t!", fig.width=6, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "All participants saw all 12 tangram images. (A) Speaker's view during selection phase. (B) During the feedback stage, speakers saw what figure each person chose, but listeners only learned if their selection was correct or incorrect. Listeners were not shown what other listeners chose. \\label{game}", cache=FALSE}

img <- png::readPNG(here(image_location, "merged_fig2.png"))
grid::grid.raster(img)
```

In this context, one approach for speakers is to 'aim low' and produce utterances tailored to the least knowledgeable listener [@yoonAimLowMechanisms2018a]. For instance, in @yoonAdjustingConceptualPacts2014, speakers developed conventions with one listener but then used longer descriptions with a new listener. Another strategy for speakers is to integrate across listeners and balance efficiency with informativeness by 'aiming in the middle'. In @yoonAudienceDesignMultiparty2019, speakers communicating to a mixed group of 3 experienced listeners and 1 naive listener used shorter utterances and made fewer accommodations than they did in groups with a greater fraction of naive listeners. Both of these strategies predict that larger groups will be slower to converge than smaller groups.

Disagreements about how to conceptualize referents can also slow groups down. In @weberCulturalConflictMerger2003, pairs of participants played a reference game with the same image sets before a listener switched groups and joined a different pair, making a group of three. The addition of the new listener slowed both listeners down for multiple rounds. When a listener switched groups, they brought preconceptions about how the pictures should be described which conflicted with how the speaker was used to describing the images. This result predicts that, with more perspectives in play, larger groups may have more difficulty agreeing on common conceptualizations.

In general, listeners expect speakers to maintain conventions and stick to descriptions that were similar to successful descriptions. However, listeners were not surprised to hear different descriptions of a familiar object if it came from a new speaker who had just entered the room [@metzingWhenConceptualPacts2003]. It's unclear what this finding predicts about new speakers who are present as fellow listeners during prior blocks -- will listeners expect them to maintain conventions? 



```{r count, include=F}
# TODO counts for all games
# For abstract (and elsewhere) count things!

games <- combined_results %>% select(gameId) %>% unique() %>% nrow() # 98

players <- combined_results %>% select(gameId, numPlayers) %>% unique() %>% summarize(players=sum(numPlayers)) # 390

words <- combined_chat %>% ungroup() %>% select(total_num_words) %>% summarize(words=sum(total_num_words)) #116000

```




# Methods

```{=latex}

	\definecolor{baseline6}{HTML}{6940FF}
		\definecolor{baseline5}{HTML}{A12EFF}
			\definecolor{baseline4}{HTML}{D24AFF}
	\definecolor{baseline3}{HTML}{FF7DF0}
		\definecolor{baseline2}{HTML}{FFBDD4}
		
		\definecolor{thick6}{HTML}{00BDA8}
		\definecolor{thick2}{HTML}{77F3DB}
		
	\definecolor{thin6}{HTML}{D47E04}
	\definecolor{thin2}{HTML}{FFDA09}
	
	\definecolor{single}{HTML}{00A2FF}
	\definecolor{full}{HTML}{425df5}
	
	\definecolor{expt1col}{HTML}{FF0099}
		\definecolor{expt3col}{HTML}{527319}
				\definecolor{expt2col}{HTML}{0000FF}

\tikzset{
	expt1/.style={
		draw, circle, color=expt1col, line width=4, align=center, scale=2},
	expt2/.style={
		draw, circle, color=expt2col, line width=4,  align=center, scale=2},
	expt3/.style={
		draw, circle, color=expt3col, line width=4, align=center, scale=2}
}
\tikzset{nodes={font=\sffamily\bfseries}} 

\begin{figure}
	\begin{tikzpicture}
	
	\def\r{6}
	\draw (0,0) edge[-Stealth, line width=1] ["Backchannel", sloped, pos=.3] (-2*\r/5,  -2*\r/3) ;
	\draw (0,0) edge[-Stealth, line width=1] ["Group Size", pos=.9] (\r, 0) ;
	\draw (0,0) edge[-Stealth, line width=1] ["Group coherence", sloped, pos=.3] (0, \r);
	
	\node (n2) at (0,0) [expt1, fill=baseline2, label={[expt1col]below:2}] {};
	\node (n3) at (1,0) [expt1, fill=baseline3, label={[expt1col]below:3}]{};
	\node (n4) at (2,0) [expt1, fill=baseline4, label={[expt1col]below:4}] {};
	\node (n5) at (3,0) [expt1, fill=baseline5, label={[expt1col]below:5}] {};
	\node (n6) at (4,0) [expt1, fill=baseline6] {};
		\node[align=center,anchor=north,text=expt1col] at (4.6,-.45) {6 baseline};
	
	\node (n2thick) at (0,4) [expt3, fill=thick2, label= {[expt3col]above right:2 thick}] {};
	\node (n6thick) at (4,4) [expt3, fill=thick6, label={[expt3col]right:6 thick}] {};
	
	\node (nfull) at (4,1.5) [expt2, fill=full, label={[expt2col]right:6 full feedback}] {};
	\node (nsingle) at (4,3) [expt2, fill=single, label={[expt2col]right:6 single speaker}] {};
	
	\node (n2thin) at (-3/2,-5/2) [expt3, fill=thin2, label={[expt3col]below right: 2 thin}] {};
	\node (n6thin2) at (2.7,-2.3) [expt2, fill=thin6, label={[expt2col] right: 6 thin}] {};
	\node (n6thin) at (2.5,-2.5) [expt3, fill=thin6, label={[expt3col]below right: 6 thin}] {};
	
	\node[align=center,anchor=north] (lab1) at (-2.5,2) {Rotating speaker;\\limited feedback};
	\node[align=center,anchor=north] (lab2) at (-2.5,4) {Single speaker;\\full feedback};
	\node[align=center,anchor=north] (lab3) at (-2,.5) {Listeners \\use chat};
	\node[align=center,anchor=north] (lab4) at (-3.5,-2) {Listeners \\use emoji};
	
	\node[align=center,anchor=north, text=expt1col] (ex1) at (2,1) {Experiment 1};
	\node[align=center,anchor=north, text=expt2col] (ex1) at (2,2.75) {Experiment 2};
	\node[align=center,anchor=north, text=expt3col] (ex1) at (.7,-1.7) {Experiment 3};
	
	\draw[dashed] (n6) edge [] (n6thin);
	\draw[dashed] (n2thin) edge [] (n6thin);
	\draw[dashed] (n2thick) edge [] (n6thick);
	\draw[dashed] (n6) edge [] (n6thick);
	
	\begin{scope}[line width=1 pt, >=Stealth]
		\draw[->] (lab1) -> (n2);
		\draw[->] (lab2) -> (n2thick);
		\draw[->] (lab3) -> (n2);
		\draw[->] (lab4) -> (n2thin);
	\end{scope}
	
\end{tikzpicture}

\caption{FOOBAR}
\end{figure}



```

## fluff
For a first experiment, we extend the dyadic repeated reference game paradigm of @hawkinsCharacterizingDynamicsLearning2020 to games for 2--6 players who rotate between speaker and listener roles. This paradigm allowed us to test how the findings from dyadic interated reference games extend to larger groups and were influenced by group size. Additionally, to more closely examine how conventionalized names develop within groups and differ between groups, we used sentence embeddings to quantify the similarities of descriptions within and between groups over time.
Building on the methods of @hawkinsCharacterizingDynamicsLearning2020, we used Empirica [@almaatouqEmpiricaVirtualLab2020] to create real-time multi-player reference games. In each game, one of the players started as the speaker who saw an array of tangrams with one highlighted (Figure \ref{game}A) and communicated which figure to click to the other players (listeners). After the speaker had identified each of the 12 images in turn, the speaker role rotated to another player and the process repeated with the same images. In total, there were 6 blocks, giving each player at least one chance to be the speaker.   We recorded what participants said in the chat, as well as who selected what image and how long they took to make their selections. <!--^[Code to run the experiment, as well as data and analysis code are available at https://osf.io/qdvbr/?view_only=47aebfde243f405e9c42a45cacb697d2.] We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study.^[Our preregistrations are at https://osf.io/cn9f4/?view_only=7fdacd698b24465cb1a8699050af5bfc and  https://osf.io/rpz67?view_only=5284203e2b644fc5ac39cf3e723b9a7e.]-->

After experiment 1, there were concerns about whether the results were dependent on any of the methods details. We were also interested in whether there were changes in knowledge or group communication that could support (or diminish) success, especially in the larger groups. To explore this, we ran 3 variants of the paradigm in experiment 1, varying different parameters. These were all run on small sets of 6 player groups. 

TODO examples of prior literature that rotated or didn't rotate !!!
Previous literature varied on whether one person had the speaker role the entire game, or whether the two participants alternated speaker and listener roles in some way. For experiment 1, we went with rotating the speaker every block: we thought this would be percieved as more fair by participants, and we thought it would be a more stringent test of convergence to convention. However, in smaller groups, the speaker role would rotate back around, meaning that the speaker in later blocks would be more experienced in small games than in large games where speakers were usually first time speakers. We cannot disentangle the effects of group size from the effects of speaker experience. To address whether continuity in speakers might contribute to better performance, in experiment 2a we ran 6 player games with one person assigned to be the speaker the entire game. 

Another point of variation in the literature is what sort of feedback is given. In particular, there is variation in whether participants were told what the right answer was when they were wrong (like in @hawkinsCharacterizingDynamicsLearning2020). In experiment 1, we opted for the minimum feedback, to make sure that participants had to negotiate and understand conventions, and could not just pick them up from the end of trial feedback. To see whether this mattered, in experiment 2b, we increased the amount of feedback, showing each participant what everyone had selected and what the right answer was. 

Listener feedback to the speaker in the form of some backchannel, is implicated in the theoretical literature as being important to convention formation TODO CITES. We were interested in whether limiting this backchannel would be a way to push around the reduction pattern and significantly change it. We were worried that entirely removing the backchannel would make the game too unfun and encourage random clicking or quitting of the speaker was just talking into the void. As a compromise between limiting the backchannel and maintaining playability, we switched to giving the listeners a discrete backchannel consisting of 4 emojis, expressing whether they understood, whether they wanted more details, whether they were totally confused, or whether they were amused (TODO figure with emojis and their meanings). These options were based on the common valences expressed in the free chat of listeners from experiment 1. Thus, in 2c, listeners could not contribute questions or content to the discourse, but the speaker still had some feedback on whether the listeners were understanding. 

Based on the results of experiment 2, it seemed that speaker continuity helped groups, and that more feedback maybe helped groups, while limiting the backchannel reduced accuracy and reduction. These results are tentative as we had a limited number of groups in each of these conditions. To more robustly demonstrate that the reduction phenomena were sensitive to these variations in group structure and coherency and to investigate how they interacted with group size, we conducted a better powered experiment. As these experiments are expensive to run, we did not do a full-factorial design; instead, we collapsed the three sources of variation into a "thick-channel" condition, combining single speaker, high feedback, and text backchannel, the settings that give richer feedback and knowledge, and a "thin-channel" condition, which was the opposite (same condition as 2c above). We crossed these two conditions with group size: either 2 or 6 player groups, picking the extreme values from experiment 1. 

We aimed for 40 games in each of these 4 cells. We had previously experienced problems with attrition in 6-player games, as when one or more participants quit, the game discontinued on everyone, leading to fewer games with data from the entire game. To mitigate this, we reprogrammed the game to instead try to keep the game going with the participants who were left (and to start games even if they hadn't filled completely). 

## Methods

Pre-regs:
1: https://osf.io/cn9f4 for the 2-4 player groups, and https://osf.io/rpz67 for the 5-6 player data run later
2a: https://osf.io/f9xyd
2b: https://osf.io/j5zbm
2c: https://osf.io/k5f4t
3: https://osf.io/untzy


## Participants

Participants were recruited using the Prolific platform, and all participants self-reported as fluent native English speakers on Prolific's demographic prescreen. Participants each took part in only one experiment. Experiment 1 took place between May and July 2021, experiment 2 between March and August 2022, and experiment 3 in October 2022. As games varied in length depending on the number of participants, we paid participants based on group size, with the goal of a \$10 hourly rate.  Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, \$10 for 4-player games, and \$11 for 5- and 6-player games. When one player had the speaker role for the entirety of a 6-player game, they gained an addition \$2 bonus. Across all games, each participant could early up to \$2.88 in performance bonuses. A total of 1319 people participated across the 3 experiments. 


## Materials

We used the 12 tangram images used by @hawkinsCharacterizingDynamicsLearning2020 and @clarkReferringCollaborativeProcess1986 (see Figure \ref{game}). These images were displayed in a grid with order randomized for each participant (thus descriptions such as "top left" were ineffective as the image might be in a different place on the speaker's and listeners' screens). The same images were used every block. 

## Procedure


```{r participants}
summary <- combined_results %>% group_by(condition, trialNum, repNum, gameId, numPlayers) %>% 
  mutate(numPlayers=ifelse(condition %in% c("6_thin", "6_thick"), "6*", as.character(numPlayers))) |> 
  group_by(gameId, numPlayers, condition) %>% 
  summarize(num_trials=max(trialNum)) %>% 
  arrange(numPlayers) %>% 
  mutate(complete=ifelse(num_trials==71,T,F)) %>% 
  group_by(numPlayers,complete, condition) %>% 
  tally() %>% 
  pivot_wider(names_from=complete, values_from=n) %>% 
  rename(Players=numPlayers,Complete=`TRUE`, Partial=`FALSE`) %>% 
  mutate(Partial=ifelse(is.na(Partial), 0, Partial)) |> 
  mutate(Experiment=factor(condition, levels=c("rotate","no_rotate","full_feedback", "emoji", "2_thin", "6_thin", "2_thick", "6_thick"),
                          labels=c("1: baseline", "2: single speaker", "2: full feedback", "2: thin", "3: thin", "3: thin", "3: thick", "3: thick"))) |> 
  select(Experiment, Players, Complete, Partial) |> 
  arrange(Experiment, Players,Complete,Partial)

knitr::kable(summary, caption="The number of games in each experiment and condition. Complete games finished all 6 blocks; partial games ended early due to disconnections, but contributed at least one complete block of data. 6* indicates that some games started with fewer than 6 players or continued with fewer than 6 players after participants disconnected.")
```
The experimental procedure was very similar across the three experiments. We first describe the procedure used in experiment 1 and then describe the differences in later experiments. 

### Experiment 1
We implemented the experiment using Empirica, a Javascript-based platform for running real-time interactive experiments online [@almaatouqEmpiricaVirtualLab2020].  From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages explaining the game. Participants had to pass a quiz to be able to play the game. They were then directed to a "waiting room" screen until their partners were ready.

Once the game started, participants saw screens like Figure \ref{game}A. Each trial, the speaker described the highlighted tangram image so that the listeners could identify and click it. All participants were free to use the chat box to communicate, but listeners could only click once the speaker had sent a message. Once a listener clicked, they could not change their selection. There was no signal to the speaker or other listeners about who had already made a selection. 

Once all listeners had selected (or a 3-minute timer ran out), participants were given feedback (Figure \ref{game}B). Listeners learned whether they individually had chosen correctly or not; listeners who were incorrect were not told the correct answer. The speaker saw which tangram each listener had selected, but listeners did not. This feedback regime is different from @hawkinsCharacterizingDynamicsLearning2020 where listeners were shown what the right answer was during feedback. We made this change to prevent listeners from learning conventions purely as a memorized mapping between utterance and correct answer. 

Listeners got 4 points for each correct answer; the speaker got points equal to the average of the listeners' points. These points translated into performance bonus at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the speaker once. The same person was the speaker for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were speakers 3 times in 2-player games, twice in 3-player games, once or twice in 4 and 5-player games, and once in 6-player games. Rotating the speaker was chosen to keep participants more equally engaged (the speaker role is more work), and to give a more robust test for reduction and convention. 

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

### Differences in experiment 2
Experiment 2 consisted of three different variations on Experiment 1, so we describe the differences from the Experiment 1 procedure. For the differences between games see TABLE TODO. 

The only change for experiment 2a was that one person was designated the speaker for the entire game. 

For experiment 2b, feedback was changed so that all participants in the feedback stage saw the speaker view showing who selected what and what the right answer was. Listeners still saw text saying whether they individually were correct or wrong. 

For experiment 2c, we altered the chatbox interface for listeners. Instead of a textbox, listeners had 4 buttons, each of which sent a different emoji to the chat. Listeners were given suggested meanings for the 4 emojis during instructions. They could send the emojis as often as desired, for instance, initially indicating confusion, and later indicating understanding. In addition, we added notifications that appeared in the chat box saying when a player had made a selection. 

### Differences in experiment 3

The thin channel condition was the same as with experiment 2c, described above. 

The thick channel condition was the same as experiment 1, except that one person was designated the speaker throughout, and all participants saw the speaker view for feedback. 

TODO confirm. Across both conditions, messages were sent to the chat to indicate when a participant had made a selection. 

The large change was behind the scenes, to handle games continuing after a participant had quit. Participants were identified as disconnected if their computer was not responding to the server for YY seconds (for instance if they closed the tab and did not reopen it quickly). If the person who disconnected was a listener, they were just removed, and they were skipped over by the speaker rotation (if applicable). If the person who disconnected was a speaker, that trial was discontinued as there was no way for listeners to get more information, and another person was assigned as speaker for the remainder of the block (or remainder of the game, depending on condition). 

TODO figure out how this interacts with the full blocks thing!!! Maybe we should break the pre-reg? (in general?, only here?)

TODO the actual distribution of game sizes!!

TODO add pre-registrations everywhere

Note: when skimming transcripts to tag non-referential utterances, we noticed that one game in the 6-player thick game had a speaker who did not give any sort of coherent descriptions, even with substantial listener prompting. We excluded this game from analyses. 


## Data pre-processing and exclusions

Participants could use the chat box freely, which meant that the chat transcript contained some non-referential language. The first author skimmed through the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about how well or fast the task was going, and confirmations or denials ("ok", "got it", "yes", "no"). We exclude these utterances from our analyses. Note that chat lines sometimes included non-referential words in addition to words referring to the tangrams ("ok, so it looks like a zombie", "yes, the one with legs"); these lines were retained intact. 

Our intended sample size was 20 complete games in each group size or condition for experiments 1 and 2, and 40 games in each condition in experiment 3. In some cases, we ended up with fewer due to games not filling or participants disconnecting early (Table \ref{parts}).  We excluded incomplete blocks from analyses, but included complete blocks from partial games.

## Modelling strategy
note that accuracy model deviates from pre-reg b/c I went overboard with the mixed effects model structure

All models were run in brms CITE with weakly regularizing priors DESCRIBE




# Results

## Behavioral results

The two key behavioral result outcomes were the accuracies of the listeners at selecting the target tangrams and the number of words produced by the speaker over the course of each trial. 

```{r triptych-acc, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO", cache=FALSE}
# accuracy

# 1
one <- combined_results |> filter(condition=="rotate") %>% group_by(playerId,repNum, gameId, numPlayers) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  mutate(numPlayers=as.character(numPlayers)) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=numPlayers))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
  theme(legend.position="bottom",
              legend.text=element_text(size=12),
        axis.title=element_text(size=10))+
scale_color_manual(values=color_scheme_1)
#2

two <- combined_results |> filter(condition %in% c("no_rotate","full_feedback", "emoji")) %>%
  filter(numPlayers==6) |> 
  group_by(playerId,repNum, gameId, numPlayers) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  theme(legend.position="bottom")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
        scale_color_manual(values=color_scheme_2)

#3
 three <- combined_results |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) %>% group_by(playerId,repNum, gameId, condition) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>%
   mutate(condition=str_replace(condition, "_", " ")) |> 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  theme(legend.position="bottom",
        legend.text=element_text(size=12),
        axis.title=element_text(size=10))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
   scale_color_manual(values=color_scheme_3)
 
 plot_grid(one, two, three, nrow=1)
```


```{r}
acc_1 <- read_rds(here(msum_loc,"acc_1.rds"))
acc_spec_1 <- read_rds(here(mform_loc,"acc_1.rds"))
```
```{r}
acc_2a <- read_rds(here(msum_loc,"acc_2a.rds"))
acc_spec_2a <- read_rds(here(mform_loc,"acc_2a.rds"))

acc_2b <- read_rds(here(msum_loc,"acc_2b.rds"))

acc_2c <- read_rds(here(msum_loc,"acc_2c.rds"))
```
```{r}
acc_3 <- read_rds(here(msum_loc,"acc_3.rds"))
acc_spec_3 <- read_rds(here(mform_loc,"acc_3.rds"))

```


Across all experiments, most individuals were accurate in their selections, with accuracy rising across blocks, but accuracy was noticeably lower, but still far above chance,  in the 6-player games with an emoji backchannel (Figure \ref{accuracy}).  In experiment 1, participants were more accurate in later blocks (`r stats(acc_1,1)`), and there was no strong effect of group size on accuracy (`r stats(acc_1,4)`) or interaction between block and group size (`r stats(acc_1,2)`). In experiment 2, participants were again more accurate in later blocks (2a: `r stats(acc_2a,1)`, 2b: `r stats(acc_2b,1)`, 2c `r stats(acc_2c,1)`). In experiment 3, participants are more accurate in later blocks (`r stats(acc_3,1)`). Participants are less accurate overall in the six player games (`r stats(acc_3, 6)`) and more slow to improve in the six player games (`r stats(acc_3, 3)`). Type of channel did not have a clear effect on accuracy either overall (`r stats(acc_3,2)`) or interacting with time (`r stats(acc_3, 2)`). 


```{r triptych-red, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO", cache=FALSE}

#1

one <- combined_chat |> filter(condition=="rotate") |>  filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram, numPlayers) %>% 
  summarize(words=sum(total_num_words)) |>
    mutate(numPlayers=as.character(numPlayers)) |> 
ggplot(aes(x=repNum+1, y=words, color=numPlayers))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  theme(legend.position="bottom",
        text=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- combined_chat|> filter(condition %in% c("no_rotate","full_feedback", "emoji")) %>%
  filter(numPlayers==6) |> 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram,condition) %>% 
  summarize(words=sum(total_num_words)) |> 
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 single speaker",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin")) |>
ggplot(aes(x=repNum+1, y=words, color=condition))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=14))+
    scale_color_manual(values=color_scheme_2)

#3


three <- combined_chat |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) %>% filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram, condition) %>% 
  summarize(words=sum(total_num_words)) |> 
  mutate(condition=str_replace(condition, "_", " ")) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
  geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

plot_grid(one,two, three, nrow=1)
```



```{r}
red_1 <- read_rds(here(msum_loc, "red_1.rds"))
red_spec_1 <- read_rds(here(mform_loc,"red_1.rds"))

```
```{r}
red_2a <- read_rds(here(msum_loc,"red_2a.rds"))
red_spec_2a <- read_rds(here(mform_loc,"red_2a.rds"))

red_2b <- read_rds(here(msum_loc,"red_2b.rds"))

red_2c <- read_rds(here(msum_loc,"red_2c.rds"))
```
```{r} 
red_3 <- read_rds(here(msum_loc, "red_3.rds"))
red_spec_3 <- read_rds(here(mform_loc, "red_3.rds"))

```

The key phenomonenon of iterated reference games is that the descriptions to the target images shorten over the course of repetition. This pattern held across all experiments and conditions, as the number of words produced by speaked decreased over the course of the game  The number of words produced by speakers decreases over the course of rounds (Figure \ref(fig:triptych-red)). In experiment 1, the overall effect of being one block later was `r stats_text(red_1,1)` words. Speakers in larger groups said more; the effect of each additional player was  `r stats_text(red_1,4)` words per trial, with no clear interaction between block and group size (`r stats(red_1,2)`). In experiment 2, the result of being one block later on the number of words the speaker said per trial was `r stats(red_2a,2)` in experiment 2a; `r stats(red_2b,2)` in 2b, and `r stats(red_2c,2)` in 2c. The rate of reduction was lower in the emoji condition than in the other conditions. In experiment 3, reduction occurred overall (`r stats(red_3,1)`). The six player games said more to start with (`r stats(red_3, 7)`) and reduced less (`r stats(red_3, 4)`) than the two-player games. There were not differences due to channel type (`r stats(red_3, 5)`) or channel type over time (`r stats(red_3, 2)`). 

TODO commentary

## Comparisons of language between and within games

TODO describe SBERT

As a measure of convention formation, we look at the similarity of descriptions within a game for a particular tangram in different blocks. We take the last round descriptions as the established convention and measure the similarity between earlier speaker utterances and this convention. 

```{r triptych-conv, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO", cache=FALSE}
#convergence

one_two_converge <- read_rds(here("code/models/one_two_converge.rds"))
three_converge <- read_rds(here("code/models/three_converge.rds"))
#1
one <- one_two_converge |> filter(condition %in% c("2", "3","4","5","6")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  theme(legend.position="bottom",
        text=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two <- one_two_converge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=14))+    scale_color_manual(values=color_scheme_2)



#3



three <- three_converge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |>  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+

  theme(legend.position="bottom",
        text=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

plot_grid(one, two, three, nrow=1)
```

```{r}
tolast_1 <- read_rds(here(msum_loc, "tolast_1.rds"))
tolast_spec_1 <- read_rds(here(mform_loc, "tolast_1.rds"))

tonext_1 <- read_rds(here(msum_loc, "tonext_1.rds"))
tonext_spec_1 <- read_rds(here(mform_loc, "tonext_1.rds"))

tofirst_1 <- read_rds(here(msum_loc, "tofirst_1.rds"))
tofirst_spec_1 <- read_rds(here(mform_loc, "tofirst_1.rds"))

```

```{r}
tolast_2a <- read_rds(here(msum_loc, "tolast_2a.rds"))
tolast_spec_2a <- read_rds(here(mform_loc, "tolast_2a.rds"))

tonext_2a <- read_rds(here(msum_loc, "tonext_2a.rds"))
tonext_spec_2a <- read_rds(here(mform_loc, "tonext_2a.rds"))

tofirst_2a <- read_rds(here(msum_loc, "tofirst_2a.rds"))
tofirst_spec_2a <- read_rds(here(mform_loc, "tofirst_2a.rds"))


tolast_2b <- read_rds(here(msum_loc, "tolast_2b.rds"))

tonext_2b <- read_rds(here(msum_loc, "tonext_2b.rds"))

tofirst_2b <- read_rds(here(msum_loc, "tofirst_2b.rds"))


tolast_2c <- read_rds(here(msum_loc, "tolast_2c.rds"))

tonext_2c <- read_rds(here(msum_loc, "tonext_2c.rds"))

tofirst_2c <- read_rds(here(msum_loc, "tofirst_2c.rds"))

```

```{r}
tolast_3 <- read_rds(here(msum_loc, "tolast_3.rds"))
tolast_spec_3 <- read_rds(here(mform_loc, "tolast_3.rds"))

tonext_3 <- read_rds(here(msum_loc, "tonext_3.rds"))
tonext_spec_3 <- read_rds(here(mform_loc, "tonext_3.rds"))

tofirst_3 <- read_rds(here(msum_loc, "tofirst_3.rds"))
tofirst_spec_3 <- read_rds(here(mform_loc, "tofirst_3.rds"))

```

In experiment 1, later utterances are more similar to the last utterance than earlier utterances are (`r stats_text(tolast_1, 2)`). The distance from the first to last utterances is invariant across group size (`r stats_text(tolast_1, 1)`), but smaller groups converge faster (`r stats_text(tolast_1, 3)`). Experiment 2 shows similar patterns of utterances become more similar to the last utterance, especially in the non-rotating 2a (`r stats_text(tolast_2a, 1)`), but also in 2b (`r stats_text(tolast_2b, 1)`) and to a smaller extent, 2c (`r stats_text(tolast_2c, 1)`). 

In terms of convergence towards the last round utterance, this is seen overall (`r stats_text(tolast_3, 3)`). The convergence is slower in thin games (`r stats_text(tolast_3, 4)`) and especially thin 6 player games (`r stats_text(tolast_3, 5)`). 

Comparing utterances between adjacent rounds reveals similar patterns. Thin games have lower similarity between adjacent blocks (`r stats_text(tonext_3, 1)`) as do larger games (`r stats_text(tonext_3,7)`). Later in the game adjacent blocks are more similar than earlier adjacent blocks (`r stats_text(tonext_3, 3)`), painting an overall nonlinear convergent pattern (as seen in figure TODO). 

The last measure of how utterances change within games is how they compare to the first utterance; this is less good because the first utterance has more fluffy language so is less diagnostic, but later utterances are further from the first round utterance than earlier utterances (`r stats_text(tofirst_3, 5)`). (TODO it's in the pre-reg, but we could dump it in a supplement? )






### Divergence 

```{r triptych-div, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO", cache=FALSE}

one_two_diverge <- read_rds(here("code/models/one_two_diverge.rds"))
three_diverge <- read_rds(here("code/models/three_diverge.rds"))
# divergence

#1
one <-  one_two_diverge |> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=16))+scale_color_manual(values=color_scheme_1)

#2

two <-  one_two_diverge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 single speaker",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin")) |>
                              ggplot( aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
      coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  theme(legend.position="bottom",
        text=element_text(size=16))+
   scale_color_manual(values=color_scheme_2)

#3
three <-  three_diverge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) |> ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=16))+
scale_color_manual(values=color_scheme_3)

plot_grid(one,two,three, nrow=1)
```

```{r}
div_1 <- read_rds(here(msum_loc, "div_1.rds"))
div_spec_1 <- read_rds(here(mform_loc, "div_1.rds"))

```
```{r}
div_2a <- read_rds(here(msum_loc, "div_2a.rds"))
div_spec_2a <- read_rds(here(mform_loc, "div_2a.rds"))

div_2b <- read_rds(here(msum_loc, "div_2b.rds"))

div_2c <- read_rds(here(msum_loc, "div_2c.rds"))
```
```{r} 
div_3 <- read_rds(here(msum_loc, "div_3.rds"))
div_spec_3 <- read_rds(here(mform_loc, "div_3.rds"))
```

Over the course of the game, different groups develop their own ways of identifying the different figures. As groups diverge, their descriptions become less similar to those used to describe the same figure in other games (`r stats_text(div_1, 1)`). Group size does not affect the cross-groups similarities in the first block (`r stats_text(div_1, 3)`), but smaller groups diverge from each other faster than larger groups (`r stats_text(div_1,2)`). 


All three sub-experiments show the pattern of divergence where descriptions are less similar across groups in later blocks than in earlier blocks. This reduction is stronger in 2a (`r stats_text(div_2a, 1)`) and 2b (`r stats_text(div_2b, 1)`) than in 2c (`r stats_text(div_2c, 1)`). 


In a model of similarities between utterances produced at the same point in the game for the same tangram across different games (`r form(div_spec_3)`), games get less similar over time (`r stats_text(div_3, 1)`). There are slight differences in the initial starting points across the different conditions, as well as slight condition differences in how fast the games diverge. In particular, 6 player thin games diverge more slowly (` r stats_text(div_3, 3)`). 



### Distinctiveness of tangrams

```{r}

tandiv_1 <- read_rds(here(msum_loc, "tandiv_1.rds"))
tandiv_spec_1 <- read_rds(here(mform_loc, "tandiv_1.rds"))

```
```{r}

tandiv_2a <- read_rds(here(msum_loc, "tandiv_2a.rds"))
tandiv_spec_2a<- read_rds(here(mform_loc, "tandiv_2a.rds"))

tandiv_2b <- read_rds(here(msum_loc, "tandiv_2c.rds"))

tandiv_2c <- read_rds(here(msum_loc, "tandiv_2c.rds"))

```

```{r}
# file naming screwup TODO fix me and the file that writes me etc
tandiv_3 <- read_rds(here(msum_loc,"tandiv3.rds"))
tandiv_spec_3 <- read_rds(here(mform_loc, "tandiv3.rds"))

```

Another way of looking at how language changes over the course of the game is looking at how games start to refer to different tangrams more differently. This could reflect initial overlap in descriping many figures as sitting or standing or by leg and arm and head position. 

Over the course of the game, descriptions for each tangram become more distinctive (`r stats_text(tandiv_1, 1)`). 
In all three subexperiments, the descriptions of tangrams become more distinctive within games across time. (2a `r stats_text(tandiv_2a,1)`, 2b `r stats_text(tandiv_2b, 1)`, 2c `r stats_text(tandiv_2c,1)`). 


Tangram distinctiveness within games increased over time (`r stats_text(tandiv_3, 1)`). There might be more to say about other effects, but it's mostly a starting places being different in larger games and then the slopes also differ a bit? 


### Emoji usage ? 




 
TODO there's a note saying to rerun these models for longer with more extensive mixed effects!! (at least of reduction model)

### Examples of names

While most groups did form conventions for most tangrams, it's illustrative to look at a case where a group did not. Table \ref{diamond} shows the transcript of a 4-person group for a specific figure where they described it geometrically every round, leading to long and not very informative descriptions. Nearly all the figures have diamond heads, so this isn't a distinguishing feature, yet it is described. This illustrates the variability between groups, but also why conventions might be useful. 


```{r diamond}
diamond <- tribble(~`Block`, ~`Person`, ~Text,
                 "1","A(S)","Diamond on top. Body with no real arms or legs. The body is shaped like a boot with the diamond on top.",
		"","C", "Is the boot pointed left or right?",
		"2", "B(S)", "diamond on top, large body beneath it. Left is a straight line all the way down, small variations on the right to the main body",
		"3", "C(S)", "Diamond in center on top. Left side straight, right side carved out like a vase.",
		"4", "D(S)", "Diamond head, flat topped body, straight on the left side with two triangles pointing out on the left",
		"","D(S)" ,"*on the right",
	"5" ,"A(S)", "Diamond on top. Left side is straight, right side is obstructed, looks like a boot",
	"", 	"B", "what do you mean by obstructed?",
		"", "A(S)", "The left side of the body is right, right side has bents in it",
		"6", "B(S)", "Diamond on top of a long large body/rectangle. Left side is complete, right side has bits missing")

knitr::kable(diamond, caption = "Excerpt from a group that did not reduce very much. The speaker for each round is marked with (S). Figure under discussion is row 3, column 3 in Figure \\ref{game}A.\\label{diamond}",  format="latex", booktabs=TRUE, linesep="") %>%
kable_styling(full_width = F) %>%
column_spec(3, width = "16em") %>% kable_styling(latex_options="H")

```



A different 4-person group had a member who during the first block shared the idea that the task would be easier if they explicitly gave "codenames" to the figures. The transcript for this group and one of the tangrams is shown in Table \ref{zigzag}. Of note, multiple speakers forget the assigned codename, demonstrating that meta-knowledge doesn't always help. This group also describes the figure in relation to another already-named figured. Nonetheless, the group successfully conventionalizes on a couple reduced names for this figure: "zigzag" and "beggar". This dual-naming of figures from multiple conceptual angles contributed by different speakers also occurs in other games. 


# General Discussion

this isn't the only group dynamic; could imagine situations where listeners can see each others work collaborate (point to each other what htey think, perhaps see feedback from speaker to one listener) which might make things reduce much faster


The emergence of conventions has been a key case study for communication more broadly. Yet this issue has -- for the most part -- been studied only in dyadic communication. While some studies have examined aspects of convention formation in larger groups [e.g., @yoonAdjustingConceptualPacts2014;@yoonAudienceDesignMultiparty2019], basic descriptive work has not yet investigated how group size changes the dynamics of interaction in a standard referential communication task, in part because such tasks can be difficult to administer to larger groups. Taking advantage of a new online multi-player experiment platform, we ran repeated reference games with groups of 2--6 players and characterized the nature of group performance.

Consistent with dyadic games, listeners' selection accuracy increased over blocks at the same time as listeners sped up their selections (question 1). 
Crucially, speakers reduced the length of their descriptive utterances as they conventionalized on concepts for each image (question 2). Because speakers rotated, this reduction finding is robust: not only did speakers say less in later repetitions than they themselves said earlier, speakers later in the order said less than speakers earlier in the rotation. This reduction varied with group size; smaller groups used shorter utterances, but group size did not significantly interact with block (question 3). The trajectory of reduction also depended on whether the current speaker correctly identified the tangram in the prior block and whether the current speaker was new to being speaker. This pattern is consistent with both the 'aim low' and 'aim middle' hypotheses from previous work [@yoonAdjustingConceptualPacts2014;@yoonAudienceDesignMultiparty2019].

What was specifically different across group sizes? Smaller groups showed more agreement in how each tangram was identified across blocks (question 4), coming to consensus earlier: Their overlap between descriptions in the first 5 blocks to the final block was higher, and words in the final block tended to originate earlier. The greater diversity in how tangrams were described in larger groups could be explained by slower convergence to a convention or parallel competing conceptualizations favored by different speakers. Larger groups have more people for the speaker to communicate to, but also more people who might interrupt with questions, and more people who have opinions about what each image looks like. Bigger groups differ from smaller groups in a number of ways, however, and disentangling these differences is an area for future work. 

<!-- ## Limitations -->

Group interactions are rich, and this experiment is necessarily a schematic simplification with a number of limitations. Real-life situations vary widely in who the interlocuters are, their relationships, their goals, and their environment [@fay2000;@carletta1998]. Our participants were a convenience sample of Prolific workers who were strangers to each other; thus we miss richness that could come from prior relationships or shared community.  Reference is only one goal out of many possible communicative goals, and the tangram images are artificial. 
We provided less feedback than previous studies such as @hawkinsCharacterizingDynamicsLearning2020; this regime imitates situations where interlocutors can't show each other examples, but it's not representative of all communicative environments. Further, our text-based online paradigm meant that participants' individual identities were not especially salient. In sum, communication takes place in a plethora of situations; our experiment provides some insights, but also misses many complexities that should be a focus of further experiments. 

<!-- ## Future work -->

The experimental paradigm presented here could be a valuable tool to disentangle the mechanisms of group size and determine which design parameters are relevant to reduction. Luckily, with an online implementation, recruiting for and running experiments is feasible, and thus it will be possible to iterate on this experiment to determine how far the patterns generalize. While much is left to be explored, this initial data set provides a rich corpus of how humans adapt language dynamically to communicate. 

## Limitations


# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

