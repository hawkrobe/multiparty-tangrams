---
title: |
  | Interaction structure constrains 
  | the emergence of conventions in group communication

author:
  - name: Veronica Boyce
    email: vboyce@stanford.edu 
    affiliation:
      - Stanford 
    footnote:
      - corresp
  - name: Robert Hawkins
    affiliation: 
      - UW-Madison
  - name: Noah D. Goodman
    affiliation: 
      - Stanford
  - name: Michael C. Frank 
    affiliation: 
      - Stanford
address:
  - code: Stanford
    address: Stanford University 
  - code: UW-Madison
    address: University of Wisconsin -- Madison
footnote:
  - code: corresp
    text: "Corresponding author. Email: vboyce@stanford.edu"
bibliography: ["papers.bib"] # Replace with one or more of your own bibtex files. Better BibTeX for Zotero is your friend
csl: dmk-format.csl # Use any CSL style. See https://www.zotero.org/styles for a good list. Ignored if citation_package: natbib
link-citations: TRUE
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{angles,positioning,arrows.meta, quotes, shapes, shapes.geometric}
  - \usepackage{graphicx}
output:
  bookdown::pdf_document2:
    toc: FALSE
    keep_tex: TRUE
    template: generic_article_template.tex
    #md_extensions: "-autolink_bare_uris"
    number_sections: FALSE
    citation_package: default # Can also be "natbib"
lang: en # Main document language in BCP47 format
geometry: "margin=1.25in"
linestretch: 1 # for double spacing
endfloat: FALSE # Set to TRUE to turn on latex endfloat package to place figures and tables at end of document
# endfloatoption: # See endfloat documentation for more possibilities
#   - tablesfirst # Default
#   - nomarkers # Default
numberlines: FALSE
authblk: TRUE # FALSE = author affiliations in footnotes; TRUE = author affiliations in a block below author names
footnotehyper: FALSE # TRUE will give you enhanced table footnote capabilities. Set to FALSE to be able to use French blocks. Needed due to what appears to be a latex bug.
urlcolor: blue
linkcolor: blue
citecolor: blue
graphics: TRUE # Needed to be able to include images
tables: TRUE # Needed to be able to include tables

---

<!---------------------- Abstract --------------------->

::: {.abstract data-latex="" lang=en}

Real-world communication frequently requires language producers to address more than one comprehender at once, yet most psycholinguistic research focuses on one-on-one communication.
As the audience size grows, interlocuters face new challenges that do not arise in dyads. 
They must consider multiple perspectives and weigh multiple sources of feedback to build shared understanding.
Here, we ask which properties of the group's *interaction structure* facilitates successful communication.
We used a repeated reference game paradigm in which directors instructed between one and five matchers to choose specific targets out of a set of abstract figures. 
Across 313 games ($N=1,319$ participants), we manipulated several key constraints on the group's interaction, including the amount of feedback that matchers could give to directors and the availability of interaction between matchers. Across groups of different sizes and interaction constraints, describers used increasingly short utterances to convey their meaning to matchers who selected the targets with increasing accuracy. Smaller groups and groups with less-constrained interaction structures ("thick channels") showed stronger convergence to group-specific conventions, while large groups with limiting interaction structures ("thin channels") struggled with convention formation. Overall, these results shed new light on the core structural factors that enable communication to thrive in larger groups.

:::

<!------------ Main text -------------------->

```{r set-up, include=FALSE}
require(Hmisc)#not directly called, but needed for dots on plots with mean_ci_boot ! 
#this has to go first b/c it defines summarize and that screws things up
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)
 

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())

knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.crop = F, out.width = "100%", dpi=300,
                      fig.pos = "tb", fig.path='figs/', fig.env="figure",
                      echo=F, warning=F, cache=T, 
                      message=F, sanitize = T)

color_scheme_1 <- c("2"="#FFBDD4", "5"="#A12EFF", "3"="#FF7DF0","6"="#6940FF","4"="#D24AFF")
color_scheme_2 <- c( "6 full feedback"="#425df5", "6 same describer"="#00A2FF","6 thin"="#D47E04")

color_scheme_3 <- c("2 thin"="#FFDA09","6 thin"="#D47E04", 
                    "2 thick"="#77F3DB","6 thick"="#00BDA8")
		
ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  |> 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"
image_location="write-ups/images"
msum_loc="code/paper_mods/summary"
mform_loc="code/paper_mods/formulae"

source(here("code/prep_ms.R"))


stats <- function(model, row, decimal=2){
  model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c("$\\beta=", model[row,2],",\\:95\\%\\:\\mathrm{CrI}=",model[row,3], "$")
}

stats_text  <- function(model, row, decimal=2){
    model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c("", model[row,2],", ($95\\%\\:\\mathrm{CrI}=",model[row,3], "$)")
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
  str_replace_all("\\*"," $\\\\times$ ") |> 
  str_replace_all("\\+", "&nbsp;+ ") |> 
   str_replace_all("~", "$\\\\sim$ ")
}
```

```{r count, include=F}

games <- combined_results |> select(gameId) |> unique() |> nrow() 

players <- combined_results |> select(gameId, numPlayers) |> unique() |> 
summarize(players=sum(numPlayers))

words <- combined_chat |> ungroup() |> select(total_num_words) |> summarize(words=sum(total_num_words)) 
```

# Introduction

Much of human social life revolves around communication in groups. 
At school, teachers address large classrooms of children [@cazden1988classroom]; at home, we chat with groups of friends and family members over dinner [@tannen2005conversational]; and at work, we attend meetings with colleagues and managers [@caplow1957organizational; @zack1993interactivity].
Such settings present considerable challenges that do not arise in the purely two-party (dyadic) settings typically studied in psychology [@branigan2006; @ginzburg2005; @traum2004]. 
For example, producers need to account for the fact that different comprehenders in the group may have different mental states or levels of background understanding [@horton2005; @horton2002; @yoon2018; @yoon2014; @weber2003;@fox-tree2013], while comprehenders must account for the fact that utterances are not necessarily tailored to them [@fay2000; @carletta1998; @metzing2003; @yoon2019; @rogers2013; @cohngordon; @tolins2016].

What enables producers and comprehenders to nevertheless overcome these challenges and navigate multi-party settings with relative ease? 

One promising set of hypotheses centers on the group's *interaction structure*, the set of constraints placed on the group's shared communication channel. 
Many different aspects of interaction structure have been implicated in the effectiveness of dyadic communication, including the availability and quality of concurrent feedback [@krauss1966; @KraussBricker67_Delay; @kraut1982listener], the bandwidth of the communication modality [@KraussEtAl77;@dewhirst1971influence], and the group's access to a shared workspace [@clark2004speaking; @garrod2007foundations].
Yet larger group introduce qualitatively different dimensions of interaction structure, leading to a large but often inconsistent body of findings even for these well-understood factors [@swaab2012communication; @hiltz1986experiments].
While communication is generally expected to deteriorate as groups get larger [@macmillan_communication_2004; @seaman1997communication], several factors that may slow such deterioration have been identified in qualitative work, each of which relates to the structural "thickness" of the feedback channel [@ahern1994effect; @parisi2005evaluating]. 

In this paper, we develop an experimental paradigm for evaluating the relative contribution of these factors: a *multi-party repeated reference game.*
The ability to distinguish one particular entity from other possible entities, known as *reference*, is one of the most primitive and ubiquitous functions of communication.
Reference games [@Wittgenstein1953; @lewis1969convention] have been widely used to study dyadic communication under controlled conditions in the lab. 
They provide a clear metric of communicative effectiveness: how many words are required before a matcher successfully chooses a target image from a context of distractors? 
*Repeated* reference games, where the same target images appear multiple times in succession, were introduced to examine how interlocutors establish shared reference in the absence of conventional labels [@krauss1964; @clark1986].
At the beginning of the game, long and costly descriptions are typically required to succeed. 
A key finding, however, is that dyads become increasingly efficient over the course of interaction. 
Later utterances require fewer words, but also become more impenetrable to outsiders [@schober1989; @wilkes1992coordinating]. 

In principle, repeated reference games provide a strong operationalization of communicative effectiveness for the problem of multi-party communication: describers must simultaneously achieve shared reference with multiple matchers. 
However, empirically studying multi-party communication raises a number of difficulties in practice. 
A much larger pool of participants must be recruited to achieve sufficient power at the relevant unit of analysis -- the group -- spanning a very high-dimensional space of possible parameter settings [@almaatouq2022].
We address this problem by drawing on recent technical advances that have made it newly possible to achieve such samples using an interactive web-based platform [@haber2019;@hawkins2023partners]. 
Repeated reference games in online, chat-based paradigms have closely replicated earlier results from face-to-face studies [@hawkins2020], and arguably more closely resemble the interfaces used by modern teams who increasingly communicate through group text threads or popular platforms like Slack or Discord.

We use the multi-party repeated reference game to explore effects of group size and interaction channel thickness through a series of three experiments. **Taken together, our findings illuminate the mechanisms of social interaction in larger groups and suggest that larger groups may be a more sensitive environment for studying communication. TODO WHAT'S OUR CALIBRATED CLAIM OF IMPORTANCE??**


```{r diagram,  fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap="(A) Participants played a repeated reference game in groups of size 2 to 6. On each trial, describers described a target image to the matchers. Each image appeared once per block for six blocks. (B) Diagram of the experimental space. Experiments varied along 3 dimensions: Group size, group coherence, and matcher backchannel. (C) Schematic of the axes we manipulated. Experiment 1 (pink) varied group size from 2 to 6 players while holding group coherence and backchannel constant. Experiment 2 (blue) held group size constant at 6 and manipulated the other dimensions. Experiment 3 (green) tested 4 corners of the space, crossing group size (2 vs. 6 players) with the thickness of interaction structure (high vs. low coherence and backchannel)."}
knitr::include_graphics("expt-diagram3.pdf")
```

# Results

We recruited `r players` participants through Prolific, an online crowd-sourcing platform.
Participants were organized into `r games` groups of size two to six for a communication game (Figure \@ref(fig:behavioral)A).
On each trial, everyone in the group was shown a gallery of 12 tangram images [@clark1986; @hawkins2020; @ji2022abstract].
One player was designated the *describer* and the others were designated the *matchers*. 
The describer was asked to use a chat box interface to describe a privately indicated *target* image. 
After all matchers guessed which of the 12 images was the target, they received task feedback and proceeded to the next trial.
The game consisted of 72 trials structured into 6 repetition blocks, where each image appeared as the target exactly once per block.

We manipulated the interaction structure of this game across 11 distinct conditions in 3 distinct pre-registered experiments (Figure \@ref(fig:behavioral)B). 
We systematically sampled points along four dimensions parameterizing different aspects of the interaction space. 
We manipulated *group size* (ranging from two to six), *role stability* (whether or not participants took turns in the describer role), richness of *task feedback* (whether or not matchers were able to see each other's responses), and richness of the *matcher backchannel* (whether matchers were able to freely respond through a chatbox or could only use emojis; Figure \@ref(fig:behavioral)C).
Other factors, such as the set of stimuli and background knowledge about one's partners, were held constant across games. 

Experiment 1 investigated how performance scaled with group size.
Based on prior qualitative work, we predicted that larger groups face a more challenging coordination problem. 
We continuously varied the number of players from 2 to 6 while keeping other factors constant. 
For these conditions, the describer role rotated after each block, so that all players had at least one turn as describer.
Matchers had access to an unrestricted chat box, but only received binary task feedback about whether their individual selection was correct without revealing others' selections or the intended target. 

Experiment 2 explored the role of interaction structure purely within the most challenging 6-player groups. 
We manipulated two factors that we expected to increase group coherence and improve performance. 
First, we maintained the same describer throughout rather than a rotating describer, such that the same individual has the opportunity to aggregate feedback across trials and track which matchers are struggling which which targets. 
Second, we gave the group of matchers full feedback about what every other member of the group had selected, and we showed the intended target. 
We also manipulated a factor that we expected to interfere with the ability to establish mutual understanding and thus impede performance. 
In the limited backchannel condition, matchers were limited to four discrete emojis (green check, thinking face, red x, and laughing-crying face) that could convey simple valence and level of comprehension, but not any referential content.

Experiment 3 crossed the extremes of group size from experiment 1 (2 vs. 6 people) with the extremes of group interactions from Experiment 2 (*thick* vs. *thin* interaction structure). 
In the *thick* condition, we maintained a consistent describer, gave all matchers full task feedback, and allowed them to freely use a chat box. 
In the *thin* condition, we forced the describer to rotate on each block, restricted feedback to their own binary correctness, and restricted the backchannel to the four emojis.
Note that the 2-player thick game most closely resembles the design of classic repeated reference games [@clark1986; @hawkins2020].

```{r behavioral, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=7.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Behavioral results across all three experiments. (A-C). Matcher accuracy at selecting the target image. (D-F). Number of words produced by the describer each trial. For all, small dots are per game, per block means, and smooth lines are predictions from model fixed effects with 95\\% credible intervals. Y-axes are truncated, and a few outliers points are not visible. **(TODO check ordering of legends!)**"}
# accuracy

acc_pred_1 <- read_rds(here("code/paper_mods/prediction/acc_pred_1.rds"))
acc_pred_2 <- read_rds(here("code/paper_mods/prediction/acc_pred_2.rds"))
acc_pred_3 <- read_rds(here("code/paper_mods/prediction/acc_pred_3.rds"))
# 1
one_acc_dat <- combined_results |> 
  filter(condition=="rotate") |> 
  group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(numPlayers=as.character(numPlayers))

one_acc_plot <- ggplot(one_acc_dat, aes(x=repNum+1, y=correct.num, color=numPlayers))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.6,1.05))+
  geom_point(data=one_acc_dat |> group_by(repNum, gameId, numPlayers) |> summarize(correct.num=mean(correct.num)),position = position_dodge(width=.4), alpha=.3)+
      #geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  geom_lineribbon(data=acc_pred_1, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(numPlayers,after_scale=alpha(fill,.2))))+
    labs(x="Block", y="Fraction correctly selected", color="", title="Experiment 1")+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
    annotate("text", x=1,y=1.05,label="A", size=6, fontface="bold")+
    theme(legend.position="none",
          axis.text=element_text(size=12),
          legend.text=element_text(size=13),
          axis.title=element_text(size=14),
          plot.title=element_text(size=16, hjust=.5))+
    scale_color_manual(values=color_scheme_1, aesthetics=c("color", "fill"))

two_acc_dat <- combined_results |>
  filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  group_by(playerId,repNum, gameId, numPlayers) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |> 
  mutate(condition=case_when(
    condition=="no_rotate" ~ "6 same describer",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin"),
    condition=factor(condition, levels=c("6 full feedback", "6 same describer", "6 thin"))
  )

two_acc_plot <- ggplot(two_acc_dat, aes(x=repNum+1, y=correct.num, color=condition))+
    scale_x_continuous(breaks=seq(1,6))+
    coord_cartesian(ylim=c(.6,1.05))+
  geom_point(data=two_acc_dat |> group_by(repNum, gameId, condition) |> summarize(correct.num=mean(correct.num)),position = position_dodge(width=.4), alpha=.3)+
    #geom_smooth(method = "glm", method.args = list(family = "binomial")) +
   geom_lineribbon(data=acc_pred_2, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
    labs(x="", y="", color="", title="Experiment 2")+
    annotate("text", x=1,y=1.05,label="B", size=6, fontface="bold")+     
    annotate("text", x=3.5,y=1.05,label="Accuracy", size=6)+
    theme(legend.position="none",
          axis.text=element_text(size=12),
          legend.text=element_text(size=14),
          axis.title=element_text(size=14),
          plot.title=element_text(size=16, hjust=.5),
          axis.title.y=element_blank())+ 
    guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
    scale_color_manual(values=color_scheme_2, aesthetics=c("color", "fill"))

#3
three_acc_dat <- combined_results |> 
  filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> 
  group_by(playerId,repNum, gameId, condition) |> 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) |>
  mutate(condition=str_replace(condition, "_", " "),
         condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin"))) 
three_acc_plot <-  ggplot(three_acc_dat, aes(x=repNum+1, y=correct.num, color=condition))+
    scale_x_continuous(breaks=seq(1,6))+
    coord_cartesian(ylim=c(.6,1.05))+
      geom_point(data=three_acc_dat |> group_by(repNum, gameId, condition) |> summarize(correct.num=mean(correct.num)),position = position_dodge(width=.4), alpha=.3)+
    #geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
     geom_lineribbon(data=acc_pred_3, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
    annotate("text", x=1,y=1.05,label="C", size=6, fontface="bold")+
    labs(x="", y="", color="", title="Experiment 3")+
    theme(legend.position="none",
          axis.text=element_text(size=12),
          legend.text=element_text(size=14),
          plot.title=element_text(size=16, hjust=.5),
          axis.title=element_text(size=14),
          axis.title.y=element_blank())+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.1) ) )+
    scale_color_manual(values=color_scheme_3, aesthetics = c("color", "fill"))
 
acc <- plot_grid(one_acc_plot, two_acc_plot, three_acc_plot, nrow=1, rel_widths = c(1.05, 1, 1))
 

red_pred_1 <- read_rds(here("code/paper_mods/prediction/red_pred_1.rds"))
red_pred_2 <- read_rds(here("code/paper_mods/prediction/red_pred_2.rds"))
red_pred_3 <- read_rds(here("code/paper_mods/prediction/red_pred_3.rds"))
#1
one_red_dat <- combined_chat |> 
  filter(condition=="rotate") |>  
  filter(role=="speaker") |> 
  mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, numPlayers) |> 
  summarize(words=sum(total_num_words)) |>
  mutate(numPlayers=as.character(numPlayers))

one_red_plot <-  ggplot(one_red_dat, aes(x=repNum+1, y=words, color=numPlayers))+
      geom_point(data=one_red_dat |> group_by(repNum, gameId, numPlayers) |> summarize(words=mean(words)),position = position_dodge(width=.4), alpha=.3)+
    #geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
   geom_lineribbon(data=red_pred_1, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(numPlayers,after_scale=alpha(fill,.2))))+
    coord_cartesian(ylim=c(0,45))+
    scale_x_continuous(breaks=seq(1,6))+
    labs( y="Number of words", x="Block", color="")+
    guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5)), fill=FALSE  )+
    annotate("text", x=1,y=45,label="D", size=6, fontface="bold")+
    theme(legend.position="bottom",
          axis.text=element_text(size=12),
          legend.text=element_text(size=13),
          axis.title=element_text(size=14),
          axis.title.x=element_blank())+
    scale_color_manual(values=color_scheme_1, aesthetics=c("color","fill"))


#2

two_red_dat <- combined_chat|> 
  filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
  filter(numPlayers==6) |> 
  filter(role=="speaker") |> 
  mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram,condition) |> 
  summarize(words=sum(total_num_words)) |> 
  mutate(condition=case_when(
    condition=="no_rotate" ~ "6 same describer",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin"),
    condition=factor(condition, levels=c("6 full feedback", "6 same describer", "6 thin"))
  )

two_red_plot <- ggplot(two_red_dat,aes(x=repNum+1, y=words, color=condition))+
    #geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5)), fill=FALSE  )+
 geom_point(data=two_red_dat |> group_by(repNum, gameId, condition) |> summarize(words=mean(words)),position = position_dodge(width=.4), alpha=.5)+
    #geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
   geom_lineribbon(data=red_pred_2, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
    coord_cartesian(ylim=c(0,45))+
    scale_x_continuous(breaks=seq(1,6))+
    labs(x="", y="", color="")+
    annotate("text", x=1,y=45,label="E", size=6, fontface="bold")+
    annotate("text", x=3.5,y=45,label="Words from describer", size=6)+
    theme(legend.position="bottom",
          axis.text=element_text(size=12),
          legend.text=element_text(size=13),
          axis.title=element_blank())+
    scale_color_manual(values=color_scheme_2, aesthetics=c("color", "fill"))

#3
three_red_dat <- combined_chat |> 
  filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |> 
  filter(role=="speaker") |> 
  mutate(groupxtangram=str_c(gameId,tangram)) |> 
  group_by(repNum, gameId,tangram, groupxtangram, condition) |> 
  summarize(words=sum(total_num_words)) |> 
  mutate(condition=str_replace(condition, "_", " "),
         condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin")))


three_red_plot <-  ggplot(three_red_dat, aes(x=repNum+1, y=words, color=condition))+
     geom_point(data=three_red_dat |> group_by(repNum, gameId, condition) |> summarize(words=mean(words)),position = position_dodge(width=.4), alpha=.3)+
    #geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
   geom_lineribbon(data=red_pred_3, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
    guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5)), fill=FALSE )+
    coord_cartesian(ylim=c(0,45))+
    scale_x_continuous(breaks=seq(1,6))+
    labs(x="", y="", color="")+
    annotate("text", x=1,y=45,label="F", size=6, fontface="bold")+
    theme(legend.position="bottom",
          axis.text=element_text(size=12),
          legend.text=element_text(size=13),
          axis.title=element_blank())+
    scale_color_manual(values=color_scheme_3, aesthetics=c("color", "fill"))

red <- plot_grid(one_red_plot,two_red_plot, three_red_plot, nrow=1, rel_widths = c(1.05,1,1))
plot_grid(acc, red, nrow=2, rel_heights = c(.95,1))
```

```{r}
acc_1 <- read_rds(here(msum_loc,"acc_1.rds"))

acc_2a <- read_rds(here(msum_loc,"acc_2a.rds"))

acc_2b <- read_rds(here(msum_loc,"acc_2b.rds"))

acc_2c <- read_rds(here(msum_loc,"acc_2c.rds"))

acc_3 <- read_rds(here(msum_loc,"acc_3.rds"))
```

## Group Performance
We first examined how accurately and efficiently groups were able to match images, before moving on to examine how describer's descriptions vary over time and condition. 

We characterize group performance along two complementary metrics: (1) matcher accuracy and (2) describer efficiency. 
Matcher accuracy is given by the percent of matchers on each trial who successfully selected the target referent. 
Describer efficiency is given by the number of words produced by the describer to achieve that degree of matcher accuracy in the group.
The degree to which describers are able to communicate more efficiently without negatively impacting matcher accuracy is indicative of convergence on a more effective shared communication protocol within the group.

### Smaller and higher coherence groups tend to be more accurate.

We begin by examining the impact of interaction structure on referential success, the ability to correctly transmit the intended target to all matchers.

To test these effects, we constructed a series of 5 logistic mixed-effects regression models predicting accuracy as a function of condition and repetition block (separate models were run for experiment 1, each condition in experiment 2, and experiment 3).

Across all conditions, we observed strong positive effects of repetition block, indicating improved performance over time (Figure \@ref(fig:behavioral)A-C, SI Tables 2-6).

Group size and differences in interaction structure contributed to variation in group performance. Larger games had lower initial accuracy (`r stats(acc_3,6)`) and improved more slowly (`r stats(acc_3,6)`) than smaller games in Experiment 3, although group size differences were not reliable in Experiment 1 (SI Table 2). Among large groups in experiment 2, accuracy was higher in the thicker conditions  than in the condition with thin interaction structure (SI Tables 3-5); however, in experiment 3, no effects of game thickness were reliable (SI Table 6). 

Regardless of group size and interaction structure, groups were far above chance and improved over the course of the game. We also observed numerical effects such that smaller groups and groups with higher coherence tended to be more accurate, though the magnitude and reliability of these effects varied across experiments.
 

```{r}
red_1 <- read_rds(here(msum_loc, "red_1.rds"))

red_2a <- read_rds(here(msum_loc,"red_2a.rds"))

red_2b <- read_rds(here(msum_loc,"red_2b.rds"))

red_2c <- read_rds(here(msum_loc,"red_2c.rds"))

red_3 <- read_rds(here(msum_loc, "red_3.rds"))

red_3_extra <- read_rds(here(msum_loc, "red_3_extra")) %>% select(diff6, thin2, thin6, thick6)

diff6 <- str_c("$\\beta=", round(red_3_extra[2,1],2),",\\:95\\%\\:\\mathrm{CrI}=[",round(red_3_extra[1,1],2),", ",round(red_3_extra[3,1],1), "]$")

thin2 <- str_c("$\\beta=", round(red_3_extra[2,2],2),", (95\\%\\:\\mathrm{CrI}=[",round(red_3_extra[1,2],2),", ",round(red_3_extra[3,2],1), "]$)")

thin6 <- str_c("$\\beta=", round(red_3_extra[2,3],2),", (95\\%\\:\\mathrm{CrI}=[",round(red_3_extra[1,3],2),", ",round(red_3_extra[3,3],1), "]$)")

thick6 <- str_c("$\\beta=", round(red_3_extra[2,4],2),", (95\\%\\:\\mathrm{CrI}=[",round(red_3_extra[1,4],2),", ",round(red_3_extra[3,4],1), "]$)")
```

### Larger groups require more information.

After establishing that groups were able to communicate the targets successfully, we turned to the challenges faced by describers when deciding how much information to provide.
Specifically, we predicted that larger and more heterogeneous groups may initially require more information, but that thicker interaction structure may similarly allow describers to communicate more effectively over time.
We tested these predictions using linear mixed-effects models predicting the number of words a describer produced on each trial as a function of condition and block. These models counted all words the describer produced, including after matcher contributions (for similar models predicting the length of describer's utterances before any matcher contributions, see SI Tables 15-18).

First, as predicted, describers in larger groups used longer descriptions at the outset than describers in smaller groups (Figure \@ref(fig:behavioral)D-F). This effect held for the continuous measure of group size for Experiment 1 (`r stats(red_1,4)`) and the 2-person versus 6-person groups in Experiment 3 (`r stats(red_3,7)`).

Samller groups tend to continue to use shorter descriptions than larger groups over the course of the game. In experiment 1, the rate of reduction was similar across different size groups (`r stats(red_1,2)`). In Experiment 3, larger groups reduced faster than smaller ones (`r stats(red_3, 4)`), but the faster reduction did not fully make up for the longer initial starting point. 

Interaction structure did not show a consistent effect on utterance length. While thin 6 player games showed a flatter reduction trajectory than thicker 6 player games in Experiment 2 (SI Tables 8-10), there was not a reliable effect of game thickness on reduction in Experiment 3 for either smaller or larger groups (SI Table 11). 

Overall, describers on average decreased their descriptions by a few words each repetition block. Smaller games use shorter descriptions than larger games across various time points in the experiment, and thinner games have numerically shallower slopes of reduction than thicker games. 


```{r}
list_1 <- read_rds(here(msum_loc, "list_1.rds"))
list_spec_1 <- read_rds(here(mform_loc, "list_1.rds"))

anylist_1 <- read_rds(here(msum_loc, "anylist_1.rds"))
anylist_spec_1 <- read_rds(here(mform_loc, "anylist_1.rds"))
```

### Larger groups use more backchannels

As a final measure of group performance, we examine the back-and-forth interactions between the describer and the group of matchers.
The backchannel allows matchers to actively provide feedback and seek clarification about the describer's referring expressions. An example transcript from a game where matchers contributed in various ways is in Table \@ref(tab:listener-example).
Overall, larger groups displayed a higher proportion of trials where at least one matcher produced utterances (Supplement Figure 2A, `r stats(anylist_1, 4)`), which declined across blocks (`r stats(anylist_1, 1)`). Over time, the length of matcher interjections decreases (Supplement Figure 2B, `r stats(list_1,1)`). This pattern is consistent with early matcher involvement in establishing a common conceptualization by asking questions and offering alternative descriptions. 
We found that emoji use in Experiment 3 followed similar trends (Supplement Figure 3).
The amount of text produced by matchers is much less than that produced by describers, but matchers contributions also reduce over time, in both frequency and length. 

```{r listener-example}

listener_sample <- pre_chat_1 |> filter(gameId=="k4otZKu35xehtF93F", target=="/experiment/tangram_C.png") |> 
  filter(!is.chitchat)|> select(playerId, repNum, text, target, role
                                ) |> mutate(person=factor(playerId, labels=c("A","B","C","D","E","F"))) |> select(-playerId) |> 
  mutate(person_name=str_c(person,ifelse(role=="speaker"," (describer)","")),
         repNum=repNum+1) |> 
  select(Person=person_name, Utterance=text)

knitr::kable(listener_sample, col.names=NULL, caption = "Example transcript of a 6-player group for Experiment 1 describing the same image each repetition. Matchers sometimes asked questions or offered clarifications, including in reference to prior descriptions.",  format="latex", booktabs=TRUE, linesep="") %>%
kable_styling(full_width = T) %>%
  column_spec(1,width="8em") |> 
column_spec(2, width = "28em") %>% kable_styling(latex_options="H") |> 
  pack_rows("Block 1", 1,8) |> 
  pack_rows("Block 2", 9,15) |> 
  pack_rows("Block 3", 16, 20) |> 
  pack_rows("Block 4",21,22) |> 
  pack_rows("Block 5", 23, 23) |> 
  pack_rows("Block 6", 24,24)
```
### Interim summary 

As an initial check on group performance, we examined three metrics of communicative performance in groups of different sizes and interaction structures. Groups in all conditions were able to communicate about the target images with a high and increasing degree of accuracy even as describers and matchers both decreased the length of their descriptions over time. Smaller groups and groups with thicker interaction structures tended to perform better, although some of the comparisons were not reliably different from one another. 

## Linguistic Content

```{r sbert-diagram, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Example utterances describing the shown tangram figure produced by two 3-player games in Experiment 1. To measure convergence within a game (blue), we measured the cosine similarity between SBERT embeddings of descriptions and the embedding of the round 6 utterance (taken to be the convention). Higher cosine similarity indicates more similar meaning. To measure divergence between games (green), we measured the similarity between embeddings of utterances from the same round across games."}
knitr::include_graphics("sbert.pdf")
```

In the previous sections, we confirmed that groups across conditions followed the classic patterns of increasing accuracy and decreasing description length.  Here, we aim to better understand the mechanisms that allow describers to use shorter descriptions while matcher accuracy increases. 
In particular, we explore the hypothesis that interaction structure and group size affect performance by acting through a *convention formation* process [@clark1986]. 
Under a recent models of convention formation [@hawkins2023partners], groups are able to leverage their shared history to coordinate on stable expectations about how to refer to particular images.
This model makes specific predictions about how interaction structure affects the ability to coordinate, in terms of the available feedback.

First, due to heterogeneity in the group -- 6 individuals who may have diverging conceptualizations --- a rational describer should provide a strictly more detailed initial description to hedge against multiple possible misunderstandings, as we previously observed. 
Second, all groups should display the characteristic dynamics of conventions: *stability*, or convergence within group, and *arbitrariness*, or divergence to multiple equilibria across groups. 
Third, convergence should be faster when a single individual is consistently in the describer role and when matchers are able to freely respond in natural language, as describers are able to aggregate feedback about the effectiveness of their own utterances from block to block and also immediately correct specific misunderstandings within a given trial.

To assess the dynamics of describer descriptions, we examine the *semantic similarity* of descriptions within and across games.
We quantified description similarity by concatenating describer messages together within a trial and embedding this description into a high-dimensional vector space using SBERT. 
SBERT is a BERT-based sentence embedder designed to map semantically similar sentences to embeddings that are nearby in embedding space.
Semantically meaningful comparisons between sentences are made by taking pairwise cosine similarities between the embeddings [@reimers2019]. 

To measure stability, or convergence within groups, we compared utterances from blocks one through five to the final (block six) description for the same image from the same game. 
To measure arbitrariness, or divergence across groups, depending on group-specific history, we compared utterances produced by different describers for the same image in the corresponding blocks. 
Figure \@ref(fig:sbert-diagram) illustrates these two measures with example concatenated utterances and their within-game and between-game cosine similarities. 



```{r sbert, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=7.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Language similarity results measured with pairwise cosine similarity between embeddings of two utterances. (A-C). Convergence of descriptions within games as measured by similarity between an utterance from block 1-5 to the block 6 utterance in the same game for the same image. (D-F). Divergence of descriptions across games as measured by the similarity between two utterances produced for the same image by different groups in the same block. For all, small dots are per game, per block means, and smooth lines are predictions from model fixed effects with 95\\% credible intervals. Y-axes are truncated, and a few outliers points are not visible.**(TODO check ordering of legends!)**"}
#convergence

one_two_converge <- read_rds(here("code/models/one_two_converge.rds"))
three_converge <- read_rds(here("code/models/three_converge.rds"))
#1
one_conv_dat <- one_two_converge |> filter(condition %in% c("2", "3","4","5","6"))

conv_pred_1 <- read_rds(here("code/paper_mods/prediction/conv_pred_1.rds"))
conv_pred_2 <- read_rds(here("code/paper_mods/prediction/conv_pred_2.rds"))
conv_pred_3 <- read_rds(here("code/paper_mods/prediction/conv_pred_3.rds"))
one_conv_plot <- ggplot(one_conv_dat, aes(x=earlier+1,y=sim,color=condition))+
            geom_point(data=one_conv_dat |> group_by(earlier, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
 # geom_smooth(formula=y~poly(x,2))+
     geom_lineribbon(data=conv_pred_1, aes(x=earlier+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="", title="Experiment 1")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  annotate("text", x=1,y=1,label="A", size=6, fontface="bold")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        plot.title=element_text(hjust=.5, size=16),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1, aesthetics=c("color", "fill"))


#2

two_conv_dat <- one_two_converge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 same describer",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin"))


two_conv_plot <- ggplot(two_conv_dat, aes(x=earlier+1,y=sim,color=condition))+
      geom_point(data=two_conv_dat |> group_by(earlier, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  #geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
      geom_lineribbon(data=conv_pred_2, aes(x=earlier+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  #guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
 # labs(y="Cosine Similarity", x="Block", color="")+
    labs(x="", y="", color="", title="Experiment 2")+
    annotate("text", x=1,y=1,label="B", size=6, fontface="bold")+
annotate("text", x=3,y=1,label="Within game", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        plot.title=element_text(hjust=.5, size=16),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+    
  scale_color_manual(values=color_scheme_2, aesthetics=c("color", "fill"))



#3



three_conv_dat <- three_converge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1)))


three_conv_plot <- ggplot(three_conv_dat, aes(x=earlier+1,y=sim,color=condition))+
      geom_point(data=three_conv_dat |> group_by(earlier, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
       geom_lineribbon(data=conv_pred_3, aes(x=earlier+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
  #geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  annotate("text", x=1,y=1,label="C", size=6, fontface="bold")+
    labs(x="", y="", color="", title="Experiment 3")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14),
        plot.title=element_text(hjust=.5, size=16),
        axis.title.y = element_blank())+
  scale_color_manual(values=color_scheme_3, aesthetics=c("color", "fill"))

conv <- plot_grid(one_conv_plot, two_conv_plot, three_conv_plot, nrow=1, rel_widths = c(1.05, 1,1))

one_two_diverge <- read_rds(here("code/models/one_two_diverge.rds"))
three_diverge <- read_rds(here("code/models/three_diverge.rds"))
# divergence

div_pred_1 <- read_rds(here("code/paper_mods/prediction/div_pred_1.rds"))
div_pred_2 <- read_rds(here("code/paper_mods/prediction/div_pred_2.rds"))
div_pred_3 <- read_rds(here("code/paper_mods/prediction/div_pred_3.rds"))
#1
one_div_dat <-  one_two_diverge |> filter(condition %in% c("2", "3","4","5","6"))

one_div_plot <- ggplot(one_div_dat,aes(x=repNum+1,y=sim,color=condition))+
geom_point(data=one_div_dat |> group_by(repNum, tangram, condition) |>  
             summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  #geom_smooth(formula=y~poly(x,2))+
       geom_lineribbon(data=div_pred_1, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ), fill=F )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  #  labs(x="", y="", color="")+
  annotate("text", x=1,y=.7,label="D", size=6, fontface="bold")+
  theme(legend.position="bottom",
        axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1, aesthetics=c("color", "fill"))

#2

two_div_dat <-  one_two_diverge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 same describer",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin"),
     condition=factor(condition, levels=c("6 full feedback", "6 same describer", "6 thin")))
 
two_div_plot <- ggplot(two_div_dat, aes(x=repNum+1,y=sim,color=condition))+
        geom_point(data=two_div_dat |> group_by(repNum, tangram, condition) |>
                     summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  #geom_smooth(formula=y~poly(x,2))+
       geom_lineribbon(data=div_pred_2, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.1,.7))+
  labs(x="", y="", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ) , fill=F)+
    annotate("text", x=1,y=.7,label="E", size=6, fontface="bold")+
annotate("text", x=3.5,y=.7,label="Between games", size=6)+
  theme(legend.position="bottom",
                axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+
   scale_color_manual(values=color_scheme_2, aesthetics=c("color", "fill"))

#3
three_div_dat <-  three_diverge |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1)),                    condition=factor(condition, levels=c("2 thick", "6 thick", "2 thin", "6 thin")))

 three_div_plot <-  ggplot(three_div_dat, aes(x=repNum+1,y=sim,color=condition))+
      geom_point(data=three_div_dat |> group_by(repNum, tangram, condition) |>
                   summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
        geom_lineribbon(data=div_pred_3, aes(x=block+1,ymin=low, y=mean, ymax=high, fill=stage(condition,after_scale=alpha(fill,.2))))+
  #geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
    labs(x="", y="", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=5) ), fill=F )+
  annotate("text", x=1,y=.7,label="F", size=6, fontface="bold")+
  theme(legend.position="bottom",
                axis.title.x=element_blank(),
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.y=element_blank())+
scale_color_manual(values=color_scheme_3, aesthetics=c("color", "fill"))

div <- plot_grid(one_div_plot,two_div_plot,three_div_plot, nrow=1, rel_widths = c(1.05, 1, 1))

plot_grid(conv, div, nrow=2,  rel_heights = c(.95,1))
```





```{r}
tolast_1 <- read_rds(here(msum_loc, "tolast_1.rds"))

tonext_1 <- read_rds(here(msum_loc, "tonext_1.rds"))

tolast_2a <- read_rds(here(msum_loc, "tolast_2a.rds"))

tonext_2a <- read_rds(here(msum_loc, "tonext_2a.rds"))

tolast_2b <- read_rds(here(msum_loc, "tolast_2b.rds"))

tonext_2b <- read_rds(here(msum_loc, "tonext_2b.rds"))

tolast_2c <- read_rds(here(msum_loc, "tolast_2c.rds"))

tonext_2c <- read_rds(here(msum_loc, "tonext_2c.rds"))

tolast_3 <- read_rds(here(msum_loc, "tolast_3.rds"))

tonext_3 <- read_rds(here(msum_loc, "tonext_3.rds"))
```

### Descriptions converge within groups

Across conditions, describer descriptions increased in semantic similarity to the final description over repetition, indicating convergence toward a stable description; convergence was fastest in smaller and higher coherence groups (Figure \@ref(fig:sbert)A-C; SI Tables 19-23).

We modeled semantic convergence with a mixed effects linear regression model predicting the similarity between a block 1-5 utterance and the corresponding block 6 utterance as a function of the earlier block number and condition. 

Smaller groups reached more stable descriptions faster than larger games. In Experiment 1, initial similarity was invariant across group size (`r stats(tolast_1, 1,3)`), but smaller groups converged faster (Figure \@ref(fig:sbert)A, `r stats(tolast_1, 3,3)`). In experiment 3, 6-player thick games started off further from their eventual convention than 2-player thick games (`r stats(tolast_3, 7,3)`) but closed the gap over time (Figure \@ref(fig:sbert)C, `r stats(tolast_3, 6,3)`). 

Thicker games converged faster than thin games (Figure \@ref(fig:sbert)B-C). In experiment 3, small thin games started off slightly further from their convention than small thick games, and this gap widened over time (`r stats(tolast_3, 4,3)`).

The combination of thin interaction structure and larger group hindered convergence more than either factor individually. Beyond the generally slower convergence in thin games, 6-player thin games showed substantially slower convergence even compared to 2-player thin games (expt 3, `r stats(tolast_3, 5,3)`). 

Across games, convergence towards the last utterance was driven by cumulative increasing similarity between pairs of utterances in adjacent blocks (Supplement Figure 4D-F, SI Tables 34-38). In early rounds, descriptions could change substantially between rounds, but by later rounds, many descriptions had already reduced and solidified and varied little round to round. 

All conditions showed some convergence toward a conventional nickname for the picture, but the speed of convergence was affected both by group size and channel width. Overall, stable descriptions emerged earlier if the describer role was consistent, if the group was smaller, and if matchers could contribute via a text channel. 

```{r}
div_1 <- read_rds(here(msum_loc, "div_1.rds"))

div_2a <- read_rds(here(msum_loc, "div_2a.rds"))

div_2b <- read_rds(here(msum_loc, "div_2b.rds"))

div_2c <- read_rds(here(msum_loc, "div_2c.rds"))
div_3 <- read_rds(here(msum_loc, "div_3.rds"))
```


### Games diverges from one another faster with thicker channels

While groups may initially overlap in their descriptions, including details of shapes or body parts, their descriptions are predicted to become increasingly dissimilar as groups increasingly adapt to their shared history. 

We modeled semantic divergence using a mixed-effects linear regression model predicting the similarity between a pair of utterances for the same image as a function of the block number and condition. 

A decrease in the similarity between different groups descriptions occurred in every condition, indicating increasing arbitrariness and group-specificity of descriptions (Figure \@ref(fig:sbert)D-F, SI Tables 24-28).
However, different game sizes and interaction structures revealed very different strengths of divergence.

Smaller games used more group-specific language. In experiment 1, smaller games diverged more quickly than larger games in experiment 1 (`r stats(div_1,2,3)`). In experiment 3, 2-player thick games started off more dissimiliar than 6-player thick games, although 6-player games diverged faster and eventually approached the dissimilarity levels of 2-player thick games (SI Table 28). 

Thicker interaction structure was associated with stronger group-specific divergence. In experiment 3, 2-player thin games diverged more slowly than 2-player thick games (`r stats(div_3, 2,3)`). As with the convergence patterns, large games with thin interaction structures had the flattest trajectories, as thinness and largeness compounded.  6-player thin games diverged even less than 2-player thin games (Figure \@ref(fig:sbert)F, `r stats(div_3, 3,3)`), and in experiment 2, 6-player thin games barely diverged at all (Figure \@ref(fig:sbert)E, `r stats(div_2c,1,3)`). 

### Interim summary 

Smaller groups show higher within-group similarities and between-group differences, sometimes showing up in the initial round and sometimes developing as a change over time. The thicker the games the faster and stronger the divergence and convergence patterns. The combination of a large game and a thin communication channel hampers within-game convergence and between-game divergence much more than either game size or thinness independently, leading to little evidence of group adaptation or group specificity in 6-player thin games. 

# General Discussion

Communication often occurs in multi-party settings, but research on referential communication typically does not focus on such settings -- largely due to practical obstacles. 
Dyadic reference games have been used to measure informational efficiency, characterized by describer-matcher pairs creating conventional (stable but somewhat arbitrary) labels which are not shared by other groups. 
In the current work, we asked how this process of reference formation unfolds in larger groups and under varying interaction structures. 
Across 3 online experiments and 11 experimental conditions, we varied game features including group size, form of matcher backchannel, and degree of group coherence. 
All conditions replicated classic phenomena: increasing accuracy, reduction in describer utterances, semantic convergence within games, and differentiation of descriptions between groups. 
However, we also found that the interaction structure of a group substantially affects how rapidly groups develop partner-specific conventions. 
Small groups may be able to form conventions under limited feedback, but larger groups require thicker interaction structure. Multi-player groups thus reveal important factors for communication which are masked in purely dyadic settings.

<!-- ## Efficiency without semantic convergence  -->

Increasing efficiency has often been taken as an index of group-specific convention formation [@clark1986; @brennan1996; @yoon2014; @yoon2018]. 
In our work, however, we observe distinct patterns for measures of raw utterance length compared to the dynamics of semantic content. 
In Experiment 3, thin 6-person games showed much less group-specific divergence despite comparable accuracy and efficiency. **TODO is there a better word than "comparable" to mean "not that different" possibly rephrase so it's clear we aren't proving the null**
This gap raises the possibility that it is possible to become more efficient and accurate without converging on a unified group-specific label. 
Instead, they may be converging to a **TODO what does "multi-modal" mean here?** multi-modal solution based on group priors [@guilbeault2021]. 
Thus, we encourage measures of semantic content (and not just performance) when evaluating convention formation.

<!-- ## Limitations and future directions.  -->

Just within the general framework of iterated reference, there is a high dimensional feature space of possible experiments. We sampled only a few points along a few dimensions in the space that felt salient. In our experiment 3, we grouped some factors together in order to have more games in each condition: a fully factorial design would have been too expensive to power adequately. We instantiated a "thin" channel by limited matchers to 4 discrete utterances (emojis), but there are other ways to manipulate channel width for describers and matchers, such as rate limiting typing or adding time pressure. Future work could sample other points in the experimental space, including exploring other manipulations on channel thickness, the effects of different target images, or groups of people with real-life prior connections. 

We cannot make claims about causal mechanisms between how experimental set-ups such as group size resulted in different outcomes: for instance, there are many differences between being in a 2-person group versus a 6-person group that could lead to the different outcomes. In a dyad, producers can tailor their utterances to the one matcher, but in large groups, producers must balance the competing needs of different comprehenders [@schober1989;@tolins2016]. These effects likely vary by both the knowledge state of and communication channels available to the comprehenders [@fox-tree2013;@horton2002; @horton2005]. Further work digging into the language used and the interactions between participants might unearth plausible mechanisms for how differences in group size and interaction structure influence outcomes, and this in turn could then point towards future experimental conditions. 

<!-- ## Conclusion  -->

Communication occurs across a broad range of situations, varying on many dimensions, including group size, medium of interaction, and group structure. 
A narrow focus on dyads with rich communication channels can lead to theories that mispredict how interactions play out in multi-party groups with varying interaction structure. 
Sampling from a broader range of communicative situations is thus a critical part of better understanding human communication. 

# Methods

For all experiments, we used Empirica [@almaatouq2020] to create real-time multi-player iterated reference games. In each game, one of the players started as the describer who saw an array of tangrams with one highlighted and communicated which figure to click to the other players (matchers). After the describer had described each of the 12 images in turn, the process repeated with the same images over a total of 6 such blocks (72 trials). We recorded what participants said in the chat, as well as who selected what image and how long they took to make their selections. 

These experiments were designed sequentially and pre-registered individually.^[Experiment 1: https://osf.io/cn9f4 for the 2-4 player groups, and https://osf.io/rpz67 for the 5-6 player data run later. Experiment 2: same describer at  https://osf.io/f9xyd, full feedback at  https://osf.io/j5zbm, and thin at  https://osf.io/k5f4t. Experiment 3: https://osf.io/untzy] We followed the analysis plan for each, although accuracy models were not explicitly specified until experiment 3, and linguistic analyses were only verbally described starting with 2b.  Results from some pre-registered models are omitted from the main text for brevity but are shown in the Supplement.

## Participants

Participants were recruited using the Prolific platform, and all participants self-reported as fluent native English speakers on Prolific's demographic prescreen. Participants each took part in only one experiment. Experiment 1 took place between May and July 2021, experiment 2 between March and August 2022, and experiment 3 in October 2022. As games varied in length depending on the number of participants, we paid participants based on group size, with the goal of a \$10 hourly rate.  Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, \$10 for 4-player games, and \$11 for 5- and 6-player games. When one player had the describer role for the entirety of a 6-player game, they gained an additional \$2 bonus. Across all games, each participant could earn up to \$2.88 in performance bonuses. A total of 1319 people participated across the 3 experiments, for roughly 20 games in each condition in experiments 1 and 2 and 40 games per condition in experiment 3. A breakdown of number of games and participants in each condition is shown in SI Table 1. 

## Materials

We used the 12 tangram images used by @hawkins2020 and @clark1986. These images were displayed in a grid with order randomized for each participant (thus descriptions such as "top left" were ineffective as the image might be in a different place on the describer's and matchers' screens). The same images were used every block. 

## Procedure

The experimental procedure was very similar across the three experiments. We first describe the procedure used in experiment 1 and then describe the differences in later experiments. 

### Experiment 1
From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages explaining the game. Participants had to pass a quiz on the instructions to be able to play the game. They were then directed to a "waiting room" screen until their partner(s) were ready.

On each trial, the describer described the highlighted tangram image so that the matchers could identify and click it. All participants were free to use the chat box to communicate, but matchers could only click once the describer had sent a message. Once a matcher clicked, they could not change their selection. There was no signal to the describer or other matchers about who had already made a selection. 

Once all matchers had selected (or a 3-minute timer ran out), participants were given feedback. Matchers learned whether they had chosen correctly or not; matchers who were incorrect were not told the correct answer. The describer saw which tangram each matcher had selected, but matchers did not. Matchers got 4 points for each correct answer; the describer got points equal to the average of the matchers' points. These points were translated into performance bonuses at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the describer once. The same person was the describer for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were describers 3 times in 2-player games, twice in 3-player games, once or twice in 4 and 5-player games, and once in 6-player games. Rotating the describer was chosen in this first experiment to keep participants more equally engaged (the describer role is more work), and to provide a more robust test of our hyppotheses regarding efficiency and convention formation. 

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

### Experiment 2
Experiment 2 consisted of three different variations on Experiment 1, all conducted in 6-player games. Each of these conditions differed from the experiment 1 baseline in one way. The same describer condition differed only in that one person was designated the describer for the entire game, rather than having the describer role rotate. The full feedback condition differed from experiment 1 in that all participants were shown what each person had selected and what the right answer was; matchers still saw text saying whether they individually were right or wrong. This condition was similar to some dyadic work, such as @hawkins2020, where matchers were shown the right answer during feedback. For the thin condition, we altered the chatbox interface for matchers. Instead of a textbox, matchers had 4 buttons, each of which sent a different emoji to the chat. Matchers were given suggested meanings for the 4 emojis during instructions. They could send the emojis as often as desired, for instance, initially indicating confusion, and later indicating understanding. In addition, we added notifications that appeared in the chat box saying when a player had made a selection. 

### Experiment 3

The thin channel condition in experiment 3 was the same as the thin condition in experiment 2, above. The thick condition combined the two group coherency enhancing variations from experiment 2: one person was the designated describer throughout, and the feedback to participants included the right answer and what each player had selected. Across both conditions in experiment 3, notifications were sent to the chat to indicate when a participant had made a selection. 

## Data pre-processing and exclusions

Participants could use the chat box freely, which meant that the chat transcript contained some non-referential language. The first author skimmed the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about how well the task was going, and confirmations or denials ("ok", "got it", "yes", "no"). We excluded these utterances from our analyses. Note that chat lines sometimes included non-referential words in addition to words referring to the tangrams ("ok, so it looks like a zombie", "yes, the one with legs"); these lines were retained intact. 

In experiments 1 and 2, games did not start if there were not enough participants and ended if any participant disconnected. In experiment 3, games started after a waiting period even if they were not full and continued even after a participant disconnected (with describer role reassigned if necessary), unless the game dropped below 2 players. The distribution of players in these games that were initially recruited to be 6 player games is in SI Figure 1. The realities of online recruitment and disconnection meant that the number of games varied between conditions. We excluded incomplete blocks from analyses, but included complete blocks from partial games (See SI Table 1).

When skimming transcripts to tag non-referential utterances, we noticed that one game in the 6-player thick condition had a describer who did not give any sort of coherent descriptions, even with substantial matcher prompting. We excluded this game from analyses. 

## Modelling strategy

We fit all regression models in brms [@burkner2018] with weakly regularizing priors.
We were unable to fit the full pre-registered mixed effects structure in a reasonable amount of time for some models, so we included what hierarchical effects were reasonable. Models of accuracy had by-group random intercepts; models of reduction had full mixed effect structure; models of S-BERT similarities had random intercepts per game and image as applicable.   (All model results and priors and formulae are reported in the Supplement). 
Models of matcher accuracy were logistic models with normal(0,1) priors for both betas and sd. 
Models of describer efficiency were run as linear models with an intercept prior of normal(12,20), a beta prior of normal(0,10), an sd prior of normal(0,5) and a correlation prior of lkj(1). 
For all of the models of SBERT similarity, we used linear models with the priors normal(.5,.2) for intercept, normal(0,.1) for beta, and normal(0,.05) for sd. 

We also needed to decide how to handle dropout in Experiment 3, as some of the 6-player games did not retain all 6 players for the entire game. 
Our decision was to follow an intent-to-treat analysis and treat data as missing completely at random. 
We note that this choice will underestimate differences between 2-player and (genuine) 6-player games, by labeling some smaller groups as 6-player groups. 

We do not know what leads some participants to drop out, but it is possible that some factors may be random (ex. connection issues) and others may be correlated with performance (ex. frustration because group is struggling).   We don't know to what extent groups that start and continue at the full size may differ from games where some participants drop out. This is potentially an issue across all experiments; in experiments 1 and 2, groups stopped playing if anyone dropped out, and in experiment 3 they kept playing as a smaller group. The number of games in each condition and rates of dropoff are shown in SI Table 1 and SI Figure 1. 

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent


