---
title: TODO title
author:
  - name: Veronica Boyce
    email: vboyce@stanford.edu 
    affiliation:
      - Stanford 
    footnote:
      - corresp
  - name: Robert Hawkins
    affiliation: 
      - Stanford
  - name: Noah D. Goodman
    affiliation: 
      - Stanford
  - name: Michael C. Frank 
    affiliation: 
      - Stanford
address:
  - code: Stanford
    address: Stanford University 
footnote:
  - code: corresp
    text: "Corresponding author. Email: vboyce@stanford.edu"
bibliography: ["papers.bib"] # Replace with one or more of your own bibtex files. Better BibTeX for Zotero is your friend
csl: dmk-format.csl # Use any CSL style. See https://www.zotero.org/styles for a good list. Ignored if citation_package: natbib
link-citations: TRUE
output:
  bookdown::pdf_document2:
    toc: FALSE
    keep_tex: TRUE
    template: generic_article_template.tex
    #md_extensions: "-autolink_bare_uris"
    number_sections: TRUE
    citation_package: default # Can also be "natbib"
  bookdown::word_document2: 
    # Produces largely readable output, though some cross-referencing may fail. Useful for collaboration.
    toc: TRUE
lang: en # Main document language in BCP47 format
geometry: "margin=25mm"
papersize: a4
#linestretch: 2 # for double spacing
endfloat: FALSE # Set to TRUE to turn on latex endfloat package to place figures and tables at end of document
# endfloatoption: # See endfloat documentation for more possibilities
#   - tablesfirst # Default
#   - nomarkers # Default
numberlines: FALSE
authblk: TRUE # FALSE = author affiliations in footnotes; TRUE = author affiliations in a block below author names
footnotehyper: FALSE # TRUE will give you enhanced table footnote capabilities. Set to FALSE to be able to use French blocks. Needed due to what appears to be a latex bug.
urlcolor: blue
linkcolor: blue
citecolor: blue
graphics: TRUE # Needed to be able to include images
tables: TRUE # Needed to be able to include tables

---

<!---------------------- Abstract --------------------->

::: {.abstract data-latex="" lang=en}
*This is an abstract in italics.*

This is the second paragraph not in italics.
:::

<!-- Use class keywords to format keywords section -->
::: {.keywords data-latex="" lang=en}
One keyword; Yet another keyword
:::



<!------------ Main text -------------------->
 

```{r global_options, include=FALSE}
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())


knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.crop = F, out.width = "100%", dpi=300,
                      fig.pos = "tb", fig.path='figs/', fig.env="figure",
                      echo=F, warning=F, cache=TRUE, 
                      message=F, sanitize = T)
```


```{r set-up, include=F}

ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  %>% 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"




image_location="write-ups/images"

msum_loc="code/paper_mods/summary"
mform_loc="code/paper_mods/formulae"

source(here("code/prep_ms.R"))

show_summary <- function(model){
  intervals <- gather_draws(model, `b_.*`, regex=T) %>% mean_qi()
  
  stats <- gather_draws(model, `b_.*`, regex=T) %>% 
    mutate(above_0=ifelse(.value>0, 1,0)) %>% 
    group_by(.variable) %>% 
    summarize(pct_above_0=mean(above_0)) %>% 
   mutate(`P-value equivalent` = signif(2*pmin(pct_above_0,1-pct_above_0), digits=2)) %>% 
    left_join(intervals, by=".variable") %>% 
    mutate(lower=round(.lower, digits=2),
           upper=round(.upper, digits=2),
           `Credible Interval`=str_c("[",lower,", ", upper,"]"),
           Term=str_sub(.variable, 3, -1),
           Estimate=round(.value, digits=2)) %>% 
    select(Term, Estimate, `Credible Interval`, `P-value equivalent`)
  
  stats
}

stats <- function(model, row){
  str_c(model[row,1],": Est=", model[row,2], ", CrI=", model[row,3])
}

stats_text  <- function(model, row){
  str_c( model[row,2], " (CrI=", model[row,3],")")
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) %>% str_replace_all(" ","") %>% 
  str_replace_all("\\*"," $\\\\times$ ") %>% 
  str_replace_all("\\+", "&nbsp;+ ") %>% 
   str_replace_all("~", "$\\\\sim$ ")
}
```

# Introduction 

- communication is important and takes place in non-dyadic situations
- one interesting thing about comm is ad-hoc expressions, adaptation to speaker/ listener pairs

- prior work has focused a lot on dyads: what happens with more people? Do theories predict anything? 

- groups also vary in compositional type aspects so mimics of these might matter

- do we want to set up other theoretical frames? do I need to read more about theory??


Verbal communication is an integral part of our daily lives. We coordinate schedules with partners, socialize with friends over board games, learn and teach in seminar classes, and listen to podcasts. Communicative environments range in size from one-on-one dialogue to broadcast communication to large groups, but the goal of efficient communication is shared across these [@branigan2006;@ginzburg2005;@traum2004]. Shared referring expressions are a necessity for efficient communication; a thing or an idea needs some sort of name that the interlocutors will jointly understand. In many cases, there are widely shared conventionalized expressions for objects or ideas, but in other cases, spontaneous ad-hoc expressions must be invented. 

The formation of these new reference expressions is well-studied in dyadic contexts and has been a case study for efficient communication more broadly. But these dynamics may be different in larger groups, which are less studied. Our current work builds on the dyadic reference game tradition by extending it to larger groups.

<!-- ## Dyadic reference games -->

@clarkReferringCollaborativeProcess1986 established an experimental method for studying the emergence of new referring expressions that has now become standard [building on @kraussChangesReferencePhrases1964;@kraussConcurrentFeedbackConfirmation1966]. Two participants see the same set of tangram figures; the speaker describes each figure in turn so the listener can select the target from the set of figures. The speaker and listener repeat this process with the same images over a series of blocks. Early descriptions are long and make reference to multiple features in the figure, but in later iterations, shorthand conventional names for each figure emerge; this shortening of utterances is called 'reduction'. 

Recently, online participant recruitment and web-based experiments have made it possible to study this convergence in larger populations [@hawkinsCharacterizingDynamicsLearning2020;@haber2019]. In @hawkinsCharacterizingDynamicsLearning2020, 83 pairs completed a similar iterated reference experiment where they communicated via a chat box. Speakers reduced their utterances, producing fewer words per image in later blocks than in earlier blocks, in line with results from face-to-face, oral paradigms.^[We use "speaker" and "listener" to refer to the roles describing and selecting targets, regardless of communication modality.]
<!-- ## Multi-party communication -->

How does this process proceed in multi-party communication? In a dyad, speakers can tailor their utterances to the one listener, but in large groups, speakers must balance the competing needs of different listeners [@schober1989;@tolins2016]. These effects likely vary by both the knowledge state of and communication channels available to the listeners [@fox-tree2013;@horton2002; @horton2005]. Prior work has focused on manipulating knowledge states by adding new listeners to established groups.




```{r interface, fig.env = "figure*", fig.pos = "t!", fig.width=6, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "All participants saw all 12 tangram images. (A) Speaker's view during selection phase. (B) During the feedback stage, speakers saw what figure each person chose, but listeners only learned if their selection was correct or incorrect. Listeners were not shown what other listeners chose. \\label{game}", cache=FALSE}

img <- png::readPNG(here(image_location, "merged_fig2.png"))
grid::grid.raster(img)
```

In this context, one approach for speakers is to 'aim low' and produce utterances tailored to the least knowledgeable listener [@yoonAimLowMechanisms2018a]. For instance, in @yoonAdjustingConceptualPacts2014, speakers developed conventions with one listener but then used longer descriptions with a new listener. Another strategy for speakers is to integrate across listeners and balance efficiency with informativeness by 'aiming in the middle'. In @yoonAudienceDesignMultiparty2019, speakers communicating to a mixed group of 3 experienced listeners and 1 naive listener used shorter utterances and made fewer accommodations than they did in groups with a greater fraction of naive listeners. Both of these strategies predict that larger groups will be slower to converge than smaller groups.

Disagreements about how to conceptualize referents can also slow groups down. In @weberCulturalConflictMerger2003, pairs of participants played a reference game with the same image sets before a listener switched groups and joined a different pair, making a group of three. The addition of the new listener slowed both listeners down for multiple rounds. When a listener switched groups, they brought preconceptions about how the pictures should be described which conflicted with how the speaker was used to describing the images. This result predicts that, with more perspectives in play, larger groups may have more difficulty agreeing on common conceptualizations.

In general, listeners expect speakers to maintain conventions and stick to descriptions that were similar to successful descriptions. However, listeners were not surprised to hear different descriptions of a familiar object if it came from a new speaker who had just entered the room [@metzingWhenConceptualPacts2003]. It's unclear what this finding predicts about new speakers who are present as fellow listeners during prior blocks -- will listeners expect them to maintain conventions? 



```{r count, include=F}
# TODO counts for all games
# For abstract (and elsewhere) count things!

games <- combined_results %>% select(gameId) %>% unique() %>% nrow() # 98

players <- combined_results %>% select(gameId, numPlayers) %>% unique() %>% summarize(players=sum(numPlayers)) # 390

words <- combined_chat %>% ungroup() %>% select(total_num_words) %>% summarize(words=sum(total_num_words)) #116000

```


# Experiment 1

For a first experiment, we extend the dyadic repeated reference game paradigm of @hawkinsCharacterizingDynamicsLearning2020 to games for 2--6 players who rotate between speaker and listener roles. This paradigm allowed us to test how the findings from dyadic interated reference games extend to larger groups and were influenced by group size. Additionally, to more closely examine how conventionalized names develop within groups and differ between groups, we used sentence embeddings to quantify the similarities of descriptions within and between groups over time.

## Methods

Building on the methods of @hawkinsCharacterizingDynamicsLearning2020, we used Empirica [@almaatouqEmpiricaVirtualLab2020] to create real-time multi-player reference games. In each game, one of the players started as the speaker who saw an array of tangrams with one highlighted (Figure \ref{game}A) and communicated which figure to click to the other players (listeners). After the speaker had identified each of the 12 images in turn, the speaker role rotated to another player and the process repeated with the same images. In total, there were 6 blocks, giving each player at least one chance to be the speaker.   We recorded what participants said in the chat, as well as who selected what image and how long they took to make their selections. <!--^[Code to run the experiment, as well as data and analysis code are available at https://osf.io/qdvbr/?view_only=47aebfde243f405e9c42a45cacb697d2.] We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study.^[Our preregistrations are at https://osf.io/cn9f4/?view_only=7fdacd698b24465cb1a8699050af5bfc and  https://osf.io/rpz67?view_only=5284203e2b644fc5ac39cf3e723b9a7e.]-->

### Participants

We recruited participants between May and July 2021 using the Prolific platform; participants had all self-reported as fluent native English speakers on Prolific's demographic prescreen. Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, \$10 for 4-player games, and \$11 for 5- and 6-player games (with the intention of a \$10 hourly rate), in addition to up to \$2.88 in performance bonuses. A total of 390 people each participated in one game. 

### Materials

We used the 12 tangram images used by @hawkinsCharacterizingDynamicsLearning2020 and @clarkReferringCollaborativeProcess1986 (see Figure \ref{game}). These images were displayed in a grid with order randomized for each participant (thus descriptions such as "top left" were ineffective as the image might be in a different place on the speaker's and listeners' screens). The same images were used every block. 

### Procedure

```{r overview}

overview <- tribble(
  ~"Experiment", ~"Game size", ~"Speaker",~"Feedback", ~"Listener chat", ~"Continue games",
  "1", "2,3,4,5,6", "rotating", "self only", "text", "no",
  "2a", "6", "one speaker", "self only", "text", "no",
  "2b", "6", "rotating", "self, others, & correct", "text", "no",
  "2c", "6", "rotating", "self only", "four emojis", "no",
  "3 thin", "2,6", "rotating", "self only", "four emojis", "yes",
  "3 thick", "2,6", "one speaker", "self, others, & correct", "text", "yes"
)
knitr::kable(overview, caption="Summary of differences in experiments. Game size refers to the number of players per game. Speaker refers to whether there was one speaker the whole game or whether the speaker role rotated every block. Feedback is whether listeners saw only whether they were right or wrong or whether the additionally saw what other listeners had selected and what the correct answer was. Listener chat refers to whethers listeners could type freely in the chat or only communicate by pressing buttons to send four emojis to the chat. Continue games refers to whether games could continue (or start) with fewer than the requisite number of players; this was not intended to be a consequential manipulation, but was done to prevent games from ending if one player dropped out (an issue that was causing data loss in 6 player games). ")
```
```{r participants}
summary <- combined_results %>% group_by(condition, trialNum, repNum, gameId, numPlayers) %>% 
  mutate(numPlayers=ifelse(condition %in% c("6_thin", "6_thick"), "6*", as.character(numPlayers))) |> 
  group_by(gameId, numPlayers, condition) %>% 
  summarize(num_trials=max(trialNum)) %>% 
  arrange(numPlayers) %>% 
  mutate(complete=ifelse(num_trials==71,T,F)) %>% 
  group_by(numPlayers,complete, condition) %>% 
  tally() %>% 
  pivot_wider(names_from=complete, values_from=n) %>% 
  rename(Players=numPlayers,Complete=`TRUE`, Partial=`FALSE`) %>% 
  mutate(Partial=ifelse(is.na(Partial), 0, Partial)) |> 
  mutate(Experiment=factor(condition, levels=c("rotate","no_rotate","full_feedback", "emoji", "2_thin", "6_thin", "2_thick", "6_thick"),
                          labels=c("1", "2a", "2b", "2c", "3: thin", "3: thin", "3: thick", "3: thick"))) |> 
  select(Experiment, Players, Complete, Partial) |> 
  arrange(Experiment, Players,Complete,Partial)

knitr::kable(summary, caption="The number of games in each experiment and condition. Complete games finished all 6 blocks; partial games ended early due to disconnections, but contributed at least one complete block of data. 6* indicates that some games started with fewer than 6 players or continued with fewer than 6 players after participants disconnected.")
```

We implemented the experiment using Empirica, a Javascript-based platform for running real-time interactive experiments online [@almaatouqEmpiricaVirtualLab2020].  From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages explaining the game. Participants had to pass a quiz to be able to play the game. They were then directed to a "waiting room" screen until their partners were ready.

Once the game started, participants saw screens like Figure \ref{game}A. Each trial, the speaker described the highlighted tangram image so that the listeners could identify and click it. All participants were free to use the chat box to communicate, but listeners could only click once the speaker had sent a message. Once a listener clicked, they could not change their selection. There was no signal to the speaker or other listeners about who had already made a selection. 

Once all listeners had selected (or a 3-minute timer ran out), participants were given feedback (Figure \ref{game}B). Listeners learned whether they individually had chosen correctly or not; listeners who were incorrect were not told the correct answer. The speaker saw which tangram each listener had selected, but listeners did not. This feedback regime is different from @hawkinsCharacterizingDynamicsLearning2020 where listeners were shown what the right answer was during feedback. We made this change to prevent listeners from learning conventions purely as a memorized mapping between utterance and correct answer. 

Listeners got 4 points for each correct answer; the speaker got points equal to the average of the listeners' points. These points translated into performance bonus at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the speaker once. The same person was the speaker for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were speakers 3 times in 2-player games, twice in 3-player games, once or twice in 4 and 5-player games, and once in 6-player games. Rotating the speaker was chosen to keep participants more equally engaged (the speaker role is more work), and to give a more robust test for reduction and convention. 

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

### Data pre-processing and exclusions

Participants could use the chat box freely, which meant that the chat transcript contained some non-referential language. The first author skimmed through the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about how well or fast the task was going, and confirmations or denials ("ok", "got it", "yes", "no"). We exclude these utterances from our analyses. Note that chat lines sometimes included non-referential words in addition to words referring to the tangrams ("ok, so it looks like a zombie", "yes, the one with legs"); these lines were retained intact. 

Our intended sample size was 20 complete games in each group size, but we ended up with fewer due to games not filling or participants disconnecting early (Table \ref{parts}).  We excluded incomplete blocks from analyses, but included complete blocks from partial games.

### Modelling strategy

All models were run in brms CITE with weakly regularizing priors DESCRIBE

Pre-regs:
1: https://osf.io/cn9f4 for the 2-4 player groups, and https://osf.io/rpz67 for the 5-6 player data run later
2a: https://osf.io/f9xyd
2b: https://osf.io/j5zbm
2c: https://osf.io/k5f4t
3: https://osf.io/untzy


## Results




### Accuracy

Our first question was whether accuracy and speed increased across groups of different sizes.


```{r}
acc_1 <- read_rds(here(msum_loc,"acc_1.rds"))
acc_spec_1 <- read_rds(here(mform_loc,"acc_1.rds"))
```


Most individuals were accurate in their selections, with accuracy rising across blocks (Figure \ref{accuracy}).  In a logistic model of accuracy (`r form(acc_spec_1)`), participants are more accurate in later blocks (`r stats(acc_1,1)`), and there was no strong effect of group size on accuracy (`r stats(acc_1,4)`) or interaction between block and group size (`r stats(acc_1,2)`). 



TODO consider adding comments about speed


```{r triptych-acc, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO", cache=FALSE}
# accuracy

# 1
one <- combined_results |> filter(condition=="rotate") %>% group_by(playerId,repNum, gameId, numPlayers) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  ggplot(aes(x=repNum+1, y=correct.num, color=as.character(numPlayers)))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )+
  theme(legend.position="bottom",
        text=element_text(size=16))+
        scale_color_viridis(discrete=T, direction=-1)

#2

palette = c("no_rotate"="orange", "full_feedback"="pink", "emoji"="red")
two <- combined_results |> filter(condition %in% c("no_rotate","full_feedback", "emoji")) %>%
  filter(numPlayers==6) |> 
  group_by(playerId,repNum, gameId, numPlayers) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
     coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  theme(legend.position="bottom",
        text=element_text(size=16))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )+
        scale_color_manual(values=palette)

#3
 three <- combined_results |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) %>% group_by(playerId,repNum, gameId, condition) %>% 
  filter(response!="false") |> 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  ggplot(aes(x=repNum+1, y=correct.num, color=condition))+
     scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.65,1))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  labs(x="Block", y="Fraction correctly selected", color="")+
  theme(legend.position="bottom",
        
        text=element_text(size=16))+
        scale_color_brewer(palette="Paired", direction=-1)+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1) ) )
 
 plot_grid(one, two, three, nrow=1)
```

### Reduction

```{r triptych-red, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO", cache=FALSE}

#1

one <- combined_chat |> filter(condition=="rotate") |>  filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram, numPlayers) %>% 
  summarize(words=sum(total_num_words)) |> 
  #group_by(repNum, name, gameId) |> 
  #summarize(words=sum(words)) |> 
ggplot(aes(x=repNum+1, y=words, color=as.character(numPlayers)))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  theme(legend.position="bottom",
        text=element_text(size=16))+
  scale_color_viridis(discrete=T, direction=-1)

#2

palette = c("no_rotate"="orange", "full_feedback"="pink", "emoji"="red")
two <- combined_chat|> filter(condition %in% c("no_rotate","full_feedback", "emoji")) %>%
  filter(numPlayers==6) |> 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram,condition) %>% 
  summarize(words=sum(total_num_words)) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  scale_color_manual(values=palette)+
  guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=16))

#3


three <- combined_chat |> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) %>% filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, gameId,tangram, groupxtangram, condition) %>% 
  summarize(words=sum(total_num_words)) |> 
  #group_by(repNum, name, gameId) |> 
  #summarize(words=sum(words)) |> 
ggplot(aes(x=repNum+1, y=words, color=condition))+
   scale_color_brewer(palette="Paired", direction=-1)+
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  coord_cartesian(ylim=c(0,60))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=16))
plot_grid(one,two, three, nrow=1)
```



```{r}
red_1 <- read_rds(here(msum_loc, "red_1.rds"))
red_spec_1 <- read_rds(here(mform_loc,"red_1.rds"))

```

The key phenomonenon of iterated reference games is that the descriptions to the target images shorten over the course of repetition. This pattern holds for the small groups in this experiment as well. The number of words produced by speakers decreases over the course of rounds, both in aggregate and for many individual groups (Figure \ref(fig:triptych-red)). Nonetheless, in some groups, a later speaker may be more verbose than an earlier speaker. Speakers make longer utterances in early blocks that reduce to shorter utterances in later blocks. From a linear model (`r form(red_spec_1)`), the effect of being one block later is `r stats_text(red_1,1)` words. 

The overall effect of having more players in a group is `r stats_text(red_1,4)` words from the speaker per trial per additional player. There is no clear interaction between block and group size (`r stats(red_1,2)`). Larger groups saying more is consistent with predictions from audience design that with more listeners to accommodate, the speaker may use multiple conceptualizations, either initially as a hedge or in response to listener clarifications. 




One potential concern is that group size correlates with whether the speaker has had the speaker role before (smaller groups repeat speakers more). To address this confound, we coded for whether the speaker has been speaker in an earlier block













### Divergence 

```{r triptych-div, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO", cache=FALSE}

one_two_diverge <- read_rds(here("code/models/one_two_diverge.rds"))
three_diverge <- read_rds(here("code/models/three_diverge.rds"))
# divergence

#1
one <-  one_two_diverge |> filter(condition %in% c("2", "3","4","5","6")) |> 
                             ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=16))+scale_color_viridis(discrete=T, direction=-1)
#2
palette = c("6noro"="orange", "6highfeed"="pink", "6emoji"="red")

two <-  one_two_diverge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
                              ggplot( aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
      coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  theme(legend.position="bottom",
        text=element_text(size=16))+
   scale_color_manual(values=palette)

#3
three <-  three_diverge |> ggplot(aes(x=repNum+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(condition,tangram), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
  guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=16))+
   scale_color_brewer(palette="Paired", direction=-1)

plot_grid(one,two,three, nrow=1)
```

```{r}
div_1 <- read_rds(here(msum_loc, "div_1.rds"))
div_spec_1 <- read_rds(here(mform_loc, "div_1.rds"))

```

Over the course of the game, different groups develop their own ways of identifying the different figures. As groups diverge, their descriptions become less similar to those used to describe the same figure in other games (`r stats_text(div_1, 1)`). Group size does not affect the cross-groups similarities in the first block (`r stats_text(div_1, 3)`), but smaller groups diverge from each other faster than larger groups (`r stats_text(div_1,2)`). 

### Examples of names

While most groups did form conventions for most tangrams, it's illustrative to look at a case where a group did not. Table \ref{diamond} shows the transcript of a 4-person group for a specific figure where they described it geometrically every round, leading to long and not very informative descriptions. Nearly all the figures have diamond heads, so this isn't a distinguishing feature, yet it is described. This illustrates the variability between groups, but also why conventions might be useful. 


```{r diamond}
diamond <- tribble(~`Block`, ~`Person`, ~Text,
                 "1","A(S)","Diamond on top. Body with no real arms or legs. The body is shaped like a boot with the diamond on top.",
		"","C", "Is the boot pointed left or right?",
		"2", "B(S)", "diamond on top, large body beneath it. Left is a straight line all the way down, small variations on the right to the main body",
		"3", "C(S)", "Diamond in center on top. Left side straight, right side carved out like a vase.",
		"4", "D(S)", "Diamond head, flat topped body, straight on the left side with two triangles pointing out on the left",
		"","D(S)" ,"*on the right",
	"5" ,"A(S)", "Diamond on top. Left side is straight, right side is obstructed, looks like a boot",
	"", 	"B", "what do you mean by obstructed?",
		"", "A(S)", "The left side of the body is right, right side has bents in it",
		"6", "B(S)", "Diamond on top of a long large body/rectangle. Left side is complete, right side has bits missing")

knitr::kable(diamond, caption = "Excerpt from a group that did not reduce very much. The speaker for each round is marked with (S). Figure under discussion is row 3, column 3 in Figure \\ref{game}A.\\label{diamond}",  format="latex", booktabs=TRUE, linesep="") %>%
kable_styling(full_width = F) %>%
column_spec(3, width = "16em") %>% kable_styling(latex_options="H")

```



A different 4-person group had a member who during the first block shared the idea that the task would be easier if they explicitly gave "codenames" to the figures. The transcript for this group and one of the tangrams is shown in Table \ref{zigzag}. Of note, multiple speakers forget the assigned codename, demonstrating that meta-knowledge doesn't always help. This group also describes the figure in relation to another already-named figured. Nonetheless, the group successfully conventionalizes on a couple reduced names for this figure: "zigzag" and "beggar". This dual-naming of figures from multiple conceptual angles contributed by different speakers also occurs in other games. 

### Convergence

```{r triptych-conv, fig.env = "figure*", fig.pos = "t!", fig.width=10, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "TODO", cache=FALSE}
#convergence

one_two_converge <- read_rds(here("code/models/one_two_converge.rds"))
three_converge <- read_rds(here("code/models/three_converge.rds"))
#1
one <- one_two_converge |> filter(condition %in% c("2", "3","4","5","6")) |> ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.2,1))+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Cosine Similarity", x="Block", color="")+
  guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  theme(legend.position="bottom",
        text=element_text(size=16))+     scale_color_viridis(discrete=T, direction=-1)




#2
palette = c("6noro"="orange", "6highfeed"="pink", "6emoji"="red")

two <- one_two_converge |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="Block", color="")+
  theme(legend.position="bottom",
        text=element_text(size=16))+    scale_color_manual(values=palette)



#3



three <- three_converge |>  ggplot( aes(x=earlier+1,y=sim,color=condition))+
      stat_summary(aes(group=str_c(gameId), color=condition),fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=.5, geom="point")+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
  coord_cartesian(ylim=c(.2,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
    guides(color = guide_legend(nrow=2, by_row=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+

  theme(legend.position="bottom",
        text=element_text(size=16))+     scale_color_brewer(palette="Paired", direction=-1)

plot_grid(one, two, three, nrow=1)
```

```{r}
tolast_1 <- read_rds(here(msum_loc, "tolast_1.rds"))
tolast_spec_1 <- read_rds(here(mform_loc, "tolast_1.rds"))

tonext_1 <- read_rds(here(msum_loc, "tonext_1.rds"))
tonext_spec_1 <- read_rds(here(mform_loc, "tonext_1.rds"))

tofirst_1 <- read_rds(here(msum_loc, "tofirst_1.rds"))
tofirst_spec_1 <- read_rds(here(mform_loc, "tofirst_1.rds"))

```

If we treat the last round utterance as the convention, then we can see how earlier utterances tend toward that convention. Later utterances are closer to the last utterance (`r stats_text(tolast_1, 2)`). The distance from the first to last utterances is invariant across group size (`r stats_text(tolast_1, 1)`), but smaller groups converge faster (`r stats_text(tolast_1, 3)`). 

This same pattern can be seen comparing utterances from adjacent rounds as later on adjacent rounds have utterances that are more similar to each other (`r stats_text(tonext_1, 2)`). 

I think we don't mention distance to first since that's not interesting? 

### Distinctiveness of tangrams

```{r}

tandiv_1 <- read_rds(here(msum_loc, "tandiv_1.rds"))
tandiv_spec_1 <- read_rds(here(mform_loc, "tandiv_1.rds"))

```

Another way of looking at how language changes over the course of the game is looking at how games start to refer to different tangrams more differently. This could reflect initial overlap in descriping many figures as sitting or standing or by leg and arm and head position. 

Over the course of the game, descriptions for each tangram become more distinctive (`r stats_text(tandiv_1, 1)`). 

## Interim Discussion

Experiment 1 sought to extend iterated reference games to groups of up to 6 players and look at how group size variation influenced different aspects of the reduction phenomena. Across group sizes, accuracy was high and increasing and descriptions reduced over the course of the game. 

TODO comment on role of listeners and qualia

By using NLP tools, we took a quantified look at how partner-specific convergence of referring expressions happens. 

TODO FIX ME

However, one limitation we observed was that the rotation of the speaker role causes speaker experience later in the game to confound with game size. 

# Experiment 2

After experiment 1, there were concerns about whether the results were dependent on any of the methods details. We were also interested in whether there were changes in knowledge or group communication that could support (or diminish) success, especially in the larger groups. To explore this, we ran 3 variants of the paradigm in experiment 1, varying different parameters. These were all run on small sets of 6 player groups. 

TODO examples of prior literature that rotated or didn't rotate !!!
Previous literature varied on whether one person had the speaker role the entire game, or whether the two participants alternated speaker and listener roles in some way. For experiment 1, we went with rotating the speaker every block: we thought this would be percieved as more fair by participants, and we thought it would be a more stringent test of convergence to convention. However, in smaller groups, the speaker role would rotate back around, meaning that the speaker in later blocks would be more experienced in small games than in large games where speakers were usually first time speakers. We cannot disentangle the effects of group size from the effects of speaker experience. To address whether continuity in speakers might contribute to better performance, in experiment 2a we ran 6 player games with one person assigned to be the speaker the entire game. 

Another point of variation in the literature is what sort of feedback is given. In particular, there is variation in whether participants were told what the right answer was when they were wrong (like in @hawkinsCharacterizingDynamicsLearning2020). In experiment 1, we opted for the minimum feedback, to make sure that participants had to negotiate and understand conventions, and could not just pick them up from the end of trial feedback. To see whether this mattered, in experiment 2b, we increased the amount of feedback, showing each participant what everyone had selected and what the right answer was. 

Listener feedback to the speaker in the form of some backchannel, is implicated in the theoretical literature as being important to convention formation TODO CITES. We were interested in whether limiting this backchannel would be a way to push around the reduction pattern and significantly change it. We were worried that entirely removing the backchannel would make the game too unfun and encourage random clicking or quitting of the speaker was just talking into the void. As a compromise between limiting the backchannel and maintaining playability, we switched to giving the listeners a discrete backchannel consisting of 4 emojis, expressing whether they understood, whether they wanted more details, whether they were totally confused, or whether they were amused (TODO figure with emojis and their meanings). These options were based on the common valences expressed in the free chat of listeners from experiment 1. Thus, in 2c, listeners could not contribute questions or content to the discourse, but the speaker still had some feedback on whether the listeners were understanding. 

## Methods


### Participants
All participants were self-reported fluent native English speakers who had not participated in experiment 1. 
All experiment 2 games were 6-player games. All games had a base pay of \$11, in addition to up to \$2.88 in performance bonuses for each player. 
Experiment 2a was run in March and April 2022, and the speaker got an additional \$2 bonus to compensate for the increased effort of being the only speaker. 
Experiment 2b was run in July 2022 and Experiment 2c was run in August 2022. 

A total of N people participated in experiment 2. 

### Materials
The materials were the same as in experiment 1. 

### Procedure
Experiment 2 consisted of three different variations on Experiment 1, so we describe the differences from the Experiment 1 procedure. For the differences between games see TABLE TODO. 

The only change for experiment 2a was that one person was designated the speaker for the entire game. 

For experiment 2b, feedback was changed so that all participants in the feedback stage saw the speaker view showing who selected what and what the right answer was. Listeners still saw text saying whether they individually were correct or wrong. 

For experiment 2c, we altered the chatbox interface for listeners. Instead of a textbox, listeners had 4 buttons, each of which sent a different emoji to the chat. Listeners were given suggested meanings for the 4 emojis during instructions. They could send the emojis as often as desired, for instance, initially indicating confusion, and later indicating understanding. In addition, we added notifications that appeared in the chat box saying when a player had made a selection. 


## Results


### Accuracy

```{r}
acc_2a <- read_rds(here(msum_loc,"acc_2a.rds"))
acc_spec_2a <- read_rds(here(mform_loc,"acc_2a.rds"))

acc_2b <- read_rds(here(msum_loc,"acc_2b.rds"))

acc_2c <- read_rds(here(msum_loc,"acc_2c.rds"))
```

Accuracy was high in 2a (no-rotate) and 2b (full feedback), similar to as in Experiment 1, while accuracy was substantially lower, but still well above change in 2c (limited backchannel) (Figure \ref{accuracy}).  In logistic models of accuracy (`r form(acc_spec_2a)`), participants are more accurate in later blocks (2a: `r stats(acc_2a,1)`, 2b: `r stats(acc_2b,1)`, 2c `r stats(acc_2c,1)`).


### Reduction

```{r}
red_2a <- read_rds(here(msum_loc,"red_2a.rds"))
red_spec_2a <- read_rds(here(mform_loc,"red_2a.rds"))

#red_2b <- read_rds(here(msum_loc,"red_2b.rds"))

red_2c <- read_rds(here(msum_loc,"red_2c.rds"))
```

Reduction occurred in each of the games, with later blocks having fewer words from the speaker than earlier blocks. The slope of reduction was lower in the emoji condition than in the other conditions. 

### Divergence

```{r}
div_2a <- read_rds(here(msum_loc, "div_2a.rds"))
div_spec_2a <- read_rds(here(mform_loc, "div_2a.rds"))

div_2b <- read_rds(here(msum_loc, "div_2b.rds"))

div_2c <- read_rds(here(msum_loc, "div_2c.rds"))
```

All three sub-experiments show the pattern of divergence where descriptions are less similar across groups in later blocks than in earlier blocks. This reduction is stronger in 2a (`r stats_text(div_2a, 1)`) and 2b (`r stats_text(div_2b, 1)`) than in 2c (`r stats_text(div_2c, 1)`). 

### Convergence

```{r}
tolast_2a <- read_rds(here(msum_loc, "tolast_2a.rds"))
tolast_spec_2a <- read_rds(here(mform_loc, "tolast_2a.rds"))

tonext_2a <- read_rds(here(msum_loc, "tonext_2a.rds"))
tonext_spec_2a <- read_rds(here(mform_loc, "tonext_2a.rds"))

tofirst_2a <- read_rds(here(msum_loc, "tofirst_2a.rds"))
tofirst_spec_2a <- read_rds(here(mform_loc, "tofirst_2a.rds"))


tolast_2b <- read_rds(here(msum_loc, "tolast_2b.rds"))

tonext_2b <- read_rds(here(msum_loc, "tonext_2b.rds"))

tofirst_2b <- read_rds(here(msum_loc, "tofirst_2b.rds"))


tolast_2c <- read_rds(here(msum_loc, "tolast_2c.rds"))

tonext_2c <- read_rds(here(msum_loc, "tonext_2c.rds"))

tofirst_2c <- read_rds(here(msum_loc, "tofirst_2c.rds"))

```

Over the course of the game, utterances become more similar to the last utterance, especially in the non-rotating 2a (`r stats_text(tolast_2a, 1)`), but also in 2b (`r stats_text(tolast_2b, 1)`) and to a smaller extent, 2c (`r stats_text(tolast_2c, 1)`). 

This pattern can also be seen in the block to next block similarities getting higher. 

### Tangram distinctiveness

```{r}

tandiv_2a <- read_rds(here(msum_loc, "tandiv_2a.rds"))
tandiv_spec_2a<- read_rds(here(mform_loc, "tandiv_2a.rds"))

tandiv_2b <- read_rds(here(msum_loc, "tandiv_2c.rds"))

tandiv_2c <- read_rds(here(msum_loc, "tandiv_2c.rds"))

```

In all three subexperiments, the descriptions of tangrams become more distinctive within games across time. (2a `r stats_text(tandiv_2a,1)`, 2b `r stats_text(tandiv_2b, 1)`, 2c `r stats_text(tandiv_2c,1)`). 

### Emoji usage ? 

## Interim discussion

# Experiment 3

Based on the results of experiment 2, it seemed that speaker continuity helped groups, and that more feedback maybe helped groups, while limiting the backchannel reduced accuracy and reduction. These results are tentative as we had a limited number of groups in each of these conditions. To more robustly demonstrate that the reduction phenomena were sensitive to these variations in group structure and coherency and to investigate how they interacted with group size, we conducted a better powered experiment. As these experiments are expensive to run, we did not do a full-factorial design; instead, we collapsed the three sources of variation into a "thick-channel" condition, combining single speaker, high feedback, and text backchannel, the settings that give richer feedback and knowledge, and a "thin-channel" condition, which was the opposite (same condition as 2c above). We crossed these two conditions with group size: either 2 or 6 player groups, picking the extreme values from experiment 1. 

We aimed for 40 games in each of these 4 cells. We had previously experienced problems with attrition in 6-player games, as when one or more participants quit, the game discontinued on everyone, leading to fewer games with data from the entire game. To mitigate this, we reprogrammed the game to instead try to keep the game going with the participants who were left (and to start games even if they hadn't filled completely). 

## Methods

### Participants
All participants were self-reported fluent native English speakers who had not participated in experiment 1 or experiment 2. 

Experiment 3 was run in October 2022. Participants in 2-player games were paid \$7 base pay, and participants in 6-player games were paid \$11 base pay. Speakers in the 6-player thick condition were given a \$2 bonus, and all participants could early up to \$2.88 in performance bonus. A total of M people participated. 

### Materials
The materials were the same as in experiment 1.

### Procedure

The thin channel condition was the same as with experiment 2c, described above. 

The thick channel condition was the same as experiment 1, except that one person was designated the speaker throughout, and all participants saw the speaker view for feedback. 

TODO confirm. Across both conditions, messages were sent to the chat to indicate when a participant had made a selection. 

The large change was behind the scenes, to handle games continuing after a participant had quit. Participants were identified as disconnected if their computer was not responding to the server for YY seconds (for instance if they closed the tab and did not reopen it quickly). If the person who disconnected was a listener, they were just removed, and they were skipped over by the speaker rotation (if applicable). If the person who disconnected was a speaker, that trial was discontinued as there was no way for listeners to get more information, and another person was assigned as speaker for the remainder of the block (or remainder of the game, depending on condition). 

TODO figure out how this interacts with the full blocks thing!!! Maybe we should break the pre-reg? (in general?, only here?)

TODO the actual distribution of game sizes!!

TODO add pre-registrations everywhere

Note: when skimming transcripts to tag non-referential utterances, we noticed that one game in the 6-player thick game had a speaker who did not give any sort of coherent descriptions, even with substantial listener prompting. We excluded this game from analyses. 


### Models
note that accuracy model deviates from pre-reg b/c I went overboard with the mixed effects model structure

## Results

 
TODO there's a note saying to rerun these models for longer with more extensive mixed effects!! (at least of reduction model)

### Accuracy

```{r}
acc_3 <- read_rds(here(msum_loc,"acc_3.rds"))
acc_spec_3 <- read_rds(here(mform_loc,"acc_3.rds"))

```

 In a logistic model of accuracy (`r form(acc_spec_3)`), participants are more accurate in later blocks (`r stats(acc_3,1)`). Participants are less accurate overall in the six player games (`r stats(acc_3, 6)`) and more slow to improve in the six player games (`r stats(acc_3, 3)`). Type of channel did not have a clear effect on accuracy either overall (`r stats(acc_3,2)`) or interacting with time (`r stats(acc_3, 2)`). 


### Reduction


```{r} 
red_3 <- read_rds(here(msum_loc, "red_3.rds"))
red_spec_3 <- read_rds(here(mform_loc, "red_3.rds"))

```

In a linear model of the number of words said by the speaker each trial (` r form(red_spec_3)`), reduction in the number of words did occur over blocks (` r stats(red_3,1`)). The six player games said more to start with (`r stats(red_3, 7)`) and reduced less (`r stats(red_3, 4)`). There were not differences due to channel type (`r stats(red_3, 5)`) or channel type over time (`r stats(red_3, 2)`). 


### Divergence

```{r} 
div_3 <- read_rds(here(msum_loc, "div_3.rds"))
div_spec_3 <- read_rds(here(mform_loc, "div_3.rds"))
```

In a model of similarities between utterances produced at the same point in the game for the same tangram across different games (`r form(div_spec_3)`), games get less similar over time (`r stats_text(div_3, 1)`). There are slight differences in the initial starting points across the different conditions, as well as slight condition differences in how fast the games diverge. In particular, 6 player thin games diverge more slowly (` r stats_text(div_3, 3)`). 

### Convergence

```{r}
tolast_3 <- read_rds(here(msum_loc, "tolast_3.rds"))
tolast_spec_3 <- read_rds(here(mform_loc, "tolast_3.rds"))

tonext_3 <- read_rds(here(msum_loc, "tonext_3.rds"))
tonext_spec_3 <- read_rds(here(mform_loc, "tonext_3.rds"))

tofirst_3 <- read_rds(here(msum_loc, "tofirst_3.rds"))
tofirst_spec_3 <- read_rds(here(mform_loc, "tofirst_3.rds"))

```

In terms of convergence towards the last round utterance, this is seen overall (`r stats_text(tolast_3, 3)`). The convergence is slower in thin games (`r stats_text(tolast_3, 4)`) and especially thin 6 player games (`r stats_text(tolast_3, 5)`). 

Comparing utterances between adjacent rounds reveals similar patterns. Thin games have lower similarity between adjacent blocks (`r stats_text(tonext_3, 1)`) as do larger games (`r stats_text(tonext_3,7)`). Later in the game adjacent blocks are more similar than earlier adjacent blocks (`r stats_text(tonext_3, 3)`), painting an overall nonlinear convergent pattern (as seen in figure TODO). 

The last measure of how utterances change within games is how they compare to the first utterance; this is less good because the first utterance has more fluffy language so is less diagnostic, but later utterances are further from the first round utterance than earlier utterances (`r stats_text(tofirst_3, 5)`). (TODO it's in the pre-reg, but we could dump it in a supplement? )

### Distinctiveness

```{r}
# file naming screwup TODO fix me and the file that writes me etc
tandiv_3 <- read_rds(here(msum_loc,"tandiv3.rds"))
tandiv_spec_3 <- read_rds(here(mform_loc, "tandiv3.rds"))

```

Tangram distinctiveness within games increased over time (`r stats_text(tandiv_3, 1)`). There might be more to say about other effects, but it's mostly a starting places being different in larger games and then the slopes also differ a bit? 

### Emoji usage

# General Discussion

this isn't the only group dynamic; could imagine situations where listeners can see each others work collaborate (point to each other what htey think, perhaps see feedback from speaker to one listener) which might make things reduce much faster


The emergence of conventions has been a key case study for communication more broadly. Yet this issue has -- for the most part -- been studied only in dyadic communication. While some studies have examined aspects of convention formation in larger groups [e.g., @yoonAdjustingConceptualPacts2014;@yoonAudienceDesignMultiparty2019], basic descriptive work has not yet investigated how group size changes the dynamics of interaction in a standard referential communication task, in part because such tasks can be difficult to administer to larger groups. Taking advantage of a new online multi-player experiment platform, we ran repeated reference games with groups of 2--6 players and characterized the nature of group performance.

Consistent with dyadic games, listeners' selection accuracy increased over blocks at the same time as listeners sped up their selections (question 1). 
Crucially, speakers reduced the length of their descriptive utterances as they conventionalized on concepts for each image (question 2). Because speakers rotated, this reduction finding is robust: not only did speakers say less in later repetitions than they themselves said earlier, speakers later in the order said less than speakers earlier in the rotation. This reduction varied with group size; smaller groups used shorter utterances, but group size did not significantly interact with block (question 3). The trajectory of reduction also depended on whether the current speaker correctly identified the tangram in the prior block and whether the current speaker was new to being speaker. This pattern is consistent with both the 'aim low' and 'aim middle' hypotheses from previous work [@yoonAdjustingConceptualPacts2014;@yoonAudienceDesignMultiparty2019].

What was specifically different across group sizes? Smaller groups showed more agreement in how each tangram was identified across blocks (question 4), coming to consensus earlier: Their overlap between descriptions in the first 5 blocks to the final block was higher, and words in the final block tended to originate earlier. The greater diversity in how tangrams were described in larger groups could be explained by slower convergence to a convention or parallel competing conceptualizations favored by different speakers. Larger groups have more people for the speaker to communicate to, but also more people who might interrupt with questions, and more people who have opinions about what each image looks like. Bigger groups differ from smaller groups in a number of ways, however, and disentangling these differences is an area for future work. 

<!-- ## Limitations -->

Group interactions are rich, and this experiment is necessarily a schematic simplification with a number of limitations. Real-life situations vary widely in who the interlocuters are, their relationships, their goals, and their environment [@fay2000;@carletta1998]. Our participants were a convenience sample of Prolific workers who were strangers to each other; thus we miss richness that could come from prior relationships or shared community.  Reference is only one goal out of many possible communicative goals, and the tangram images are artificial. 
We provided less feedback than previous studies such as @hawkinsCharacterizingDynamicsLearning2020; this regime imitates situations where interlocutors can't show each other examples, but it's not representative of all communicative environments. Further, our text-based online paradigm meant that participants' individual identities were not especially salient. In sum, communication takes place in a plethora of situations; our experiment provides some insights, but also misses many complexities that should be a focus of further experiments. 

<!-- ## Future work -->

The experimental paradigm presented here could be a valuable tool to disentangle the mechanisms of group size and determine which design parameters are relevant to reduction. Luckily, with an online implementation, recruiting for and running experiments is feasible, and thus it will be possible to iterate on this experiment to determine how far the patterns generalize. While much is left to be explored, this initial data set provides a rich corpus of how humans adapt language dynamically to communicate. 

## Limitations


# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

