---
title: |
 | Supplement to "Interaction structure constrains 
 | the emergence of conventions in group communication"
output:
  pdf_document:
    toc: true
    toc_depth: 2
    keep_tex: true
    extra_dependencies: ["float"]
header-includes:
 - \usepackage{float}
 - \usepackage{setspace}\singlespacing
 - \renewcommand{\textfraction}{0.00}
 - \renewcommand{\topfraction}{1}
 - \renewcommand{\bottomfraction}{1}
 - \renewcommand{\floatpagefraction}{1}
 - \setcounter{topnumber}{5}
 - \setcounter{bottomnumber}{5}
 - \setcounter{totalnumber}{6}

---
```{r set-up, include=FALSE}
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)
library(ggthemes)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())


knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.crop = F, out.width = "100%", dpi=300,
                      fig.pos = "H", fig.path='figs/', fig.env="figure",
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T, out.extra="")


color_scheme_1 <- c("2"="#FFBDD4", "5"="#A12EFF", "3"="#FF7DF0","6"="#6940FF","4"="#D24AFF")
color_scheme_2 <- c( "6 full feedback"="#425df5", "6 same describer"="#00A2FF","6 thin"="#D47E04")

color_scheme_3 <- c("2 thin"="#FFDA09","6 thin"="#D47E04", 
                    "2 thick"="#77F3DB","6 thick"="#00BDA8")


		
ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  |> 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"




image_location="write-ups/images"

msum_loc="code/paper_mods/summary"
mform_loc="code/paper_mods/formulae"

source(here("code/prep_ms.R"))


stats <- function(model, row, decimal=2){
  model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c(model[row,1],": ", model[row,2], " ", model[row,3])
}

stats_text  <- function(model, row, decimal=2){
    model <- model |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)
  str_c( model[row,2],"  ",model[row,3])
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
  str_replace_all("\\*"," $\\\\times$ ") |> 
  str_replace_all("\\+", "&nbsp;+ ") |> 
   str_replace_all("~", "$\\\\sim$ ")
}
```

# Number of games

```{r participants}

players <- combined_results |> mutate(realPlayer=ifelse(is.na(activePlayerCount), numPlayers, activePlayerCount),
                                       numPlayers=ifelse(condition %in% c("6_thin", "6_thick"), "6*", as.character(numPlayers))) |> group_by(condition, numPlayers, gameId) |> summarize(count=max(realPlayer)) |> group_by(condition, numPlayers) |> summarize(`Total Participants`=sum(count))

summary <- combined_results |> group_by(condition, trialNum, repNum, gameId, numPlayers) |> 
  mutate(numPlayers=ifelse(condition %in% c("6_thin", "6_thick"), "6*", as.character(numPlayers))) |> 
  group_by(gameId, numPlayers, condition) |> 
  summarize(num_trials=max(trialNum)) |> 
  arrange(numPlayers) |> 
  mutate(complete=ifelse(num_trials==71,T,F)) |> 
  group_by(numPlayers,complete, condition) |> 
  tally() |> 
  pivot_wider(names_from=complete, values_from=n) |> 
    left_join(players) |> 
  rename(Players=numPlayers,Complete=`TRUE`, Partial=`FALSE`) |> 
  mutate(Partial=ifelse(is.na(Partial), 0, Partial)) |> 
  mutate(Experiment=factor(condition, levels=c("rotate","no_rotate","full_feedback", "emoji", "2_thin", "6_thin", "2_thick", "6_thick"),
                          labels=c("1: baseline", "2: same describer", "2: full feedback", "2: thin", "3: thin", "3: thin", "3: thick", "3: thick"))) |> 
  select(Experiment, Players, Complete, Partial, `Total Participants`) |> 
  arrange(Experiment, Players,Complete,Partial, `Total Participants`)

knitr::kable(summary, caption="The number of games in each experiment and condition. Complete games finished all 6 blocks; partial games ended early due to disconnections, but contributed at least one complete block of data. 6* indicates that some games started with fewer than 6 players or continued with fewer than 6 players after participants disconnected.")
```

In experiment 3, the 6* player games did not all have 6 players, both because games continued as participants dropped out and because if there weren't enough players after 5 minutes of waiting, the game would start with whoever was there. All analyses use "intent to treat" and call these 6 player games. 

The number of games goes up in some cases because only complete blocks (where the describer said something every trial) are analysed. If there was initial confusion and a desciber missed a trial, that block was excluded. 

```{r player-count, fig.width=8, fig.height=3, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Number of players during 6 thin and 6 thick games in experiment 3. Blocks that were incomplete were excluded, so if a describer said nothing during a trial, that block was excluded." }

combined_results |> filter(condition %in% c("6_thin", "6_thick")) |> select(gameId, trialNum, activePlayerCount, condition) |> 
  unique() |>
  mutate(numplayers=as.factor(activePlayerCount)) |> 
  ggplot(aes(x=trialNum+1,fill=numplayers))+
  geom_bar(width=1,position="stack", alpha=.7)+
  facet_grid(.~condition)+
  labs(fill="Number of players", y="Count", x="Trial")+
  theme(legend.position = "bottom")+scale_fill_solarized()

```

\pagebreak

# More on matcher utterances 

 
```{r, include=T}

listeners <- combined_results |> select(condition, playerId, gameId, repNum, trialNum, targetNum, numPlayers)

listener_chat <- combined_chat |> filter(role=="listener") |>  full_join(listeners) |> group_by(condition,  numPlayers, trialNum, repNum, gameId) |> mutate(total_num_words=ifelse(is.na(total_num_words),0, total_num_words)) |> 
  summarize(words=sum(total_num_words)) |> filter(condition %in% c("rotate", "2_thick", "6_thick", "no_rotate", "full_feedback"))

  emojis <- combined_emoji |> mutate(emoji=case_when(
    text=="✅"~  "check",
    text=="🤔" ~ "think",
    text=="❌" ~ "x",
    text=="😂" ~ "lol",
  )) |> full_join(listeners) |> filter(condition %in% c("2_thin", "6_thin", "emoji"))|>
    mutate(is.emoji=ifelse(is.na(emoji), 0, 1)) |> 
    group_by(gameId, trialNum, repNum, condition, numPlayers) 
  
  count_emoji <- emojis |> summarize(words=sum(is.emoji))
  
  all_list <- listener_chat |> union(count_emoji) |> mutate(condition2=ifelse(condition=="rotate", str_c(numPlayers,condition), condition))
```


Matchers' use of backchannel declined over the course of the game. The use of emoji in the thin games is not directly comparable to matcher language use in thick games, since some emoji usage (such as the green checkmark) are most likely equivalent to non-referential matcher language ("got it" etc.) that was excluded. The higher rate of emoji use versus referential language thus could be due to its non-equivalence, a lower level of accuracy in thin games, or matchers having a lower threshold for sending emojis compared to writing out clarifications. 

```{r listeners, fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Matcher contributions. A-C: Fraction of trials where any matcher said anything that was referential. Dots are per game averages. Smooths are binomial fit lines. D-F: On trials where at least one matcher contributed, the number of words of referential language produced by matchers. Dots are per game averages. Smooths are quadratic fit lines. Y-axis is truncated, and a few outliers points are not visible."}
anytalk <- all_list |> group_by(condition, numPlayers, condition2, gameId, trialNum, repNum) |> summarize(words=sum(words)) |> mutate(is.words=ifelse(words>0, 1,0)) 

# maybe try per game trials/block where any listener talked?


one_talk_dat <- anytalk |> filter(condition=="rotate") |>  
    mutate(numPlayers=as.character(numPlayers))

one_talk_plot <- 
ggplot(one_talk_dat, aes(x=repNum+1, y=is.words, color=numPlayers))+
  geom_point(data=one_talk_dat|> group_by(gameId, repNum, numPlayers) |> summarize(is.words=mean(is.words)),position = position_dodge(width=.4), alpha=.3)+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1.05))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="Block", color="", title="Experiment 1")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
  annotate("text", x=1,y=1.05,label="A", size=6, fontface="bold")+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),        plot.title=element_text(size=16, hjust=.5))+
  scale_color_manual(values=color_scheme_1)


#2

two_talk_dat <- anytalk|> filter(condition %in% c("no_rotate","full_feedback", "emoji")) |>
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 same describer",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin"))

two_talk_plot <- 
ggplot(two_talk_dat, aes(x=repNum+1, y=is.words, color=condition))+
  geom_point(data=two_talk_dat|> group_by(gameId, repNum, condition) |> summarize(is.words=mean(is.words)),position = position_dodge(width=.4), alpha=.3)+
   geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1.05))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="", color="", title="Experiment 2")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
  annotate("text", x=1,y=1.05,label="B", size=6, fontface="bold")+
    annotate("text", x=3.5,y=1.05,label="Any matcher words", size=6)+
   theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),        plot.title=element_text(size=16, hjust=.5),
        axis.title.y=element_blank())+
    scale_color_manual(values=color_scheme_2)

#3


three_talk_dat <- anytalk|> filter(condition %in% c("2_thin", "2_thick", "6_thin", "6_thick")) |>  
  mutate(condition=str_replace(condition, "_", " "))

three_talk_plot <- 
ggplot(three_talk_dat, aes(x=repNum+1, y=is.words, color=condition))+
  geom_point(data=three_talk_dat|> group_by(gameId, repNum, condition) |> summarize(is.words=mean(is.words)),position = position_dodge(width=.4), alpha=.3)+
geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
  coord_cartesian(ylim=c(0,1.05))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Fraction trials with any words", x="", color="", title="Experiment 3")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=1.2) ) )+
  annotate("text", x=1,y=1.05,label="C", size=6, fontface="bold")+
   theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),        plot.title=element_text(size=16, hjust=.5),
        axis.title.y=element_blank())+
  scale_color_manual(values=color_scheme_3)

  top <- plot_grid(one_talk_plot, two_talk_plot, three_talk_plot, nrow=1, rel_widths = c(1.05,1,1))
  
  
  
  
one_list_dat <- all_list |>    filter(words!=0)|> filter(condition=="rotate") |>  
    mutate(numPlayers=as.character(numPlayers))

one_list_plot <- 
ggplot(one_list_dat, aes(x=repNum+1, y=words, color=numPlayers))+
geom_point(data=one_list_dat|> group_by(gameId, repNum, numPlayers) |> summarize(words=mean(words)),position = position_dodge(width=.4), alpha=.3)+ 
  geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="Block", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    annotate("text", x=1,y=25,label="D", size=6, fontface="bold")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.x=element_blank())+
  scale_color_manual(values=color_scheme_1, drop=F)


#2

two_list_dat <- all_list|>   filter(words!=0) |> filter(condition %in% c("no_rotate","full_feedback")) |>
  filter(numPlayers==6) |> 
    mutate(condition=case_when(
    condition=="no_rotate" ~ "6 same describer",
    condition=="full_feedback" ~ "6 full feedback",
    condition=="emoji" ~ "6 thin"))

two_list_plot <- ggplot(two_list_dat, aes(x=repNum+1, y=words, color=condition))+
  geom_point(data=two_list_dat|> group_by(gameId, repNum, condition) |> summarize(words=mean(words)),position = position_dodge(width=.4), alpha=.3)+ 
      geom_point(size=1, alpha=.05, position = position_dodge(width=.4))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="", color="")+
      annotate("text", x=1,y=25,label="E", size=6, fontface="bold")+
  annotate("text", x=3.5,y=25,label="Words from matchers", size=6)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_blank())+
    scale_color_manual(values=color_scheme_2, drop=F)

#3


three_list_dat <- all_list|>   filter(words!=0) |> filter(condition %in% c( "2_thick", "6_thick")) |>  
  mutate(condition=str_replace(condition, "_", " "))

three_list_plot <- 
ggplot(three_list_dat, aes(x=repNum+1, y=words, color=condition))+
geom_point(data=three_list_dat|> group_by(gameId, repNum, condition) |> summarize(words=mean(words)),position = position_dodge(width=.4), alpha=.3)+     geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+  scale_color_manual(values=color_scheme_3)+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  coord_cartesian(ylim=c(0,25))+
       scale_x_continuous(breaks=seq(1,6))+
  labs( y="Number of words", x="", color="")+
      annotate("text", x=1,y=25,label="F", size=6, fontface="bold")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_blank())

  bot <- plot_grid(one_list_plot, two_list_plot, three_list_plot, nrow=1, rel_widths=c(1.05,1,1))
  
plot_grid(top, bot, nrow=2, rel_heights = c(1,.75))

```


```{r emoji,  fig.width=8, fig.height=2.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Fraction of trials on which at least one matcher produced the labelled emoji. Fraction of trials when any emoji was produced are shown in black.  Dots are per condition, per block estimates with 95\\% bootstrapped CIs. Smooths are binomial fit lines. "}
combined_emoji |> mutate(emoji=case_when(
    text=="✅"~  "check",
    text=="🤔" ~ "think",
    text=="❌" ~ "x",
    text=="😂" ~ "lol",
  )) |>  filter(!is.na(emoji)) |> full_join(listeners) |> 
  filter(condition %in% c("2_thin", "6_thin", "emoji"))|> 
  unique() |> 
  mutate(is.emoji=ifelse(is.na(emoji), 0, 1)) |> 
    pivot_wider(names_from=emoji, values_from=is.emoji, values_fill=0) |> 
  select(-`NA`) |> 
  mutate(total=check+think+x+lol) |> 
  pivot_longer(`think`:`total`, names_to="emoji", values_to="count") |> 
  group_by(gameId, trialNum, repNum, condition, numPlayers, emoji) |> mutate(num=ifelse(count>1, 1, count)) |> group_by(gameId,trialNum, repNum, condition, emoji) |> summarize(n=sum(num)) |> mutate(any=ifelse(n>1, 1, n)) |> 
  mutate(cond=case_when(
    condition=="2_thin" ~ "Expt 3: 2 thin",
    condition=="6_thin" ~ "Expt 3: 6 thin",
    condition=="emoji" ~ "Expt 2: 6 thin"
  )) -> to_plot

  ggplot(to_plot |> filter(emoji!="total"),aes(x=repNum+1, y=any, color=emoji))+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
        stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1)+
        scale_color_solarized()+
     geom_smooth(data=to_plot |> filter(emoji=="total"), method=glm, formula=y~poly(x,2), alpha=.3,  color="black")+
        stat_summary(data=to_plot |> filter(emoji=="total"), fun.data = "mean_cl_boot", position = position_dodge(width=.3), alpha=1, color="black")+
  facet_wrap(~cond)+
    labs(x="Block", y="Fraction trials")+
  guides(color = guide_legend(override.aes = list(linetype = 0, alpha=1, fill=NA) ) )+
    theme(legend.text=element_text(size=12))

```

We note a deviation from the pre-registration here in the analysis of the emojis. In the pre-registration we said we would "analyse the distribution of emoji’s produced as a function of block and its relation to accuracy and speaker utterance length." We did not do this beyond the visualization shown here. 

\pagebreak

# Additional measure of convergence

The main text included the graph for convergence comparing utterances from blocks 1-5 to the utterance from block 6. Here we show two other measures of semantic shifts for descriptions for the same tangram in the same game: similarity to the first utterance and similarity to the next utterance. 

Similarity to the first utterance is not very informative (but we pre-registered it). Similarity to the next utterance is what actually drives the convergence phenomena: pairs of utterances from adjacent blocks become closer together over time. 

```{r other,  fig.width=10, fig.height=8, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Additional measures of convergence and divergence. A-C is the similarity between utterances on a given block to the first block utterance for the same image, in the same game.  Dots are per-game averages, smooths are quadratic. D-F is the similarity between utterances on a given block to the corresponding utterances in the next block.  Dots are per-game averages, smooths are quadratic.", cache=T}

#first

one_two_first <- read_rds(here("code/models/one_two_tofirst.rds"))
three_tofirst <- read_rds(here("code/models/three_tofirst.rds"))
#1
one_first_dat <- one_two_first |> filter(condition %in% c("2", "3","4","5","6"))

one_first_plot <- ggplot(one_first_dat, aes(x=later+1,y=sim,color=condition))+
geom_point(data=one_first_dat |> group_by(later, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(formula=y~poly(x,2))+
  coord_cartesian(ylim=c(.25,.9))+
  scale_x_continuous(breaks=seq(2,6))+
  labs(y="Cosine Similarity", x="Block", color="", title="Experiment 1")+
      annotate("text", x=2,y=.9,label="A", size=6, fontface="bold")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
                 plot.title=element_text(size=16, hjust=.5),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)


#2

two_first_dat <- one_two_first |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |> 
    mutate(condition=case_when(
    condition=="6noro" ~ "6 same describer",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin"))

two_first_plot <- 
  ggplot(two_first_dat, aes(x=later+1,y=sim,color=condition))+
geom_point(data=two_first_dat |> group_by(later, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(method="glm", formula=y~poly(x,2), show_guide=F)+ # the smooth isn't working b/c singularities
  scale_x_continuous(breaks=seq(2,6))+
  coord_cartesian(ylim=c(.25,.9))+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="", color="", title="Experiment 2")+
      annotate("text", x=2,y=.9,label="B", size=6, fontface="bold")+
annotate("text", x=4,y=.9,label="Similarity to first block", size=5)+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        legend.text=element_text(size=14),
         plot.title=element_text(size=16, hjust=.5),
        axis.title.y=element_blank(),
        axis.title=element_text(size=14))+    scale_color_manual(values=color_scheme_2)
#3

three_first_dat <- three_tofirst |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1)))

three_first_plot <- ggplot(three_first_dat, aes(x=later+1,y=sim,color=condition))+
geom_point(data=three_first_dat |> group_by(later, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(2,6))+
  coord_cartesian(ylim=c(.25,.9))+
  labs(y="Cosine Similarity", x="", color="", title="Experiment 3")+
    guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
      annotate("text", x=2,y=.9,label="C", size=6, fontface="bold")+
  theme(legend.position="none",
        axis.text=element_text(size=12),
        axis.title.y=element_blank(),
                 plot.title=element_text(size=16, hjust=.5),
        legend.text=element_text(size=14),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_3)

tofirst <- plot_grid(one_first_plot, two_first_plot, three_first_plot, nrow=1, rel_widths = c(1.05,1,1))

one_two_next <- read_rds(here("code/models/one_two_tonext.rds"))
three_next <- read_rds(here("code/models/three_tonext.rds"))
# divergence

#1
one_next_dat <-  one_two_next|> filter(condition %in% c("2", "3","4","5","6"))

one_next_plot <- ggplot(one_next_dat, aes(x=earlier+1,y=sim,color=condition))+
   geom_point(data=one_next_dat |> group_by(earlier, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  guides(color = guide_legend(nrow=2, byrow=T, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,5))+
        coord_cartesian(ylim=c(.25,1))+
  labs(y="Cosine Similarity", x="Block", color="")+
      annotate("text", x=1,y=1,label="D", size=6, fontface="bold")+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
        axis.title.x = element_blank())+
  scale_color_manual(values=color_scheme_1)

#2

two_next_dat <-  one_two_next |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 same describer",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin"))

two_next_plot <- ggplot(two_next_dat, aes(x=earlier+1,y=sim,color=condition))+
     geom_point(data=two_next_dat |> group_by(earlier, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  scale_x_continuous(breaks=seq(1,5))+
        coord_cartesian(ylim=c(.25,1))+
  labs(y="Cosine Similarity", x="", color="")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
annotate("text", x=3,y=1,label="Similarity to next block", size=5)+
      annotate("text", x=1,y=1,label="E", size=6, fontface="bold")+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_blank())+
   scale_color_manual(values=color_scheme_2)

#3
three_next_dat <-  three_next |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1)))

three_next_plot <- ggplot(three_next_dat, aes(x=earlier+1,y=sim,color=condition))+
      geom_point(data=three_next_dat |> group_by(earlier,gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(formula=y~poly(x,2), method="lm")+
  scale_x_continuous(breaks=seq(1,5))+
        coord_cartesian(ylim=c(.25,1))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
    annotate("text", x=1,y=1,label="F", size=6, fontface="bold")+
  labs(y="Cosine Similarity", x="Block", color="")+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_blank())+
scale_color_manual(values=color_scheme_3)

tonext <- plot_grid(one_next_plot,two_next_plot,three_next_plot, nrow=1, rel_widths = c(1.05,1,1))


plot_grid(tofirst, tonext, nrow=2, rel_heights = c(.8,1), label_size=20)
```

\pagebreak

# Distinctiveness of tangrams

An additional measure of convergence/divergence patterns is how different tangrams get described in the same game -- as nicknames evolve, different tangrams get more different descriptions. 

```{r dist,   fig.width=10, fig.height=4, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Divergence in descriptions of different tangrams. Cosine similarity between the descriptions of two different tangrams in the same block and group are shown.  Dots are per-game averages, smooths are quadratic.", cache=T}

one_two_tandiv<- read_rds(here("code/models/one_two_tangrams_div.rds"))
three_tandiv<- read_rds(here("code/models/three_tangrams_div.rds"))
# divergence

#1
one_div_dat <-  one_two_tandiv |> filter(condition %in% c("2", "3","4","5","6"))

one_div_plot <- ggplot(one_div_dat, aes(x=repNum+1,y=sim,color=condition))+
      geom_point(data=one_div_dat |> group_by(repNum, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(formula=y~poly(x,2))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  scale_x_continuous(breaks=seq(1,6))+
        coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="Block", color="", title="Experiment 1")+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
                 plot.title=element_text(size=16, hjust=.5),
        axis.title=element_text(size=14))+
  scale_color_manual(values=color_scheme_1)

#2

two_div_dat <-  one_two_tandiv |>  filter(condition %in% c("6emoji", "6highfeed", "6noro")) |>
  mutate(condition=case_when(
    condition=="6noro" ~ "6 same describer",
    condition=="6highfeed" ~ "6 full feedback",
    condition=="6emoji" ~ "6 thin"))

two_div_plot <- ggplot(two_div_dat, aes(x=repNum+1,y=sim,color=condition))+
    geom_point(data=two_div_dat |> group_by(repNum, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
      coord_cartesian(ylim=c(.1,.7))+
  labs(y="Cosine Similarity", x="", color="", title="Experiment 2")+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
                 plot.title=element_text(size=16, hjust=.5),
        axis.title.y=element_blank())+
   scale_color_manual(values=color_scheme_2)

#3
three_div_dat <-  three_tandiv |> mutate(condition=str_c(str_sub(condition,1,1)," ", str_sub(condition,2,-1))) 

three_div_plot <- ggplot(three_div_dat, aes(x=repNum+1,y=sim,color=condition))+
      geom_point(data=three_div_dat |> group_by(repNum, gameId, condition) |> summarize(sim=mean(sim)),position = position_dodge(width=.4), alpha=.3)+
  geom_smooth(formula=y~poly(x,2))+
  scale_x_continuous(breaks=seq(1,6))+
   coord_cartesian(ylim=c(.1,.7))+
  guides(color = guide_legend(nrow=2, byrow=F, override.aes = list(linetype = 0, alpha=1, fill=NA, size=6) ) )+
  labs(y="Cosine Similarity", x="", color="", title="Experiment 3")+
  theme(legend.position="bottom",
        axis.text=element_text(size=12),
        legend.text=element_text(size=13),
        axis.title=element_text(size=14),
                 plot.title=element_text(size=16, hjust=.5),
        axis.title.y=element_blank())+
scale_color_manual(values=color_scheme_3)

plot_grid(one_div_plot,two_div_plot,three_div_plot, nrow=1, rel_widths = c(1.05,1,1))


```

```{r}

tandiv_1 <- read_rds(here(msum_loc, "tandiv_1.rds"))
tandiv_spec_1 <- read_rds(here(mform_loc, "tandiv_1.rds"))

```
```{r}

tandiv_2a <- read_rds(here(msum_loc, "tandiv_2a.rds"))
tandiv_spec_2a<- read_rds(here(mform_loc, "tandiv_2a.rds"))

tandiv_2b <- read_rds(here(msum_loc, "tandiv_2c.rds"))

tandiv_2c <- read_rds(here(msum_loc, "tandiv_2c.rds"))

```

```{r}
tandiv_3 <- read_rds(here(msum_loc,"tandiv_3.rds"))
tandiv_spec_3 <- read_rds(here(mform_loc, "tandiv_3.rds"))

```
```{r}
tolast_1 <- read_rds(here(msum_loc, "tolast_1.rds"))

tonext_1 <- read_rds(here(msum_loc, "tonext_1.rds"))

tolast_2a <- read_rds(here(msum_loc, "tolast_2a.rds"))

tonext_2a <- read_rds(here(msum_loc, "tonext_2a.rds"))

tolast_2b <- read_rds(here(msum_loc, "tolast_2b.rds"))

tonext_2b <- read_rds(here(msum_loc, "tonext_2b.rds"))

tolast_2c <- read_rds(here(msum_loc, "tolast_2c.rds"))

tonext_2c <- read_rds(here(msum_loc, "tonext_2c.rds"))

tolast_3 <- read_rds(here(msum_loc, "tolast_3.rds"))

tonext_3 <- read_rds(here(msum_loc, "tonext_3.rds"))

```


\pagebreak

# Summaries of model outputs

The following sections contain model outputs. All models were run using BRMS. We report the priors and pre-registration status for each group of models. Tables provide the individual model formulae and the point estimates and 95% credible intervals for the fixed effects. 

Note that for all models, block was 0 indexed, so intercepts are what happened during the first block. 


 
```{r}
form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) |> str_replace_all(" ","") |> 
      str_replace_all("~", "~$\\\\sim$ ") |> 
  str_replace_all("\\*","~$\\\\times$ ") |> 
  str_replace_all("\\+", "~+ ") |> 
   str_replace_all("_", "")
}

do_table <- function(mod, cap,decimal=2){
  model <- read_rds(here(msum_loc,mod)) |> 
    mutate(Estimate=round(Estimate, digits=decimal),
           Term=str_replace_all(Term, "_", ""),
           Lower=round(lower, digits=decimal),
           Upper=round(upper, digits=decimal),
           `Credible Interval`=str_c("[",Lower,", ", Upper,"]")) |> 
    select(Term, Estimate, `Credible Interval`)

spec <- read_rds(here(mform_loc,mod))

kable(model |> select(Term, Est.=Estimate, `95\\% CrI`=`Credible Interval`), escape=F, format='latex', booktabs=T, linesep="",
      caption=str_c(cap, ": ",form(spec), sep=""),
      align='lll', position="H")
}
```


# Accuracy models

Accuracy models were all run as logistic models with normal(0,1) priors for both betas and sd. This model was not explicitly included in the experiment 1 and 2 pre-registrations; it was included with more ambitious mixed effects (which did not run in a timely manner) in the experiment 3 pre-registration. 

```{r}

do_table("acc_1.rds", "Experiment 1 logistic model of matcher accuracy")
do_table("acc_2a.rds", "Experiment 2: 6 same describer logistic model of matcher accuracy")
do_table("acc_2b.rds", "Experiment 2: 6 full feedback logistic model of matcher accuracy")
do_table("acc_2c.rds", "Experiment 2: 6 thin logistic model of matcher accuracy")
do_table("acc_3.rds", "Experiment 3 logistic model of matcher accuracy")

```


# Reduction models 

## Primary reduction model

Reduction models were run as linear models with an intercept prior of normal(12,20), a beta prior of normal(0,10), an sd prior of normal(0,5) and a correlation prior of lkj(1). This model was pre-registered for each experiment and run with the mixed effects structure as pre-specified. 

```{r}

do_table("red_1.rds", "Experiment 1")
do_table("red_2a.rds", "Experiment 2: 6 same describer")
do_table("red_2b.rds", "Experiment 2: 6 full feedback")
do_table("red_2c.rds", "Experiment 2: 6 thin")
do_table("red_3.rds", "Experiment 3")

```

## Extra reduction model

For experiment 1, we also pre-specified a model about whether the describer's correctness on the prior block (when they were a matcher) had an effect on how many words of description they produced. Priors were the same as for primary reduction model.

```{r}

do_table("weird_1.rds", "Experiment 1")

```

## Matcher reduction models

These models were not pre-registered. 

For the model of how often any matchers used the backchannel, the priors were normal(0,1) for both beta and sd. 

For the model of how much was said on trials when matchers talked, the priors were the same as for the primary (describer) reduction model. 
```{r}

do_table("list_1.rds", "Experiment 1")

do_table("anylist_1.rds", "Experiment 1")


```

## Initial utterance reduction model

These models were not pre-registered. They looked at describer reduction only on words that were produced prior to the first matcher message each trial. These models were only run on experimental conditions where matchers could contribute textual responses. 

Reduction models were run as linear models with the same priors as the primary reduction model. 

```{r}

do_table("pre_list_1.rds", "Experiment 1")
do_table("pre_list_2a.rds", "Experiment 2: 6 same describer")
do_table("pre_list_2b.rds", "Experiment 2: 6 full feedback")
do_table("pre_list_3.rds", "Experiment 3")

```

# Linguistic content models

We ran a number of models predicting the cosine similarity between pairs of S-BERT embeddings of utterances. For all of these models, we used linear models with the priors normal(.5,.2) for intercept, normal(0,.1) for beta, and normal(0,.05) for sd. 

These models were verbally described (but not formally specified) in the pre-registrations for experiment 2 in the full feedback and thin conditions and for experiment 3, for looking at divergence between games, convergence within games (compared to first block, next block, and last block utterances), and divergence between tangrams within games. 

## Convergence within games: comparison to last round
This is the primary convergence metric presented in the main paper. 

```{r}

do_table("tolast_1.rds", "Experiment 1", decimal=3)
do_table("tolast_2a.rds", "Experiment 2: 6 same describer", decimal=3)
do_table("tolast_2b.rds", "Experiment 2: 6 full feedback", decimal=3)
do_table("tolast_2c.rds", "Experiment 2: 6 thin", decimal=3)
do_table("tolast_3.rds", "Experiment 3", decimal=3)

```


## Divergence across games

This is the divergence metric presented in the paper. 

```{r}

do_table("div_1.rds", "Experiment 1", decimal=3)
do_table("div_2a.rds", "Experiment 2: 6 same describer",decimal=3)
do_table("div_2b.rds", "Experiment 2: 6 full feedback",decimal=3)
do_table("div_2c.rds", "Experiment 2: 6 thin",decimal=3)
do_table("div_3.rds", "Experiment 3",decimal=3)

```


## Divergence across tangrams

This is an additional metric comparing the similiarities between descriptions for different tangrams within a game. It measures how distinct the descriptions for different tangram images are. 

```{r}

do_table("tandiv_1.rds", "Experiment 1",decimal=3)
do_table("tandiv_2a.rds", "Experiment 2: 6 same describer",decimal=3)
do_table("tandiv_2b.rds", "Experiment 2: 6 full feedback",decimal=3)
do_table("tandiv_2c.rds", "Experiment 2: 6 thin",decimal=3)
do_table("tandiv_3.rds", "Experiment 3",decimal=3)

```

\pagebreak

## Convergence to next

We also looked at how similar an utterance was to the next block utterance for the same image in the same group: this can be thought of as the derivative of the to-last comparison. (Although cosine similarities are not actually additive in the same way integrals are).

```{r}

do_table("tonext_1.rds", "Experiment 1",decimal=3)
do_table("tonext_2a.rds", "Experiment 2: 6 same describer",decimal=3)
do_table("tonext_2b.rds", "Experiment 2: 6 full feedback",decimal=3)
do_table("tonext_2c.rds", "Experiment 2: 6 thin",decimal=3)
do_table("tonext_3.rds", "Experiment 3",decimal=3)

```


## Divergence from first

We also looked at how similar an utterance was to the first block utterance for the same image. This is not very informative because first round utterances tend to be pretty noisy with lots of hedges and filler words. 

```{r}

do_table("tofirst_1.rds", "Experiment 1",decimal=3)
do_table("tofirst_2a.rds", "Experiment 2: 6 same describer",decimal=3)
do_table("tofirst_2b.rds", "Experiment 2: 6 full feedback",decimal=3)
do_table("tofirst_2c.rds", "Experiment 2: 6 thin",decimal=3)
do_table("tofirst_3.rds", "Experiment 3",decimal=3)

```

# Exploratory Mega-analytic models

For the mega-analytic models:

 - thin and emoji conditions are coded as thin; everything else is thick

- group size is coded as intent to treat

- the intercept condition is 2 player, thick, first block

- "thinner" is thin condition instead

- "larger" is per addiitonal player

- "block" is per later block

```{r}
do_table("acc_meta.rds", "Mega-analytic on accuracy")
do_table("mega_red.rds", "Mega-analytic of reduction")
do_table("mega_div.rds", "Mega-analytic on divergence between groups", decimal=3)
do_table("mega_tolast.rds", "Mega-analytic on convergence to last", decimal=3)

```

# Log reduction

Reduction models re-run using log-words as DV; these are the same as reduction models except for this change. 

```{r}

do_table("log_red_1.rds", "Experiment 1 log reduction")
do_table("log_red_3.rds", "Experiment 3 log reduction")
```
