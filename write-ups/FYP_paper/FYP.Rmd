---
title             : "How do conventions emerge in group communication: Evidence from 2-4 player reference games"
shorttitle        : "Conventions in groups"

author: 
  - name          : "Veronica Boyce"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : ""
    email         : "vboyce@stanford.edu"
    role:        ""
 
affiliation:
  - id            : "1"
    institution   : "Stanford University"
 
authornote: |
  First Year Project for Psych Department

abstract: |
  TODO
  
keywords          : ""
wordcount         : ""

bibliography      : ["r-references.bib", "FYP.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")

knitr::opts_chunk$set(echo = FALSE, warning=F, message=F)
knitr::opts_chunk$set(dev = "png", dev.args = list(type = "cairo-png"))
options(knitr.table.format = "html")
library(tidyverse)
library(jsonlite)
library(here)
library(rlang)
library(brms)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())

ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  %>% 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"

date_start=lubridate::ymd('2021-05-04')

image_location="write-ups/images"

model_location="code/models"
```

```{r, include=F, cache=T}
d.games <- read_csv(here(data_location, 'games.csv')) %>% 
  rename(gameId = `_id`) %>% 
    filter(createdAt >= date_start)

d.chat.raw <- read_csv(here(data_location, 'rounds.csv'), guess_max=10000) %>%
  filter(createdAt >= date_start) %>%
  mutate(data.chat = ifelse(is.na(data.chat), '{}', data.chat)) %>%
  rename(row_id = `_id`) %>%
  mutate(data.chat = map(data.chat, .f = ParseJSONColumn)) %>%
  unnest(data.chat) %>%
  select(-data.target, -ends_with('response'), -ends_with('_correct'), -ends_with('time')) %>%
  rename_with(~ gsub("data.", "", .x, fixed = TRUE)) %>% 
  write_csv(here(data_location, 'raw_chat.csv'))

d.round_results.raw <- read_csv(here(data_location,'rounds.csv'),guess_max=10000) %>% 
  filter(createdAt >= date_start) %>% 
  rename_with(~ gsub("data.", "", .x, fixed = TRUE)) %>% 
  rename_with ( ~ gsub("room", "player", .x, fixed=T)) %>% 
    rename_with ( ~ gsub("player", "player_", .x, fixed=T)) %>% 
    rename_with ( ~ gsub("correct", "_correct", .x, fixed=T)) %>% 
    rename_with ( ~ gsub("response", "_response", .x, fixed=T)) %>% 
  rename_with( ~ gsub("time", "_time", .x, fixed=T)) %>% 
  select(-chat) %>% 
  gather(key, value, starts_with('player')) %>% 
  separate(key, into = c('blah', 'playerId', 'info')) %>% 
  spread(info, value) %>% 
  select(-blah) %>% 
  mutate(tangram = gsub('/experiment/tangram_', '', target, fixed=TRUE),
         tangram = gsub('.png', '', tangram, fixed=TRUE)) %>% 
  mutate(correct=as.logical(correct),
         time=as.numeric(time)/1000) %>% 
  filter(!is.na(correct)) %>% 
  filter(playerId!=speaker)

#only include rounds that finished
rounds_exclude <- d.round_results.raw %>% group_by(gameId,numPlayers,repNum) %>% tally() %>% filter(n!=12*(numPlayers-1)) %>% select(gameId,repNum)

d.round_results <-  d.round_results.raw %>% anti_join(rounds_exclude)

```



**TODOs**:
- mention pre-reg
- add figure of set-up
- figure sizing
- model results
- intro
- results
- discussion
- any new analyses to add??

# Methods

We recruited participants to play a repeated reference game in groups of 2-4. Participants viewed an array of 12 tangrams (TODO picture). One person was assigned the speaker role and say one of the images highlighted; the goal was for them to communicate the identity of this image to their partners who would then click on it. All participants were free to use the chat box to communicate. The speaker identified each of the 12 tangrams during a block; then the speaker role rotated to a different participant for the next block. Each group completed a total of 6 blocks, all with the same 12 images. We recorded what participants said in the chat, as well as who selected what image and how long they took to select.

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. 

## Participants

```{r, include=F}
summary <- d.round_results %>% group_by(trialNum, repNum, gameId, numPlayers) %>% 
           mutate(time= time %|% 180) %>% 
  summarize(max_time=max(time)) %>% 
  group_by(gameId, numPlayers) %>% 
  summarize(total_time=sum(max_time)/60,
            num_trials=max(trialNum)) %>% 
  arrange(numPlayers) %>% 
  mutate(complete=ifelse(num_trials==71,T,F)) %>% 
  group_by(numPlayers,complete) %>% 
  tally()
```

Participants were recruited using the Prolific platform between 4th and 10th of May 2021. We screened for participants who were fluent, native English speakers. Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, and \$10 for 4-player games (with the intentional of a $10 hourly rate), in addition to performance bonuses.

Our intended sample size was 20 complete games in each group size, but we ended up with `r summary[2,3]` complete 2-player games (`r summary[1,3]` partial),`r summary[4,3]` complete 3-player games (`r summary[3,3]` partial), and `r summary[6,3]` complete 4-player games (`r summary[5,3]` partial). We included excluded incomplete blocks from analyses, but included complete blocks from partial games. (Partial games occurred when a participant disconnected early, for example due to internet trouble.)

## Materials
We used the 12 tangram images used by @hawkinsCharacterizingDynamicsLearning2020 and @clarkReferringCollaborativeProcess1986. These images were displayed in a grid for each participant with order randomized for each participant. The same images were used every round. 

## Procedure

We implemented the experiment using Empirica, a Javascript-based platform for running real-time interactive experiments online [@almaatouqEmpiricaVirtualLab2020]. Code for running this experiment is available at GITHUB URL. From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages that explained the game. Participants had to pass a quiz to be able to play the game. They were then directed to a "waiting room" screen until their partners were ready.

Once the game started, participants saw screens like FIGURE TODO. Each trial, the speaker had to describe the highlighted tangram image so that the listeners could identify it and click it. All participants were free to use the chat box to communicate. Listeners could only click once the speaker had sent a message. Once all listeners has selected (or a 3-minute timer had run out), participants were given feedback. Listeners only learned whether they individually had chosen correctly or not; listeners who were incorrect were not told the correct answer. The speaker saw which tangram each listener had selected. Listeners got 4 points for each correct answer; the speaker got points equal to the average of the listeners points. These points translated into cents of performance bonus at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the speaker once. The same person was the speaker for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were speakers 3 times in 2-player games, 2 times in 3-player games and once or twice in 4-player games.

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

## Data analysis
I skimmed through the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about well or fast the task was going and confirmations or denials ("ok", "got it", "yes", "no"). We exclude these utterances from our analyses.

We used `r cite_r("r-references.bib", footnote=T)` for all our analyses.

# Results

In general groups showed expected patterns. They had high and increasing accuracy, coupled with faster response times, and decreases in utterance length showing the classic reduction pattern. 

```{r chat, include=F}
d.chat <- read_csv(here(data_location, "filtered_chat.csv")) %>% 
  filter(!is.chitchat) %>% 
  filter(!is.na(target)) %>% 
  mutate(text = gsub("\\n", '', fixed = T, text),
         text = gsub("[/?/.]", ' ', text),
         text = str_squish(text),
         tangram = gsub('/experiment/tangram_', '', target, fixed=TRUE),
         tangram = gsub('.png', '', tangram, fixed=TRUE),
         utt_length_chars = str_length(text), 
         utt_length_words = str_count(text, "\\W+") + 1) %>%
  group_by(gameId, trialNum, repNum, tangram, playerId, role, countCorrect, numPlayers) %>%
  summarize(text = paste0(text, collapse = ', '),
            total_num_words = sum(utt_length_words) %>% as.numeric(),
            total_num_chars = sum(utt_length_chars) %>% as.numeric()) %>%
  anti_join(rounds_exclude) %>% 
  full_join(d.round_results, c("gameId", "trialNum", "repNum", "playerId", "tangram", "countCorrect", "numPlayers")) %>% 
  mutate(text = text %|% "",
         total_num_words= total_num_words %|% 0,
         total_num_chars= total_num_chars %|% 0,
         role = role %|% "listener")

```
```{r, include=F}
model_input <- d.chat %>% filter(role=="speaker") %>% 
  mutate(block=repNum,
         words=total_num_words,
         tangram_group=str_c(tangram, gameId))
         
priors <- c(
  set_prior("normal(20, 20)", class="Intercept"),
  set_prior("normal(0, 10)", class="b"),
  set_prior("normal(0, 10)", class="sd"),
  set_prior("lkj(1)",       class="cor"))

model <- brm(words ~ block * numPlayers + (block|tangram)+ (1|playerId)+(1|tangram_group)+(block|gameId), data=model_input,file=here(model_location, "model1"),                            prior=priors, control=list(adapt_delta=.95))

         

```
```{r, include=F}
d.prev.speaker <- d.chat %>% ungroup() %>%  filter(role=="speaker") %>% select(gameId,repNum, tangram, total_num_words_prev=total_num_words)
d.prev.round <- d.chat %>% ungroup() %>% select(playerId, correct, tangram, gameId, repNum) %>% 
  left_join(d.prev.speaker) %>% unique() %>% mutate(repNum=repNum+1)


d.chat.lagged <- d.chat %>%
  ungroup() %>% 
  select(gameId, playerId, trialNum, repNum, playerId, role, tangram, total_num_words, numPlayers) %>%
  left_join(d.prev.round) %>%
  mutate(reduction_word=log(total_num_words)-log(total_num_words_prev)) %>%
  filter(repNum>0) %>%
  filter(role=="speaker") %>%
  mutate(prev_correct_round=correct)


model_input <- d.chat.lagged %>% filter(role=="speaker") %>% 
  mutate(block=repNum,
         words=total_num_words,
         tangram_group=str_c(tangram, gameId),
         was_INcorrect=ifelse(!prev_correct_round,1,0))
         
priors <- c(
  set_prior("normal(20, 20)", class="Intercept"),
  set_prior("normal(0, 10)", class="b"),
  set_prior("normal(0, 10)", class="sd"),
  set_prior("lkj(1)",       class="cor"))

model_speaker_acc <- brm(words ~ block * numPlayers +block*was_INcorrect+ (block|tangram)+ (1|playerId)+(1|tangram_group)+(block|gameId), data=model_input,file=here(model_location, "speaker_acc"),                         prior=priors, control=list(adapt_delta=.95))

         
```

```{r}

fem1 <- fixef(model)
fem2 <- fixef(model_speaker_acc)
```

(ref:accuracy) Listeners have high accuracy which increases of the course of the game, although accuracy increases less in 4-player games than smaller games. Accuracy rates are shown for each block, error bars are bootstrapped 95% CIs. 

```{r accuracy, out.height="35%", fig.width=6, fig.height=4, fig.pos='h', fig.cap="(ref:accuracy)"}

d.round_results %>% group_by(playerId,repNum, gameId, numPlayers) %>% 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  ggplot(aes(x=repNum+1, y=correct.num, color=as.factor(numPlayers)))+
geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  #geom_point()+
  scale_color_brewer(palette="Dark2")+
  #scale_y_continuous(limits = c(0,1))+
  labs(x="Block Number", y="Fraction correct", color="Player count")+
    theme(legend.position="bottom")



```
Most groups were accurate in their selections, with accuracy rising over rounds (Fig \@ref(fig:accuracy)). This indicates that speakers were usually successful at conveying the intended referents. While on average games of each size increase in accuracy, 4-player games show lower gains in accuracy than smaller games. We do not have a clear explanation for why this is, whether it is reliable, or what pattern to expect for even larger (ex. 5 person) games. 


(ref:time) Listeners selected images faster in later blocks. Only times to correct responses are shown.

```{r time, out.height="35%", fig.width=6, fig.height=4, fig.pos='h', fig.cap="(ref:time)"}

d.round_results %>% group_by(playerId, repNum, gameId, numPlayers) %>% 
  filter(correct==T) %>% 
  #summarize(time=mean(time)) %>% 
  ggplot(aes(x=repNum+1, y=time, color=as.factor(numPlayers)))+
  geom_jitter(width=.4, height=0, alpha=.03)+
geom_smooth(method = "glm", formula = y~x,
                      method.args = list(family = gaussian(link = 'log')))+
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  scale_y_continuous(limits = c(0,180))+
    scale_color_brewer(palette="Dark2")+
  labs(x="Block Number", y="Time to selection in seconds", color="Player count")+
  theme(legend.position = "bottom")


```
Participants selected images faster in later rounds (Fig \@ref(fig:time)). There is wide variability, but appears to be an unintuitive effect of group size with fastest selection in 2-player games, but 4-player games being faster than 3-player games. This speed up is consistent with prior work by @weberCulturalConflictMerger2003 which used speed as the dependent measure.


(ref:total-words) Speaker and listeners say fewer words in later blocks. Note: y-axis clipped at 50 which hides a few speaker outliers. 

```{r total-words, out.height="35%", fig.width=6, fig.height=4, fig.pos='h', fig.cap="(ref:total-words)"}

ggplot(d.chat, aes(x=repNum+1, y=total_num_words, color=as.factor(numPlayers)))+
  facet_wrap(~role, nrow=1)+
  scale_color_brewer(palette="Dark2")+
    geom_jitter(alpha=.05)+
    geom_smooth(method=glm, formula=y~poly(x,2), alpha=.3)+
     stat_summary(fun.data = "mean_cl_boot")+
    scale_y_continuous(limits = c(0,50))+
  labs(y="Number of words", x="Block number", color="Player count")+
  theme(legend.position="bottom")

```
The main effect of interest is whether speakers and listeners reduce in the number of words they say over the course of rounds. As shown in Fig \@ref(fig:total-words), the number of words produced does decrease. Listeners often don't talk much, but are more likely to ask questions or make clarification in early rounds. Speakers make longer utterances in early blocks and reduce to shorter utterances in later blocks. Notably, this shortening pattern occurs even as speakers rotate. In aggregate, the effect of being one block later is `r round(fem1["block","Estimate"],2)` [`r round(fem1["block", "Q2.5"],2)`,`r round(fem1["block","Q97.5"],2)`] words. The overall effect of having more players in a group is  `r round(fem1["numPlayers","Estimate"],2)` [`r round(fem1["numPlayers", "Q2.5"],2)`,`r round(fem1["numPlayers","Q97.5"],2)`] per additional player. This estimate is uncertain because of a relatively small number of groups and wide group-level variability. 


(ref:word-lines) Words said by the speaker for each tangram in each group. Each referent/group trajectory is a thin line; aggregate curve is bolded. No outliers were omitted.

```{r variability, out.height="35%", fig.width=6, fig.height=4, fig.pos='h', fig.cap="(ref:word-lines)"}

d.chat %>% filter(role=="speaker") %>% 
    mutate(groupxtangram=str_c(gameId,tangram)) %>% 
  group_by(repNum, numPlayers, gameId,tangram, groupxtangram) %>% 
  summarize(words=sum(total_num_words)) %>% 
ggplot(aes(x=repNum+1, y=words, color=as.factor(numPlayers)))+
  facet_wrap(~numPlayers, nrow=1)+
  scale_color_brewer(palette="Dark2")+
    geom_line(aes(group=groupxtangram), alpha=.1,method=glm, se=F)+
    geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian(link = 'log')))+
  labs( y="Number of words", x="Block number", color="Player count")+
  theme(legend.position="null")


```
This variability can be seen in Fig \@ref(fig:variability). While the averaged data shows a smooth reduction in the number of words, individual trajectories for specific tangrams in specific groups are more varied. Reduction is not monotonic, as some later speakers use more words than were used in earlier rounds. 

Because the ground truth answers are not provided to listeners who make mistakes, they may not learn what utterance was referring to (unless they ask in the chat). What happens if a listener gets a tangram wrong and then is the speaker on the next block? For that tangram, they are unlikely to build off the previous descriptionsn and conventions that they don't understand. In contrast, a speaker who previously got the tangram right is reasonably likely to continue the conceptualization used so far and conventionalize it more, such as by reducing unneeded details. In aggregate hypothesizes that speakers should say more words if they got that tangram wrong the previous round that not, after controlling for other effects. This is borne out; speakers say `r round(fem2["was_INcorrect","Estimate"],2)` [`r round(fem2["was_INcorrect", "Q2.5"],2)`,`r round(fem2["was_INcorrect","Q97.5"],2)`] more words when previously wrong. 




# Discussion
TODO effects/interpretation of speaker rotation and feedback regime

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
