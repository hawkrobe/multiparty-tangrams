---
title: "Two's company but six is a crowd: emergence of conventions in multiparty communication games"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"
header-includes:
  - \usepackage{booktabs}
author-information: > 
    \author{{\large \bf Veronica Boyce (vboyce@stanford.edu)} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Robert D. Hawkins (rdhawkins@princeton.edu)} \\ Princton Neuroscience Institute \\ Princeton University
    \AND {\large \bf Noah D. Goodman (ngoodman@stanford.edu)} \\ Departments of Psychology and Computer Science \\ Stanford University
    \And {\large \bf Michael C. Frank (mcfrank@stanford.edu)} \\ Department of Psychology \\ Stanford University}

abstract: >
  From classrooms to dinner parties, many of our everyday conversations take place in larger groups where speakers address multiple listeners at once. Such multiparty settings raise a number of challenges for classical theories of communication, which largely focus on dyadic interactions. In this study, we investigated how speakers adapt their referring expressions over time as a function of the feedback they receive from multiple parties.  We collected a large corpus of multiparty repeated reference games (98 games, 390 participants, 116K words) where speakers designed referring expressions for groups of 1 to 5 listeners. Larger groups tended to use more words total and to introduce more new words; nonetheless, most groups were able to converge to more efficient conventions regardless of the number of listeners.

    
keywords: >
    Pragmatics; Communication; Reference game; Convention; Reduction; Efficiency
    
output: cogsci2016::cogsci_paper
final-submission: \cogscifinalcopy
---
 
# Introduction

```{r global_options, include=FALSE}
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(cowplot)
library(tidybayes)
library(kableExtra)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(theme_bw())


knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=TRUE, 
                      message=F, sanitize = T)
```


```{r set-up, include=F}

ParseJSONColumn <- function(x) {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  %>% 
    fromJSON(flatten = T)
}

##Data import constants
data_location="data/study1"




image_location="write-ups/images"

model_location="code/models"


#we exclude rounds where no one talked (this is our criteria for "they weren't playing anymore")
# this is better than if no one submitted b/c maybe people fail to click on some round?
rounds_include <- read_rds(here(data_location,"rounds_include.rds"))

d.round_results <-  read_rds(here(data_location,'round_results.rds'))

# b/c countCorrect was being bad
d.correct <- d.round_results %>% 
  group_by(`_id`,gameId,target,targetNum,repNum,trialNum,
           numPlayers,countCorrect,speaker,tangram) %>% 
  summarize(realCorrect=sum(ifelse(correct,1,0)))


#d.exit_survey <- read_csv(here(data_location,"exit_survey.csv"))

show_summary <- function(model){
  intervals <- gather_draws(model, `b_.*`, regex=T) %>% mean_qi()
  
  stats <- gather_draws(model, `b_.*`, regex=T) %>% 
    mutate(above_0=ifelse(.value>0, 1,0)) %>% 
    group_by(.variable) %>% 
    summarize(pct_above_0=mean(above_0)) %>% 
   mutate(`P-value equivalent` = signif(2*pmin(pct_above_0,1-pct_above_0), digits=2)) %>% 
    left_join(intervals, by=".variable") %>% 
    mutate(lower=round(.lower, digits=2),
           upper=round(.upper, digits=2),
           `Credible Interval`=str_c("[",lower,", ", upper,"]"),
           Term=str_sub(.variable, 3, -1),
           Estimate=round(.value, digits=2)) %>% 
    select(Term, Estimate, `Credible Interval`, `P-value equivalent`)
  
  stats
}

stats <- function(model, row){
  str_c(model[row,1],": Est=", model[row,2], ", CrI=", model[row,3])
}

stats_text  <- function(model, row){
  str_c( model[row,2], " (CrI=", model[row,3],")")
}

form <- function(model){
 dep <- as.character(model$formula[2])
 ind <- as.character(model$formula[3])
 
 str_c(dep," ~ ",ind) %>% str_replace_all(" ","") %>% 
  str_replace_all("\\*"," $\\\\times$ ") %>% 
  str_replace_all("\\+", "&nbsp;+ ") %>% 
   str_replace_all("~", "$\\\\sim$ ")
}
```

Verbal communication is an integral part of our daily lives. We coordinate schedules with partners, socialize with friends over board games, learn and teach in seminar classes, and listen to podcasts. Communicative environments range in size from one-on-one dialogue to broadcast communication to large groups, but the goal of efficient communication is shared across these [@branigan2006;@ginzburg2005;@traum2004]. Shared referring expressions are a necessity for efficient communication; a thing or an idea needs some sort of name that the interlocutors will jointly understand. In many cases, there are widely shared conventionalized expressions for objects or ideas, but in other cases, spontaneous ad-hoc expressions must be invented. 

The formation of these new reference expressions is well-studied in dyadic contexts and has been a case study for efficient communication more broadly. But these dynamics may be different in larger groups, which are less studied. Our current work builds on the dyadic reference game tradition by extending it to larger groups.

<!-- ## Dyadic reference games -->

@clarkReferringCollaborativeProcess1986 established an experimental method for studying the emergence of new referring expressions that has now become standard [building on @kraussChangesReferencePhrases1964;@kraussConcurrentFeedbackConfirmation1966]. Two participants see the same set of tangram figures; the speaker describes each figure in turn so the listener can select the target from the set of figures. The speaker and listener repeat this process with the same images over a series of blocks. Early descriptions are long and make reference to multiple features in the figure, but in later iterations, shorthand conventional names for each figure emerge; this shortening of utterances is called 'reduction'. 

Recently, online participant recruitment and web-based experiments have made it possible to study this convergence in larger populations [@hawkinsCharacterizingDynamicsLearning2020;@haber2019]. In @hawkinsCharacterizingDynamicsLearning2020, 83 pairs completed a similar iterated reference experiment where they communicated via a chat box. Speakers reduced their utterances, producing fewer words per image in later blocks than in earlier blocks, in line with results from face-to-face, oral paradigms.^[We use "speaker" and "listener" to refer to the roles describing and selecting targets, regardless of communication modality.]
<!-- ## Multi-party communication -->

How does this process proceed in multi-party communication? In a dyad, speakers can tailor their utterances to the one listener, but in large groups, speakers must balance the competing needs of different listeners [@schober1989;@tolins2016]. These effects likely vary by both the knowledge state of and communication channels available to the listeners [@fox-tree2013;@horton2002; @horton2005]. Prior work has focused on manipulating knowledge states by adding new listeners to established groups.




```{r interface, fig.env = "figure*", fig.pos = "t!", fig.width=6, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "All participants saw all 12 tangram images. (A) Speaker's view during selection phase. (B) During the feedback stage, speakers saw what figure each person chose, but listeners only learned if their selection was correct or incorrect. Listeners were not shown what other listeners chose. \\label{game}", cache=FALSE}

img <- png::readPNG(here(image_location, "merged_fig2.png"))
grid::grid.raster(img)
```

In this context, one approach for speakers is to 'aim low' and produce utterances tailored to the least knowledgeable listener [@yoonAimLowMechanisms2018a]. For instance, in @yoonAdjustingConceptualPacts2014, speakers developed conventions with one listener but then used longer descriptions with a new listener. Another strategy for speakers is to integrate across listeners and balance efficiency with informativeness by 'aiming in the middle'. In @yoonAudienceDesignMultiparty2019, speakers communicating to a mixed group of 3 experienced listeners and 1 naive listener used shorter utterances and made fewer accommodations than they did in groups with a greater fraction of naive listeners. Both of these strategies predict that larger groups will be slower to converge than smaller groups.

Disagreements about how to conceptualize referents can also slow groups down. In @weberCulturalConflictMerger2003, pairs of participants played a reference game with the same image sets before a listener switched groups and joined a different pair, making a group of three. The addition of the new listener slowed both listeners down for multiple rounds. When a listener switched groups, they brought preconceptions about how the pictures should be described which conflicted with how the speaker was used to describing the images. This result predicts that, with more perspectives in play, larger groups may have more difficulty agreeing on common conceptualizations.

In general, listeners expect speakers to maintain conventions and stick to descriptions that were similar to successful descriptions. However, listeners were not surprised to hear different descriptions of a familiar object if it came from a new speaker who had just entered the room [@metzingWhenConceptualPacts2003]. It's unclear what this finding predicts about new speakers who are present as fellow listeners during prior blocks -- will listeners expect them to maintain conventions? 

Work on multi-party communication has focused on the addition of a new person into a pair or group that had built up some shared representations. Our present work complements this prior work by examining the effect of group size during the process of convention formation. We extend the dyadic repeated reference game paradigm of @hawkinsCharacterizingDynamicsLearning2020 to games for 2--6 players who rotate between speaker and listener roles. This paradigm allows us to confirm that these findings in dyads extend to larger groups: that accuracy and speed will increase across blocks (question 1) and that speakers will reduce their utterances (produce fewer words) in later blocks (question 2). Additionally, we will be able to test for trends across group size, allowing us to ask whether smaller groups use shorter utterances and reduce faster than larger groups (question 3) and how conventions emerge in larger groups (question 4). In sum, these analyses will fill a gap in the literature by providing a basic characterization of how convention-formation and communication occurs in larger groups.


```{r chat}

rounds_include <- read_rds(here(data_location,"rounds_include.rds"))
d.round_results <- read_rds(here(data_location,"round_results.rds"))
d.chat.filter <- read_csv(here(data_location, "filtered_chat.csv")) %>% 
  filter(!is.chitchat) %>% 
  filter(!is.na(target)) %>% 
  mutate(text = gsub("\\n", '', fixed = T, spellchecked), # note that this is using spellcorrected version!!!!
         text = gsub("[/?/.]", ' ', text),
         text = str_squish(text),
         tangram = gsub('/experiment/tangram_', '', target, fixed=TRUE),
         tangram = gsub('.png', '', tangram, fixed=TRUE),
         utt_length_chars = str_length(text), 
         utt_length_words = str_count(text, "\\W+") + 1) %>%
  group_by(gameId, trialNum, repNum, tangram) %>% 
  mutate(is.firstutter=ifelse(role!="speaker",F,NA)) %>% 
  fill(c("is.firstutter"), .direction="down") %>% 
  mutate(is.firstutter= is.firstutter %|% T) 

d.chat <- d.chat.filter %>% 
  group_by(gameId, trialNum, repNum, tangram, playerId, role, numPlayers) %>%
  summarize(text = paste0(text, collapse = ', '),
            total_num_words = sum(utt_length_words, na.rm=T) %>% as.numeric(),
            total_num_chars = sum(utt_length_chars, na.rm=T) %>% as.numeric()) %>%
  inner_join(rounds_include) %>% 
  full_join(d.round_results, c("gameId", "trialNum", "repNum", "playerId", "tangram", "numPlayers")) %>% 
  mutate(text = text %|% "",
         total_num_words= total_num_words %|% 0,
         total_num_chars= total_num_chars %|% 0,
         role = role %|% "listener")

d.chat.pre <- d.chat.filter %>% group_by(gameId, trialNum, repNum, tangram, playerId, is.firstutter,role, numPlayers) %>%
  summarize(text = paste0(text, collapse = ', '),
            total_num_words = sum(utt_length_words, na.rm=T) %>% as.numeric(),
            total_num_chars = sum(utt_length_chars, na.rm=T) %>% as.numeric()) %>%
  inner_join(rounds_include) %>% 
  ungroup() %>% 
  mutate(text = text %|% "",
         total_num_words= total_num_words %|% 0,
         total_num_chars= total_num_chars %|% 0,
         role = role %|% "listener") %>% 
  filter(is.firstutter)

```

```{r count}
# For abstract (and elsewhere) count things!

games <- d.round_results %>% select(gameId) %>% unique() %>% nrow() # 98

players <- d.round_results %>% select(gameId, numPlayers) %>% unique() %>% summarize(players=sum(numPlayers)) # 390

words <- d.chat %>% ungroup() %>% select(total_num_words) %>% summarize(words=sum(total_num_words)) #116000

```



# Methods



Building on the methods of @hawkinsCharacterizingDynamicsLearning2020, we used Empirica [@almaatouqEmpiricaVirtualLab2020] to create real-time multi-player reference games. In each game, one of the players started as the speaker who saw an array of tangrams with one highlighted (Figure \ref{game}A) and communicated which figure to click to the other players (listeners). After the speaker had identified each of the 12 images in turn, the speaker role rotated to another player and the process repeated with the same images. In total, there were 6 blocks, giving each player at least one chance to be the speaker.   We recorded what participants said in the chat, as well as who selected what image and how long they took to make their selections.^[Code to run the experiment, as well as data and analysis code are available at https://osf.io/qdvbr/?view_only=47aebfde243f405e9c42a45cacb697d2.] We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study.^[Our preregistrations are at https://osf.io/cn9f4/?view_only=7fdacd698b24465cb1a8699050af5bfc and  https://osf.io/rpz67?view_only=5284203e2b644fc5ac39cf3e723b9a7e.]

## Participants

We recruited participants between May and July 2021 using the Prolific platform; participants had all self-reported as fluent native English speakers on Prolific's demographic prescreen. Participants were paid \$7 for 2-player games, \$8.50 for 3-player games, \$10 for 4-player games, and \$11 for 5- and 6-player games (with the intention of a \$10 hourly rate), in addition to up to \$2.88 in performance bonuses. A total of 390 people each participated in one game. 

## Materials

We used the 12 tangram images used by @hawkinsCharacterizingDynamicsLearning2020 and @clarkReferringCollaborativeProcess1986 (see Figure \ref{game}). These images were displayed in a grid with order randomized for each participant (thus descriptions such as "top left" were ineffective as the image might be in a different place on the speaker's and listeners' screens). The same images were used every block. 

## Procedure


```{r parts, results="asis"}

summary <- d.round_results %>% group_by(trialNum, repNum, gameId, numPlayers) %>% 
           mutate(time= time %|% 180) %>% 
  summarize(max_time=max(time)) %>% 
  group_by(gameId, numPlayers) %>% 
  summarize(total_time=sum(max_time)/60,
            num_trials=max(trialNum)) %>% 
  arrange(numPlayers) %>% 
  mutate(complete=ifelse(num_trials==71,T,F)) %>% 
  group_by(numPlayers,complete) %>% 
  tally() %>% 
  pivot_wider(names_from=complete, values_from=n) %>% 
  rename(Players=numPlayers,Complete=`TRUE`, Partial=`FALSE`) %>% 
    mutate(Players=int(Players)) %>% 
  arrange(Players,Complete,Partial)

tab1 <- xtable::xtable(summary, align="lccc",
                       caption = "Number of games run for each player count.\\label{parts}")

print(tab1, type="latex", comment = F, include.rownames=F, table.placement = "h")
```

We implemented the experiment using Empirica, a Javascript-based platform for running real-time interactive experiments online [@almaatouqEmpiricaVirtualLab2020].  From Prolific, participants were directed to our website where they navigated through a self-paced series of instruction pages explaining the game. Participants had to pass a quiz to be able to play the game. They were then directed to a "waiting room" screen until their partners were ready.

Once the game started, participants saw screens like Figure \ref{game}A. Each trial, the speaker described the highlighted tangram image so that the listeners could identify and click it. All participants were free to use the chat box to communicate, but listeners could only click once the speaker had sent a message. Once a listener clicked, they could not change their selection. There was no signal to the speaker or other listeners about who had already made a selection. 

Once all listeners had selected (or a 3-minute timer ran out), participants were given feedback (Figure \ref{game}B). Listeners learned whether they individually had chosen correctly or not; listeners who were incorrect were not told the correct answer. The speaker saw which tangram each listener had selected, but listeners did not. This feedback regime is different from @hawkinsCharacterizingDynamicsLearning2020 where listeners were shown what the right answer was during feedback. We made this change to prevent listeners from learning conventions purely as a memorized mapping between utterance and correct answer. 

Listeners got 4 points for each correct answer; the speaker got points equal to the average of the listeners' points. These points translated into performance bonus at the end of the experiment. 

In each block, each of the 12 tangrams was indicated to the speaker once. The same person was the speaker for an entire block, but participants rotated roles between blocks. Thus, over the course of the 6 blocks, participants were speakers 3 times in 2-player games, twice in 3-player games, once or twice in 4 and 5-player games, and once in 6-player games. Rotating the speaker was chosen to keep participants more equally engaged (the speaker role is more work), and to give a more robust test for reduction and convention. 

After the game finished, participants were given a survey asking for optional demographic information and feedback on their experience with the game. 

## Data pre-processing and exclusions

Participants could use the chat box freely, which meant that the chat transcript contained some non-referential language. The first author skimmed through the chat transcripts, tagging utterances that did not refer to the current tangram. These were primarily pleasantries ("Hello"), meta-commentary about how well or fast the task was going, and confirmations or denials ("ok", "got it", "yes", "no"). We exclude these utterances from our analyses. Note that chat lines sometimes included non-referential words in addition to words referring to the tangrams ("ok, so it looks like a zombie", "yes, the one with legs"); these lines were retained intact. 

Our intended sample size was 20 complete games in each group size, but we ended up with fewer due to games not filling or  participants disconnecting early (Table \ref{parts}).  We excluded incomplete blocks from analyses, but included complete blocks from partial games.

# Results

## Accuracy and Speed

Our first question was whether accuracy and speed increased across groups of different sizes.

### Accuracy is high and increasing.

```{r model-acc, include=F, eval=FALSE}
acc_input <- d.round_results %>% group_by(playerId,repNum, gameId, numPlayers) %>% 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  mutate(block=repNum,
         tangram_group=str_c(tangram, gameId))

priors <- c(set_prior("normal(0,1)", class="b"))#, #we're doing logistic, so these are reasonable b/c transform
                     # set_prior("normal(0,1)", class="sd"))

model <- brm(correct.num ~ block*numPlayers, 
             family=bernoulli(link="logit"),
             data=acc_input, 
             cores = 4,
             file=here(model_location, "acc_model"), prior=priors, control=list(adapt_delta=.95))

acc <- show_summary(model) %>% write_rds(here(model_location,"acc_summ.rds"))
acc_spec <- model$formula %>% write_rds(here(model_location, "acc_spec.rds"))
```

```{r}
acc <- read_rds(here(model_location,"acc_summ.rds"))
acc_spec <- read_rds(here(model_location,"acc_spec.rds"))
```

```{r accuracy, fig.env="figure", fig.pos = "t", fig.align = "center", out.width="100%", fig.width=5, fig.height=2.5, fig.cap = "Players' accuracy at correctly selecting the target figure by block and group size. Accuracy increases across blocks. \\label{accuracy}" }
d.round_results %>% group_by(playerId,repNum, gameId, numPlayers) %>% 
  mutate(correct.num=ifelse(correct,1,0)) %>% 
  ggplot(aes(x=repNum+1, y=correct.num, color=as.factor(numPlayers)))+
geom_smooth(method = "glm", method.args = list(family = "binomial"), size=1.3) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.3), size=.5)+
  scale_color_viridis(discrete=T, direction=-1)+
    scale_x_continuous(breaks=seq(1,6))+
  labs(x="Block", y="Selection Accuracy", color="Players")+
  theme(legend.position="right")

```

Most individuals were accurate in their selections, with accuracy rising across blocks (Figure \ref{accuracy}).  In a logistic model of accuracy^[`r form(acc_spec)` This and all subsequent regression models were run in brms with weakly regularizing priors.], participants are more accurate in later blocks (`r stats(acc,1)`), and there was no strong effect of group size on accuracy (`r stats(acc,4)`) or interaction between block and group size (`r stats(acc,2)`). 

### Participants speed up in later blocks.

```{r model-time, include=F, eval=FALSE}
#note: there were some issues with time recording, source unknown. We exclude the obvious errors where time > 180, but it's probably still a bit dodgy?
time_input <- d.round_results %>% group_by(playerId, repNum, gameId, numPlayers) %>% 
  filter(correct==T) %>% 
  filter(time<181) %>% 
  filter(time>0) %>% 
  mutate(block=repNum,
         tangram_group=str_c(tangram, gameId))

priors <- c(set_prior("normal(0,100)", class="Intercept"),
            set_prior("normal(0,50)", class="b"))

model <- brm(time ~ block*numPlayers , 
             data=time_input, 
             cores = 4,
             file=here(model_location, "time_model"), prior=priors, control=list(adapt_delta=.95))

time <- show_summary(model) %>% write_rds(here(model_location,"time_summ.rds"))
time_spec <- model$formula %>% write_rds(here(model_location, "time_spec.rds"))

```

```{r}
time <- read_rds(here(model_location,"time_summ.rds"))
time_spec <- read_rds(here(model_location,"time_spec.rds"))
```


```{r time, fig.env="figure", fig.pos = "t", fig.align = "center",out.width="100%", fig.width=5, fig.height=2.5, fig.cap = "How long listeners took to select a figure in seconds by block and group size. Listeners selected images faster in later blocks. Only times for correct responses are shown.\\label{time}" }
d.round_results %>% group_by(playerId, repNum, gameId, numPlayers) %>% 
  filter(correct==T) %>% 
  filter(time<181) %>% 
  #summarize(time=mean(time)) %>% 
  ggplot(aes(x=repNum+1, y=time, color=as.factor(numPlayers)))+
  geom_jitter(width=.4, height=0, alpha=.03)+
geom_smooth(method = "glm", formula = y~x,
                      method.args = list(family = gaussian(link = 'log')))+
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2))+
  scale_y_continuous(limits = c(0,180))+
      scale_x_continuous(breaks=seq(1,6))+
 scale_color_viridis(discrete=T, direction=-1)+ 
  labs(x="Block", y="Time to select (s)", color="Players")+
  theme(legend.position = "right")

```


Participants selected images faster in later blocks (Figure \ref{time}), although there was wide variability. In a linear model of selection time^[`r form(time_spec)`], participants got faster across blocks (`r stats(time,1)`) and were slightly slower in larger games (`r stats(time,4)`). This speed up is consistent with prior work by @weberCulturalConflictMerger2003 which used speed as the dependent measure. Wide variability in selection time meant that especially for larger groups, there was a wide spread in how long it took groups to complete the experiment. 

## Reduction

Our second question was whether speakers reduce their referring expressions in larger groups. 

### Speakers' utterances reduce in length. 

```{r variability, fig.env="figure", fig.pos = "h", fig.align = "center",out.width="100%", fig.width=6, fig.height=3, fig.cap = "Number of words from speaker (total, across all 12 figures) in a block. Each colored line is one group, the overall trend is shown in black. Across group size, the number of words decreases as conventions emerge, but convention formation is not a smooth process, and there is variability between speakers.\\label{variability}" }
d.chat %>% filter(role=="speaker") %>% group_by(gameId,numPlayers,repNum) %>% 
  summarize(words=sum(total_num_words)) %>% ggplot(aes(x=repNum+1, color=as.factor(numPlayers), y=words, ))+geom_line(aes(group=gameId))+facet_wrap(~numPlayers, nrow=1)+
  geom_smooth(method=glm, formula=y~poly(x,2), se=F, color="black")+
  scale_color_viridis(discrete=T, direction=-1)+
  scale_x_continuous(breaks=seq(1,6))+
  labs(y="Total words from speaker", x="Block", color="Players")+
  theme(legend.position="none")

```

```{r model-speaker, include=F, eval=FALSE}
speaker_input <- d.chat %>% filter(role=="speaker") %>% 
  mutate(block=repNum,
         words=total_num_words,
         tangram_group=str_c(tangram, gameId))
         
priors <- c(
  set_prior("normal(20, 20)", class="Intercept"),
  set_prior("normal(0, 10)", class="b"),
  set_prior("normal(0, 10)", class="sd"),
  set_prior("lkj(1)",       class="cor"))

model <- brm(words ~ block * numPlayers + (block|tangram)+ (1|playerId)+(1|tangram_group)+(block|gameId),
             cores = 4,
             data=speaker_input,file=here(model_location, "speaker_model"),                            prior=priors, control=list(adapt_delta=.95))

speaker <- show_summary(model) %>% write_rds(here(model_location,"speaker_summ.rds"))
speaker_spec <- model$formula %>% write_rds(here(model_location, "speaker_spec.rds"))


```

```{r}
speaker <- read_rds(here(model_location,"speaker_summ.rds"))
speaker_spec <- read_rds(here(model_location,"speaker_spec.rds"))

```

As shown in Figure \ref{variability}, the number of words produced by speakers decreases over the course of rounds, both in aggregate and for many individual groups. Nonetheless, in some groups, a later speaker may be more verbose than an earlier speaker. Speakers make longer utterances in early blocks that reduce to shorter utterances in later blocks. From a linear model[^2], the effect of being one block later is `r stats_text(speaker,1)` words. 

[^2]: `r form(speaker_spec)`

### Listeners rarely talk.

```{r model-listener, include=F, eval=FALSE}
listener_input <- d.chat %>% filter(role=="listener") %>% 
  mutate(block=repNum,
         words=total_num_words,
         tangram_group=str_c(tangram, gameId))
         
priors <- c(
  set_prior("normal(0, 20)", class="Intercept"),
  set_prior("normal(0, 10)", class="b"),
  set_prior("normal(0, 10)", class="sd"),
  set_prior("lkj(1)",       class="cor"))

model <- brm(words ~ block * numPlayers + (block|tangram)+ (1|playerId)+(1|tangram_group)+(block|gameId),
             cores = 4,
             data=listener_input,file=here(model_location, "listener_model"),                            prior=priors, control=list(adapt_delta=.95))

         
listener <- show_summary(model) %>% write_rds(here(model_location,"listener_summ.rds"))
listener_spec <- model$formula %>% write_rds(here(model_location, "listener_spec.rds"))

```

```{r}
listener <- read_rds(here(model_location,"listener_summ.rds"))
listener_spec <- read_rds(here(model_location,"listener_spec.rds"))
```

Listeners often don't talk much, but are more likely to ask questions or make clarification in early blocks. In a linear regression for the number of words each listener said [^1], there was an effect of block (`r stats(listener, 1)`), but no clear effect of game size (`r stats(listener,4)`). 

[^1]: `r form(listener_spec)`

```{r repeat-speakers, include=F, eval=FALSE}
model_input <- d.chat %>% filter(role=="speaker") %>% 
  mutate(block=repNum,
         words=total_num_words,
         tangram_group=str_c(tangram, gameId)) %>% 
  mutate(speaker.repeat=ifelse(block<numPlayers,0,1))
  
         
priors <- c(
  set_prior("normal(20, 20)", class="Intercept"),
  set_prior("normal(0, 10)", class="b"),
  set_prior("normal(0, 10)", class="sd"),
  set_prior("lkj(1)",       class="cor"))

model_repeat_speaker <- brm(words ~ block * numPlayers + block * speaker.repeat+(block|tangram)+ (1|playerId)+(1|tangram_group)+(block|gameId), 
                            data=model_input,
                            cores = 4,
                            file=here(model_location, "model_code_repeat"),                            prior=priors, control=list(adapt_delta=.95))

speaker_repeats <- show_summary(model_repeat_speaker) %>% write_rds(here(model_location,"speaker_repeat_summ.rds"))
speaker_repeat_spec <- model_repeat_speaker$formula %>% write_rds(here(model_location, "speaker_repeat_spec.rds"))

```

```{r}
repeat_speaker <- read_rds(here(model_location,"speaker_repeat_summ.rds"))
repeat_speaker_spec <- read_rds(here(model_location,"speaker_repeat_spec.rds"))
```

## Effects of group size on conventions

Our third question was whether smaller groups would use fewer words or reduce faster than larger groups. 

### Larger groups say more. 

The overall effect of having more players in a group is `r stats_text(speaker,4)` words from the speaker per trial per additional player. There is no clear interaction between block and group size (`r stats(speaker,2)`). Larger groups saying more is consistent with predictions from audience design that with more listeners to accommodate, the speaker may use multiple conceptualizations, either initially as a hedge or in response to listener clarifications. 

### Speaker experience does not fully explain group size effects. 

One potential concern is that group size correlates with whether the speaker has had the speaker role before (smaller groups repeat speakers more). To address this confound, we coded for whether the speaker has been speaker in an earlier block[^3]. Repeat speakers do use fewer words (`r stats(repeat_speaker,6)`), but there are still effects of group size (`r stats(repeat_speaker,5)`) and block (`r stats(repeat_speaker,1)`). The effects of block and repeat speaker are subadditive (`r stats(repeat_speaker,3)`), and there is minimal interaction between block and group size (`r stats(repeat_speaker,2)`). 

[^3]: `r form(repeat_speaker_spec)`

## Development of conventions 

Our final question was how conventions emerge in larger groups.

### Speakers who don't know the convention reduce less. 

```{r speaker-acc, include=F, eval=FALSE}
d.prev.speaker <- d.chat %>% ungroup() %>%  filter(role=="speaker") %>% select(gameId,repNum, tangram, total_num_words_prev=total_num_words)
d.prev.round <- d.chat %>% ungroup() %>% select(playerId, correct, tangram, gameId, repNum) %>% 
  left_join(d.prev.speaker) %>% unique() %>% mutate(repNum=repNum+1)


d.chat.lagged <- d.chat %>%
  ungroup() %>% 
  select(gameId, playerId, trialNum, repNum, playerId, role, tangram, total_num_words, numPlayers) %>%
  left_join(d.prev.round) %>%
  mutate(reduction_word=log(total_num_words)-log(total_num_words_prev)) %>%
  filter(repNum>0) %>%
  filter(role=="speaker") %>%
  mutate(prev_correct_round=correct)


model_input <- d.chat.lagged %>% filter(role=="speaker") %>% 
  mutate(block=repNum,
         words=total_num_words,
         tangram_group=str_c(tangram, gameId),
         was_INcorrect=ifelse(!prev_correct_round,1,0))
         
priors <- c(
  set_prior("normal(20, 20)", class="Intercept"),
  set_prior("normal(0, 10)", class="b"),
  set_prior("normal(0, 10)", class="sd"),
  set_prior("lkj(1)",       class="cor"))

model_speaker_acc <- brm(words ~ block * numPlayers*was_INcorrect+ (block|tangram)+ (1|playerId)+(1|tangram_group)+(block|gameId),
                         cores = 4,
                         data=model_input,file=here(model_location, "speaker_acc2"),                         prior=priors, control=list(adapt_delta=.95))

speaker_acc <- show_summary(model_speaker_acc) %>% write_rds(here(model_location,"speaker_acc_summ.rds"))
speaker_acc_spec <- model_speaker_acc$formula %>% write_rds(here(model_location, "speaker_acc_spec.rds"))

```

```{r}
speaker_acc <- read_rds(here(model_location,"speaker_acc_summ.rds"))
speaker_acc_spec <- read_rds(here(model_location,"speaker_acc_spec.rds"))

```


In our games (which had limited feedback), listeners who got a tangram wrong didn't  have a way of knowing what the right answer was unless they asked for clarification in the chat. If a speaker got a tangram wrong as a listener in the previous block, they may not have known the conventional description that went with it, and thus were unlikely to follow the convention. If we assume that reduction is a sign of convention development, then speakers should say more words when they got the tangram wrong the previous block. We added prior errors as an additional predictor to our regression predicting number of words and found that speakers said more words for tangrams after they were incorrect (`r stats(speaker_acc,6)`). 

<!-- [^4]: `r form(speaker_acc_spec)` -->

### Smaller groups reduce and stabilize conventions sooner.

```{r similarity, fig.env = "figure*", fig.pos = "h", fig.width=9, fig.height=3, fig.align = "center", set.cap.width=T, num.cols.cap=2,out.width="80%", fig.cap = "Comparison of the content words is the final (6th) block to words in previous blocks. (A) The proportion 6th block content words found in each prior block. (B) The proportion 6th block content words that were first used by the speaker in each block. Smaller games have higher overlap and a greater proportion of words originating earlier. \\label{similarity}" }
d.numPlayer <- read_rds(here(data_location,'round_results.rds')) %>% select(numPlayers, gameId) %>% unique()
matches <- read_csv(here("data/study1/word_matches.csv")) %>% left_join(d.numPlayer, by="gameId")

location_first_match <- matches %>% 
  filter(later_rep==5) %>% 
  group_by(earlier_rep,gameId,numPlayers) %>% 
  summarize(overlap=mean(match))

first <- ggplot(location_first_match, aes(x=earlier_rep+1, y=overlap, color=as.factor(numPlayers)))+
  geom_jitter(alpha=.5,width=.2, height=0)+facet_grid(.~numPlayers)+
    scale_color_viridis(discrete=T, direction=-1)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2), color="black")+
   stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2), color="black", geom="line")+
  scale_x_continuous(lim=c(.5,6.5))+
  labs(x="", y="Prop. block 6 \ncontent  words \nfound in block")+
  theme(legend.position="none", axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.title.x=element_blank())

never <- matches %>% filter(later_rep==5) %>% group_by(numPlayers, gameId, target, word) %>% summarize(blah=sum(match)) %>% filter(blah==0) %>% mutate(earliest_rep=5) %>% select(gameId, target, word, numPlayers, earliest_rep)
convention <- matches %>% filter(later_rep==5) %>% 
  filter(match) %>% 
  group_by(gameId,target,word, numPlayers) %>% 
  summarize(earliest_rep=min(earlier_rep)) %>% 
  union(never) %>% 
  group_by(gameId, numPlayers, earliest_rep) %>% 
  tally() %>% 
  group_by(gameId,numPlayers) %>% 
  summarize(pct=n/sum(n), earliest_rep=earliest_rep)

conv <- ggplot(convention, aes(x=earliest_rep+1, y=pct, color=as.factor(numPlayers)))+
  geom_jitter(alpha=.5,width=.2, height=0)+facet_grid(.~numPlayers)+
    scale_color_viridis(discrete=T, direction=-1)+
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2), color="black")+
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width=.2), color="black", geom="line")+
    scale_x_continuous(lim=c(.5,6.5))+
  labs(x="Block", y="Prop. block 6 \ncontent  words \noriginating in block")+
  theme(legend.position="none")

plot_grid(first, conv, labels=c('A','B'), rows=2, rel_heights=c(1,1.2))
```


```{r same-speaker, include=F, eval=FALSE}
same_speaker <- matches %>% 
  filter(later_rep==5) %>% 
  mutate(same_speaker=ifelse(earlier_rep%%numPlayers==later_rep%%numPlayers,1,0),
         match.num=ifelse(match, 1,0)) %>% 
    mutate(target=str_extract(target,"[A-Z]")) %>% 
  select(gameId,target,block=earlier_rep,numPlayers,match, same_speaker) %>% 
  group_by(gameId,target,block, numPlayers, same_speaker) %>% 
  summarize(overlap=mean(match))
  
  priors <- c(
  set_prior("normal(0, 1)", class="Intercept"),
  set_prior("normal(0, 1)", class="b"),
  set_prior("normal(0,1)", class="sd"))
  #set_prior("lkj(1)",       class="cor")
  #)

 model_conventions <- brm(overlap ~ block * numPlayers + same_speaker + (1|gameId)+(1|target),
                          cores = 4,
                          data=same_speaker,file=here(model_location, "model_convention"),  prior=priors, control=list(adapt_delta=.95))

  #model_conventions <- glm(match ~ block * numPlayers + same_speaker, data=same_speaker ,family=binomial)
         
conventions <- show_summary(model_conventions) %>% write_rds(here(model_location,"conventions_summ.rds"))
convention_spec <- model_conventions$formula %>% write_rds(here(model_location, "convention_spec.rds"))
```

```{r}
conventions <- read_rds(here(model_location,"conventions_summ.rds"))
convention_spec <- read_rds(here(model_location,"convention_spec.rds"))

```


Another angle to look at conventions is to take the speaker's utterances in the last block as the "convention", and look at how far back they started. We took the contentful words said by the speaker in the last block and looked at how many of them were used to describe that tangram in prior rounds.^[Contentful words were defined as all words in a referential message with a part of speech identified by the Spacy (\url{http://spacy.io}) tagger as being a noun, verb, or adjective; that were not on the Spacy stop word list; and that did not have a lemma in the set ['look','like','body','person','man','guy'], a list generated as being extremely common vocabulary across tangrams.] Then we calculated the proportion overlap between the last block utterance and earlier blocks, shown in Figure \ref{similarity}A. In a linear model of the overlap between an earlier block and the last block[^5], later blocks have more overlap (`r stats(conventions,1)`).  Blocks with the same speaker as the last round have more overlap (`r stats(conventions,5)`); this pattern is visible in the peaks for blocks 2 and 4 in the 2 player games. Larger groups have less overlap between blocks (`r stats(conventions,4)`), but there is no interaction between blocks and game size (`r stats(conventions,2)`). One potential confound is that in smaller games, players spend more time in the speaker role; however, there is still more overlap in smaller games even to blocks with a different speaker.  

[^5]: `r form(convention_spec)`

Another way to measure conventions is to look at when these words were first introduced by the speaker (Figure \ref{similarity}B). A greater fraction of 6th block words were new in 5 or 6 player games compared with smaller games, whereas most words used in 2-player games originated in the 1st or 2nd blocks.  Overall, conventions reduced and stabilized sooner in smaller groups, perhaps because fewer people need to implicitly agree on them. 

### Groups varied in their strategies and reduction. 

While most groups did form conventions for most tangrams, it's illustrative to look at a case where a group did not. Table \ref{diamond} shows the transcript of a 4-person group for a specific figure where they described it geometrically every round, leading to long and not very informative descriptions. Nearly all the figures have diamond heads, so this isn't a distinguishing feature, yet it is described. This illustrates the variability between groups, but also why conventions might be useful. 


```{r diamond}
diamond <- tribble(~`Block`, ~`Person`, ~Text,
                 "1","A(S)","Diamond on top. Body with no real arms or legs. The body is shaped like a boot with the diamond on top.",
		"","C", "Is the boot pointed left or right?",
		"2", "B(S)", "diamond on top, large body beneath it. Left is a straight line all the way down, small variations on the right to the main body",
		"3", "C(S)", "Diamond in center on top. Left side straight, right side carved out like a vase.",
		"4", "D(S)", "Diamond head, flat topped body, straight on the left side with two triangles pointing out on the left",
		"","D(S)" ,"*on the right",
	"5" ,"A(S)", "Diamond on top. Left side is straight, right side is obstructed, looks like a boot",
	"", 	"B", "what do you mean by obstructed?",
		"", "A(S)", "The left side of the body is right, right side has bents in it",
		"6", "B(S)", "Diamond on top of a long large body/rectangle. Left side is complete, right side has bits missing")

knitr::kable(diamond, caption = "Excerpt from a group that did not reduce very much. The speaker for each round is marked with (S). Figure under discussion is row 3, column 3 in Figure \\ref{game}A.\\label{diamond}",  format="latex", booktabs=TRUE, linesep="") %>%
kable_styling(full_width = F) %>%
column_spec(3, width = "16em") %>% kable_styling(latex_options="H")

```



A different 4-person group had a member who during the first block shared the idea that the task would be easier if they explicitly gave "codenames" to the figures. The transcript for this group and one of the tangrams is shown in Table \ref{zigzag}. Of note, multiple speakers forget the assigned codename, demonstrating that meta-knowledge doesn't always help. This group also describes the figure in relation to another already-named figured. Nonetheless, the group successfully conventionalizes on a couple reduced names for this figure: "zigzag" and "beggar". This dual-naming of figures from multiple conceptual angles contributed by different speakers also occurs in other games. 




```{r zigzag}

zigzag <- tribble(~Block, ~Person, ~`Text`,
 "1", "A(S)" , "[...] yes, the legs are like a zig zag",
		"",	"C", "CODE name ZIGZAG",
			"","A(S)",	"There are no legs upwards",
			"2", "B(S)", "okay so similar to begger guy but no foot pointing up",
			"","B(S)", "its like a zigzag",
			"","B(S)", "i forgot the code name",
			"","D", "zigzag yea",
			"","A", "The one standing with knees bent",
			"","B(S)", "yeah",
			"","B(S)" ,"standing",
			"", "C", "Yeah zigzag",
			"3", "C(S)",	"The begger with no foot coming out from the left",
			"","B", "zigzag",
			"","C(S)",	"zigzag it is",
			"","C(S)",	"sorry i forgot",
			"4", "D(S)",	"zigzag",
		"5", "A(S)",	"zigzag",	
			"6", "B(S)",	"beggar guy",
			"", "B(S)" ,"zigzag")

knitr::kable(zigzag, caption = "Excerpt from a group that explicitly gave nicknames to the figures.  The speaker for each round is marked with (S). Tangram under discussion is row 1, column 4 in Figure \\ref{game}A. \\label{zigzag}", format="latex",booktabs = TRUE, linesep="") %>%
column_spec(3, width = "16em") 


```

# Discussion

The emergence of conventions has been a key case study for communication more broadly. Yet this issue has -- for the most part -- been studied only in dyadic communication. While some studies have examined aspects of convention formation in larger groups [e.g., @yoonAdjustingConceptualPacts2014;@yoonAudienceDesignMultiparty2019], basic descriptive work has not yet investigated how group size changes the dynamics of interaction in a standard referential communication task, in part because such tasks can be difficult to administer to larger groups. Taking advantage of a new online multi-player experiment platform, we ran repeated reference games with groups of 2--6 players and characterized the nature of group performance.

Consistent with dyadic games, listeners' selection accuracy increased over blocks at the same time as listeners sped up their selections (question 1). 
Crucially, speakers reduced the length of their descriptive utterances as they conventionalized on concepts for each image (question 2). Because speakers rotated, this reduction finding is robust: not only did speakers say less in later repetitions than they themselves said earlier, speakers later in the order said less than speakers earlier in the rotation. This reduction varied with group size; smaller groups used shorter utterances, but group size did not significantly interact with block (question 3). The trajectory of reduction also depended on whether the current speaker correctly identified the tangram in the prior block and whether the current speaker was new to being speaker. This pattern is consistent with both the 'aim low' and 'aim middle' hypotheses from previous work [@yoonAdjustingConceptualPacts2014;@yoonAudienceDesignMultiparty2019].

What was specifically different across group sizes? Smaller groups showed more agreement in how each tangram was identified across blocks (question 4), coming to consensus earlier: Their overlap between descriptions in the first 5 blocks to the final block was higher, and words in the final block tended to originate earlier. The greater diversity in how tangrams were described in larger groups could be explained by slower convergence to a convention or parallel competing conceptualizations favored by different speakers. Larger groups have more people for the speaker to communicate to, but also more people who might interrupt with questions, and more people who have opinions about what each image looks like. Bigger groups differ from smaller groups in a number of ways, however, and disentangling these differences is an area for future work. 

<!-- ## Limitations -->

Group interactions are rich, and this experiment is necessarily a schematic simplification with a number of limitations. Real-life situations vary widely in who the interlocuters are, their relationships, their goals, and their environment [@fay2000;@carletta1998]. Our participants were a convenience sample of Prolific workers who were strangers to each other; thus we miss richness that could come from prior relationships or shared community.  Reference is only one goal out of many possible communicative goals, and the tangram images are artificial. 
We provided less feedback than previous studies such as @hawkinsCharacterizingDynamicsLearning2020; this regime imitates situations where interlocutors can't show each other examples, but it's not representative of all communicative environments. Further, our text-based online paradigm meant that participants' individual identities were not especially salient. In sum, communication takes place in a plethora of situations; our experiment provides some insights, but also misses many complexities that should be a focus of further experiments. 

<!-- ## Future work -->

The experimental paradigm presented here could be a valuable tool to disentangle the mechanisms of group size and determine which design parameters are relevant to reduction. Luckily, with an online implementation, recruiting for and running experiments is feasible, and thus it will be possible to iterate on this experiment to determine how far the patterns generalize. While much is left to be explored, this initial data set provides a rich corpus of how humans adapt language dynamically to communicate. 


# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
